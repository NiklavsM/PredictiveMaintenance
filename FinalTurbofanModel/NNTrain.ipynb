{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4-tf\n",
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# Adding all needed imports\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "from keras.layers.convolutional import Conv1D\n",
    "print(tf.keras.__version__)\n",
    "print(tf.__version__)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math as mt\n",
    "import random as rng\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "151\n",
      "80\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "dataTrain = np.load(\"dataFormatted/finished/stTrain.npy\", allow_pickle=True)\n",
    "targetTrain = np.load(\"dataFormatted/finished/stTrainTarget.npy\", allow_pickle=True)\n",
    "\n",
    "\n",
    "dataVal = np.load(\"dataFormatted/finished/stVal.npy\", allow_pickle=True)\n",
    "targetVal = np.load(\"dataFormatted/finished/stValTarget.npy\", allow_pickle=True)\n",
    "\n",
    "\n",
    "print(len(dataTrain[0]))\n",
    "print(len(targetTrain[0]))\n",
    "print(len(dataTrain))\n",
    "print(len(targetTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "numRows = 30\n",
    "step = 15\n",
    "\n",
    "\n",
    "\n",
    "def finalSplit(data, targets, numRows, step):\n",
    "    div = int(numRows/2)\n",
    "    splits = []\n",
    "    splitsTarget = []\n",
    "    for each in range(len(data)):\n",
    "        run = data[each]\n",
    "        target = targets[each]\n",
    "        for i in range(div, len(target) - div, step):\n",
    "            split = []\n",
    "            RUL = 0\n",
    "            for j in range(-div,div):\n",
    "                index = i + j\n",
    "                element = run[index].copy()\n",
    "                RUL = target[index]\n",
    "                split.append(element)\n",
    "            splits.append(split)\n",
    "            splitsTarget.append(RUL)\n",
    "            \n",
    "    return splits, splitsTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712\n",
      "179\n"
     ]
    }
   ],
   "source": [
    "dataSplitTrain, targetSplitTrain = finalSplit(dataTrain, targetTrain, numRows, step)\n",
    "dataSplitVal, targetSplitVal = finalSplit(dataVal, targetVal, numRows, step)\n",
    "\n",
    "\n",
    "print(len(dataSplitTrain))\n",
    "print(len(dataSplitVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "dataSplitTrain = np.array(dataSplitTrain)\n",
    "targetSplitTrain = np.array(targetSplitTrain)\n",
    "dataSplitVal = np.array(dataSplitVal)\n",
    "targetSplitVal = np.array(targetSplitVal)\n",
    "\n",
    "\n",
    "\n",
    "width = len(dataSplitTrain[0][0])\n",
    "print(width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The added layer must be an instance of class Layer. Found: Tensor(\"gru_10/Identity:0\", shape=(None, 150), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-17c20fab58f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m   \u001b[0mdense\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m   \u001b[0mdrop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m   \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m ])\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m    112\u001b[0m       \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    156\u001b[0m       raise TypeError('The added layer must be '\n\u001b[0;32m    157\u001b[0m                       \u001b[1;34m'an instance of class Layer. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m                       'Found: ' + str(layer))\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: Tensor(\"gru_10/Identity:0\", shape=(None, 150), dtype=float32)"
     ]
    }
   ],
   "source": [
    "visible = layers.Input(shape=(numRows, width))\n",
    "\n",
    "cnn = layers.Conv1D(width, 3, activation='relu')(visible)\n",
    "rnn1 = layers.GRU(150, dropout=0.2)(cnn)\n",
    "#rnn2 = layers.GRU(150, dropout=0.2)(rnn1)\n",
    "\n",
    "\n",
    "#rnnX = layers.LSTM(300, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(visible)\n",
    "#rnnY = layers.LSTM(300, dropout=0.2, recurrent_dropout=0.2)(rnnX)\n",
    "\n",
    "#combo = layers.concatenate([rnn2,rnnY])\n",
    "dense = layers.Dense(150, activation='relu')(rnn1)\n",
    "drop = layers.Dropout(0.2)(dense)\n",
    "out = layers.Dense(1, activation='linear')(drop)\n",
    " \n",
    "\n",
    "# model = Model(inputs=visible, outputs=out)\n",
    "model = keras.Sequential([\n",
    "  layers.Conv1D(width, 3, activation='relu'),\n",
    "  layers.GRU(150, dropout=0.2),\n",
    "  layers.Dense(150, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mse', \n",
    "              metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/50\n",
      "712/712 [==============================] - 2s 3ms/sample - loss: 4405.4521 - mae: 55.1099 - val_loss: 2317.3003 - val_mae: 39.6279\n",
      "Epoch 2/50\n",
      "712/712 [==============================] - 0s 572us/sample - loss: 1684.4866 - mae: 35.2902 - val_loss: 1508.1857 - val_mae: 33.7041\n",
      "Epoch 3/50\n",
      "712/712 [==============================] - 0s 573us/sample - loss: 1463.9538 - mae: 33.0631 - val_loss: 1414.5222 - val_mae: 32.5188\n",
      "Epoch 4/50\n",
      "712/712 [==============================] - 0s 567us/sample - loss: 1359.6850 - mae: 31.8909 - val_loss: 1277.5423 - val_mae: 31.0312\n",
      "Epoch 5/50\n",
      "712/712 [==============================] - 0s 621us/sample - loss: 1204.7709 - mae: 29.9234 - val_loss: 1026.5061 - val_mae: 27.7800\n",
      "Epoch 6/50\n",
      "712/712 [==============================] - 0s 625us/sample - loss: 902.4195 - mae: 25.9598 - val_loss: 632.4703 - val_mae: 21.3090\n",
      "Epoch 7/50\n",
      "712/712 [==============================] - 0s 656us/sample - loss: 535.6976 - mae: 19.3436 - val_loss: 364.0445 - val_mae: 15.3625\n",
      "Epoch 8/50\n",
      "712/712 [==============================] - 0s 688us/sample - loss: 408.7398 - mae: 16.2620 - val_loss: 326.6343 - val_mae: 14.1488\n",
      "Epoch 9/50\n",
      "712/712 [==============================] - 0s 643us/sample - loss: 373.6763 - mae: 15.0902 - val_loss: 279.2300 - val_mae: 12.7669\n",
      "Epoch 10/50\n",
      "712/712 [==============================] - 0s 638us/sample - loss: 379.4256 - mae: 14.8050 - val_loss: 278.9329 - val_mae: 12.7705\n",
      "Epoch 11/50\n",
      "712/712 [==============================] - 0s 640us/sample - loss: 358.5481 - mae: 14.5237 - val_loss: 272.0129 - val_mae: 12.5974\n",
      "Epoch 12/50\n",
      "712/712 [==============================] - 0s 635us/sample - loss: 365.0520 - mae: 14.6768 - val_loss: 263.2291 - val_mae: 12.4574\n",
      "Epoch 13/50\n",
      "712/712 [==============================] - 0s 645us/sample - loss: 367.9121 - mae: 14.6847 - val_loss: 269.6470 - val_mae: 12.6825\n",
      "Epoch 14/50\n",
      "712/712 [==============================] - 0s 632us/sample - loss: 341.1647 - mae: 13.9557 - val_loss: 278.7103 - val_mae: 12.9182\n",
      "Epoch 15/50\n",
      "712/712 [==============================] - 0s 632us/sample - loss: 338.7157 - mae: 14.0089 - val_loss: 268.6409 - val_mae: 12.9527\n",
      "Epoch 16/50\n",
      "712/712 [==============================] - 0s 636us/sample - loss: 350.8103 - mae: 14.1497 - val_loss: 256.0694 - val_mae: 12.3727\n",
      "Epoch 17/50\n",
      "712/712 [==============================] - 0s 622us/sample - loss: 328.5805 - mae: 13.7168 - val_loss: 255.9881 - val_mae: 12.4086\n",
      "Epoch 18/50\n",
      "712/712 [==============================] - 0s 628us/sample - loss: 351.8270 - mae: 14.3056 - val_loss: 275.6522 - val_mae: 13.6904\n",
      "Epoch 19/50\n",
      "712/712 [==============================] - 0s 619us/sample - loss: 330.1302 - mae: 14.0247 - val_loss: 270.2962 - val_mae: 13.4397\n",
      "Epoch 20/50\n",
      "712/712 [==============================] - 0s 625us/sample - loss: 322.2197 - mae: 13.5832 - val_loss: 263.5647 - val_mae: 12.4273\n",
      "Epoch 21/50\n",
      "712/712 [==============================] - 0s 625us/sample - loss: 314.6098 - mae: 13.3905 - val_loss: 248.3864 - val_mae: 12.0078\n",
      "Epoch 22/50\n",
      "712/712 [==============================] - 0s 635us/sample - loss: 314.0190 - mae: 13.2256 - val_loss: 260.8048 - val_mae: 12.7623\n",
      "Epoch 23/50\n",
      "712/712 [==============================] - 0s 628us/sample - loss: 308.4672 - mae: 13.2338 - val_loss: 258.4122 - val_mae: 12.5884\n",
      "Epoch 24/50\n",
      "712/712 [==============================] - 0s 611us/sample - loss: 318.0907 - mae: 13.4848 - val_loss: 257.9886 - val_mae: 12.7613\n",
      "Epoch 25/50\n",
      "712/712 [==============================] - 0s 573us/sample - loss: 312.9884 - mae: 13.3809 - val_loss: 255.5279 - val_mae: 12.5693\n",
      "Epoch 26/50\n",
      "712/712 [==============================] - 0s 590us/sample - loss: 311.1986 - mae: 13.2599 - val_loss: 252.5974 - val_mae: 12.3488\n",
      "Epoch 27/50\n",
      "712/712 [==============================] - 0s 577us/sample - loss: 306.1682 - mae: 13.0822 - val_loss: 258.1215 - val_mae: 12.4107\n",
      "Epoch 28/50\n",
      "712/712 [==============================] - 0s 577us/sample - loss: 308.2046 - mae: 13.2098 - val_loss: 260.1779 - val_mae: 12.4450\n",
      "Epoch 29/50\n",
      "712/712 [==============================] - 0s 579us/sample - loss: 317.8321 - mae: 13.4323 - val_loss: 265.4330 - val_mae: 13.1704\n",
      "Epoch 30/50\n",
      "712/712 [==============================] - 0s 590us/sample - loss: 304.1569 - mae: 13.1052 - val_loss: 263.7641 - val_mae: 13.0781\n",
      "Epoch 31/50\n",
      "712/712 [==============================] - 0s 573us/sample - loss: 302.7109 - mae: 12.8960 - val_loss: 268.8432 - val_mae: 13.2866\n",
      "Epoch 32/50\n",
      "712/712 [==============================] - 0s 574us/sample - loss: 321.9402 - mae: 13.5660 - val_loss: 259.9092 - val_mae: 12.7424\n",
      "Epoch 33/50\n",
      "712/712 [==============================] - 0s 573us/sample - loss: 297.7297 - mae: 13.0087 - val_loss: 268.9233 - val_mae: 12.6696\n",
      "Epoch 34/50\n",
      "712/712 [==============================] - 0s 581us/sample - loss: 309.4910 - mae: 13.2532 - val_loss: 262.9938 - val_mae: 12.8078\n",
      "Epoch 35/50\n",
      "712/712 [==============================] - 0s 576us/sample - loss: 299.5578 - mae: 12.8968 - val_loss: 260.1813 - val_mae: 12.7709\n",
      "Epoch 36/50\n",
      "712/712 [==============================] - 0s 583us/sample - loss: 298.1179 - mae: 12.7136 - val_loss: 262.6743 - val_mae: 12.9070\n",
      "Epoch 37/50\n",
      "712/712 [==============================] - 0s 563us/sample - loss: 291.9392 - mae: 12.7527 - val_loss: 257.8755 - val_mae: 12.4927\n",
      "Epoch 38/50\n",
      "712/712 [==============================] - 0s 563us/sample - loss: 295.3561 - mae: 12.8039 - val_loss: 261.0217 - val_mae: 12.5608\n",
      "Epoch 39/50\n",
      "712/712 [==============================] - 0s 563us/sample - loss: 284.1298 - mae: 12.4395 - val_loss: 258.7287 - val_mae: 12.4584\n",
      "Epoch 40/50\n",
      "712/712 [==============================] - 0s 567us/sample - loss: 295.7607 - mae: 12.8490 - val_loss: 255.1396 - val_mae: 11.9750\n",
      "Epoch 41/50\n",
      "712/712 [==============================] - 0s 570us/sample - loss: 312.9570 - mae: 13.1308 - val_loss: 263.6843 - val_mae: 12.6205\n",
      "Epoch 42/50\n",
      "712/712 [==============================] - 0s 565us/sample - loss: 294.5280 - mae: 12.8651 - val_loss: 263.6406 - val_mae: 12.7575\n",
      "Epoch 43/50\n",
      "712/712 [==============================] - 0s 563us/sample - loss: 292.7835 - mae: 12.7868 - val_loss: 268.2961 - val_mae: 13.1123\n",
      "Epoch 44/50\n",
      "712/712 [==============================] - 0s 565us/sample - loss: 289.9429 - mae: 12.6848 - val_loss: 264.2735 - val_mae: 12.7828\n",
      "Epoch 45/50\n",
      "712/712 [==============================] - 0s 573us/sample - loss: 287.0865 - mae: 12.6068 - val_loss: 279.2245 - val_mae: 13.6533\n",
      "Epoch 46/50\n",
      "712/712 [==============================] - 0s 576us/sample - loss: 278.3182 - mae: 12.3858 - val_loss: 255.4332 - val_mae: 12.5699\n",
      "Epoch 47/50\n",
      "712/712 [==============================] - 0s 576us/sample - loss: 282.5877 - mae: 12.4814 - val_loss: 260.4657 - val_mae: 12.7478\n",
      "Epoch 48/50\n",
      "712/712 [==============================] - 0s 591us/sample - loss: 288.5775 - mae: 12.8038 - val_loss: 263.4545 - val_mae: 12.9631\n",
      "Epoch 49/50\n",
      "712/712 [==============================] - 0s 577us/sample - loss: 268.2309 - mae: 12.2353 - val_loss: 249.2636 - val_mae: 12.2915\n",
      "Epoch 50/50\n",
      "712/712 [==============================] - 0s 590us/sample - loss: 255.8286 - mae: 12.0383 - val_loss: 253.7009 - val_mae: 12.7721\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_9 (Conv1D)            multiple                  374       \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  multiple                  73350     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             multiple                  22650     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             multiple                  151       \n",
      "=================================================================\n",
      "Total params: 96,525\n",
      "Trainable params: 96,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.fit(dataSplitTrain, targetSplitTrain, epochs=50, verbose=1, validation_data=(dataSplitVal,targetSplitVal))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('saved_model/final_model')\n",
    "# model_json = model.to_json()\n",
    "# with open(\"./model.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "# # serialize weights to HDF5\n",
    "# model.save_weights(\"model.h5\")\n",
    "# print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"./valData.npy\", simsTest)\n",
    "# np.save(\"./valTarget.npy\", targetTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import tempfile\n",
    "# import os\n",
    "\n",
    "# MODEL_DIR = tempfile.gettempdir()\n",
    "# version = 1\n",
    "# export_path = os.path.join(MODEL_DIR, str(version))\n",
    "# print('export_path = {}\\n'.format(export_path))\n",
    "\n",
    "# tf.keras.models.save_model(\n",
    "#     model,\n",
    "#     export_path,\n",
    "#     overwrite=True,\n",
    "#     include_optimizer=True,\n",
    "#     save_format=None,\n",
    "#     signatures=None,\n",
    "#     options=None\n",
    "# )\n",
    "\n",
    "# print('\\nSaved model:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "\n",
    "# export_path_base = sys.argv[-1]\n",
    "# export_path = os.path.join(\n",
    "#       tf.compat.as_bytes(export_path_base),\n",
    "#       tf.compat.as_bytes('1'))\n",
    "# print('Exporting trained model to', export_path)\n",
    "# builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "# builder.add_meta_graph_and_variables(\n",
    "#       sess, [tf.saved_model.tag_constants.SERVING],\n",
    "#       signature_def_map={\n",
    "#            'predict_images':\n",
    "#                prediction_signature,\n",
    "#            signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n",
    "#                classification_signature,\n",
    "#       },\n",
    "#       main_op=tf.tables_initializer())\n",
    "# builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(model, \"/tmp/finalModel/1/\", save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.experimental.export_saved_model(model,'saved_model/3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /saved_model/1/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, '/saved_model/1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
