{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math as mt\n",
    "import random as rng\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the initial loading of the data. Cycle column is used as the labels, otherwise the simulation number and input variable columns are dropped. Also load the test dataset available in case we want to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Get a range of the column values so they can be used as the column names\n",
    "def getColumns(size):\n",
    "    columns = []\n",
    "    for i in range(size):\n",
    "        columns.append(i)\n",
    "    return columns\n",
    "\n",
    "def initialLoad(directory):\n",
    "    #Read the csv file, discard the null columns\n",
    "    turbo = pd.read_csv(directory, header=None, sep=' ')\n",
    "    turbo = turbo.drop([26, 27], axis=1)\n",
    "    #Drop the simulation and cycle count from the data\n",
    "    turboSens = turbo.drop([0,1,2,3,4], axis=1)\n",
    "    turboSens.columns = getColumns(turboSens.shape[1])\n",
    "    return turbo, turboSens\n",
    "\n",
    "\n",
    "#Read the csv file, discard the null columns\n",
    "directory = \"../CMAPSSData/train_FD001.txt\"\n",
    "directoryTest = \"../CMAPSSData/test_FD001.txt\"\n",
    "directoryTestExtra = \"../CMAPSSData/RUL_FD001.txt\"\n",
    "\n",
    "turbo,turboSens = initialLoad(directory)\n",
    "\n",
    "valTurbo,valSens = initialLoad(directoryTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#minVals = []\n",
    "#maxVals = []\n",
    "# Get the minimum and maximum value of each column and store them in minVals and maxVals respectively\n",
    "#for i in range(len(turboSens.columns)):\n",
    "#    minVals.append(turboSens[i].min())\n",
    "#    maxVals.append(turboSens[i].max())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather the cycle numbers for the dataset and convert them into labels for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "turboUsefulSens = turboSens\n",
    "valUsefulSens = valSens\n",
    "\n",
    "turboNp = turboUsefulSens.to_numpy()\n",
    "valNp = valUsefulSens.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the number of cycles for each simulation, and split each simulation\n",
    "maxCycles = []\n",
    "simCount = 100\n",
    "\n",
    "def getTargets(cycleList, count):\n",
    "    simulations = []\n",
    "    current = 0\n",
    "    for i in range(simCount):\n",
    "        sim = [cycleList[current]]\n",
    "        current += 1\n",
    "        while current < len(cycleList):\n",
    "            if(cycleList[current]==1):\n",
    "                break\n",
    "            sim.append(cycleList[current])\n",
    "            current+=1\n",
    "        simulations.append(sim)\n",
    "    return simulations\n",
    "\n",
    "simulations = getTargets(turbo[1], simCount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "#Get the lowest cycle max\n",
    "maxCycles = []\n",
    "for i in simulations:\n",
    "    maxCycles.append(max(i))\n",
    "    \n",
    "print(min(maxCycles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flip the cycle counts so they represent deterioration instead of incrementing(decrementing from total cycles to 0 instead of incrementing from 0 to total cycles)\n",
    "simulationsRev = []\n",
    "for sim in simulations:\n",
    "    simRev = []\n",
    "    maxSim = max(sim)\n",
    "    for i in sim:\n",
    "        simRev.append(maxSim - i)\n",
    "    simulationsRev.append(simRev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = []\n",
    "for sim in simulationsRev:\n",
    "    for item in sim:\n",
    "        flat_list.append(item)\n",
    "        \n",
    "flatNp = np.array(flat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data for the next stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Train\", turboNp)\n",
    "np.save(\"TrainTarget\", flatNp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same process for the test data in case we want to use it. takes a few extra steps since the labels need another file to mark the RUL when it stops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valTargets = getTargets(valTurbo[1],simCount)\n",
    "file = open(directoryTestExtra, 'r')\n",
    "\n",
    "valTargetRev = []\n",
    "for sim in valTargets:\n",
    "    rev = []\n",
    "    maxCount = max(sim)\n",
    "    extra = int(file.readline())\n",
    "    for i in sim:\n",
    "        rev.append(maxCount - i + extra)\n",
    "    valTargetRev.append(rev)\n",
    "file.close()\n",
    "\n",
    "flat_val = []\n",
    "for sim in valTargetRev:\n",
    "    for item in sim:\n",
    "        flat_val.append(item)\n",
    "        \n",
    "        \n",
    "valTargNp = np.array(flat_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Validate\", valNp)\n",
    "np.save(\"ValidateTarget\", valTargNp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also put all the data in the same file in case we want to use all the data combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33727\n",
      "33727\n"
     ]
    }
   ],
   "source": [
    "allSensNp = np.append(turboNp, valNp, axis=0)\n",
    "allTargNp = np.append(flatNp, valTargNp)\n",
    "\n",
    "print(len(allSensNp))\n",
    "print(len(allTargNp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"all\", allSensNp)\n",
    "np.save(\"allTarget\", allTargNp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
