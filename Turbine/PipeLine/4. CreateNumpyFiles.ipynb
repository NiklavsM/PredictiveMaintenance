{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data must now be shaped so that it can be used in the neural network. This is the same shape as the the turbofan i.e. multiple rows of sequential sensor data, in this case 60 cycles instead of 30. The data is saved in batches so that during training 1 file can easily be loaded and used as a single batch. Each batch file in this case contains 32 instances of model data(with each instance containing 60 cycles). The data is just sampled at a step rate of 60 since there is enough data as is.\n",
    "\n",
    "\n",
    "First change directories and specify the folders needed to write to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob,os\n",
    "import pickle\n",
    "\n",
    "dir = \"D:\\\\WindData\\\\POD_Request_3541\\\\Project\\\\processed\\\\trimmed\"\n",
    "\n",
    "os.chdir(dir)\n",
    "\n",
    "if not os.path.exists('final'):\n",
    "    os.makedirs('final')\n",
    "if not os.path.exists('final/data'):\n",
    "        os.makedirs('final/data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note down the data files and label files which will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['labels\\\\0.csv', 'labels\\\\1.csv', 'labels\\\\10.csv', 'labels\\\\11.csv', 'labels\\\\12.csv', 'labels\\\\13.csv', 'labels\\\\14.csv', 'labels\\\\15.csv', 'labels\\\\16.csv', 'labels\\\\2.csv', 'labels\\\\3.csv', 'labels\\\\4.csv', 'labels\\\\5.csv', 'labels\\\\6.csv', 'labels\\\\7.csv', 'labels\\\\8.csv', 'labels\\\\9.csv']\n"
     ]
    }
   ],
   "source": [
    "labels = glob.glob(\"labels/*.csv\")\n",
    "dataSets = glob.glob(\"data/*.csv\")\n",
    "print(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for creating a new batch of data. Here the skiprows and nrows attributes are used to carve out specific parts of the data. When there is not enough data for a batch it returns an empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullBatch(numBatches, batchSize, depth, labelFile, dataFile):\n",
    "    dataList = []\n",
    "    avgList = []\n",
    "    skip = numBatches * batchSize * depth\n",
    "    for i in range(batchSize):\n",
    "        frameData = pd.read_csv(dataFile, header=None, skiprows=skip, nrows=depth)\n",
    "        if len(frameData) < depth:\n",
    "            return [], 0\n",
    "        else:\n",
    "            avgData = pd.read_csv(labelFile, header=None, skiprows=skip, nrows=depth)\n",
    "            avg = avgData[0].mean()\n",
    "            avgList.append(avg)\n",
    "            dataList.append(frameData.values.tolist())\n",
    "            skip += depth\n",
    "    return dataList, avgList\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch size and number of cycles per instance is specified. The labels are also saved into one big list.\n",
    "\n",
    "The loop takes every data/label file pair and makes as many batches batches as possible. The data from each batch is saved in its own file, while the labels are put into the label list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN found\n",
      "NaN found\n",
      "NaN found\n",
      "NaN found\n",
      "NaN found\n",
      "Round done\n",
      "NaN found\n",
      "Round done\n",
      "Round done\n",
      "Round done\n",
      "Round done\n",
      "Round done\n",
      "Round done\n",
      "Round done\n",
      "Round done\n",
      "Round done\n",
      "Round done\n",
      "Round done\n",
      "NaN found\n",
      "NaN found\n",
      "NaN found\n",
      "NaN found\n",
      "Round done\n",
      "NaN found\n",
      "NaN found\n",
      "NaN found\n",
      "NaN found\n",
      "NaN found\n",
      "NaN found\n",
      "Round done\n",
      "Round done\n",
      "Round done\n",
      "Round done\n"
     ]
    }
   ],
   "source": [
    "batchSize = 32\n",
    "depth = 60\n",
    "labelList = []\n",
    "batchCount = 0\n",
    "\n",
    "for label, data in zip(labels, dataSets):\n",
    "    numBatches = 0\n",
    "    batch, avgList = pullBatch(numBatches, batchSize, depth, label, data)\n",
    "    while not len(batch)==0:\n",
    "        npArray = np.array(batch)\n",
    "        if not np.any(np.isnan(npArray)):\n",
    "            labelList.append(avgList)\n",
    "            np.save(\"final/data/\" + str(batchCount) + \".npy\", npArray)\n",
    "        else:\n",
    "            print(\"NaN found\")\n",
    "        numBatches+=1\n",
    "        batchCount+=1\n",
    "        batch, avgList = pullBatch(numBatches, batchSize, depth, label, data)\n",
    "    print(\"Round done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frame = pd.DataFrame(labelList, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the list of labels as a pickle so that it can easily be loaded for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(labelList, open(\"./final/labels.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
