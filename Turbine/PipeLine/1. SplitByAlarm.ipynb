{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 1- splitting the data based on the on/off times of each alarm instance\n",
    "\n",
    "Change directories, specify the necessary new folder locations and get the list of csv files for the turbine data. Files are opened and read manually instead of loading in since they are too large for memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Copies\\\\LDT-1Hz-01-January.csv', 'Copies\\\\LDT-1Hz-02-February.csv', 'Copies\\\\LDT-1Hz-03-March.csv', 'Copies\\\\LDT-1Hz-04-April.csv', 'Copies\\\\LDT-1Hz-05-May.csv', 'Copies\\\\LDT-1Hz-06-June.csv', 'Copies\\\\LDT-1Hz-07-July.csv', 'Copies\\\\LDT-1Hz-08.csv', 'Copies\\\\LDT-1Hz-09-September.csv', 'Copies\\\\LDT-1Hz-Tur-2017-10.csv', 'Copies\\\\LDT-1Hz-Tur-2017-11.csv', 'Copies\\\\LDT-1Hz-Tur-2017-12.csv', 'Copies\\\\LDT-1Hz-Tur-2018-01.csv', 'Copies\\\\LDT-1Hz-Tur-2018-02.csv', 'Copies\\\\LDT-1Hz-Tur-2018-03.csv', 'Copies\\\\LDT-1Hz-Tur-2018-04.csv', 'Copies\\\\LDT-1Hz-Tur-2018-05.csv', 'Copies\\\\LDT-1Hz-Tur-2018-06.csv', 'Copies\\\\LDT-1Hz-Tur-2018-07.csv', 'Copies\\\\LDT-1Hz-Tur-2018-08.csv', 'Copies\\\\LDT-1Hz-Tur-2018-09.csv', 'Copies\\\\LDT-1Hz-Tur-2018-10.csv', 'Copies\\\\LDT-1Hz-Tur-2018-11.csv', 'Copies\\\\LDT-1Hz-Tur-2018-12.csv', 'Copies\\\\LDT-1Hz-Tur-2019-01.csv', 'Copies\\\\LDT-1Hz-Tur-2019-02.csv', 'Copies\\\\LDT-1Hz-Tur-2019-03.csv', 'Copies\\\\LDT-1Hz-Tur-2019-05.csv', 'Copies\\\\LDT-1Hz-Tur-2019-06.csv', 'Copies\\\\LDT-1Hz-Tur-2019-07.csv', 'Copies\\\\LDT-1Hz-Tur-2019-08.csv', 'Copies\\\\LDT-1Hz-Tur-2019-09.csv']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob,os\n",
    "\n",
    "\n",
    "dir = \"D:/WindData/POD_Request_3541/Project\"\n",
    "\n",
    "os.chdir(dir)\n",
    "if not os.path.exists('processed'):\n",
    "    os.makedirs('processed')\n",
    "\n",
    "names = glob.glob(\"Copies/*.csv\")\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the list of alarms you want to seperate your data based on. Then create a list of on and off times for the alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alarms = pd.read_csv(\"Alarms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ons = alarms['On'].to_list()\n",
    "offs = alarms['Off'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['18/02/2017 07:12', '08/03/2017 16:30', '17/03/2017 18:51', '24/03/2017 09:10', '24/03/2017 22:30', '16/11/2017 17:43', '21/05/2018 06:16', '22/05/2018 06:17', '23/05/2018 06:16', '24/05/2018 06:21', '25/05/2018 06:06', '28/05/2018 06:07', '29/05/2018 06:12', '30/05/2018 06:24', '31/05/2018 06:16', '01/06/2018 06:18', '04/06/2018 06:22']\n",
      "['23/02/2017 16:08', '17/03/2017 15:42', '23/03/2017 15:30', '24/03/2017 15:20', '25/03/2017 00:45', '18/12/2017 00:00', '21/05/2018 18:04', '22/05/2018 18:13', '23/05/2018 18:12', '24/05/2018 18:11', '25/05/2018 14:08', '28/05/2018 18:16', '29/05/2018 17:48', '30/05/2018 18:30', '31/05/2018 17:26', '01/06/2018 14:05', '04/06/2018 17:08']\n"
     ]
    }
   ],
   "source": [
    "print(ons)\n",
    "print(offs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Copies\\\\LDT-1Hz-01-January.csv\"\n",
    "file = open(name,'r')\n",
    "columns = file.readline()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the functions needed to iterate through the datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fileList = []\n",
    "currentFile = 0\n",
    "\n",
    "#Read a new line of data, if the file is empty load a new file and read again. Retrun the line of data and the current file\n",
    "def iterateLine(file):\n",
    "    global currentFile\n",
    "    line = file.readline()\n",
    "    if(line==\"\"):\n",
    "        file.close()\n",
    "        currentFile+=1\n",
    "        file = open(fileList[currentFile], 'r')\n",
    "        file.readline()\n",
    "        line = file.readline()\n",
    "    return file, line\n",
    "#Read a new line of data, if the file is empty load a new file and read again. Discard the line of data and return the current file\n",
    "def deleteLine(file):\n",
    "    global currentFile\n",
    "    line = file.readline()\n",
    "    if(line==\"\"):\n",
    "        file.close()\n",
    "        currentFile+=1\n",
    "        file = open(fileList[currentFile], 'r')\n",
    "        file.readline()\n",
    "        file.readline()\n",
    "    return file\n",
    "\n",
    "#Convert the dataline time and date format so it matches the alarm time and date format\n",
    "def getExactTime(line):\n",
    "    exact = line.split(\",\")[0]\n",
    "    split = exact.split()\n",
    "    date, time = split[0], split[1]\n",
    "    dateSplit = date.split(\"-\")\n",
    "    dateFix = dateSplit[2] + \"/\" + dateSplit[1] + \"/\" + dateSplit[0]\n",
    "    return dateFix + \" \" + time\n",
    "\n",
    "\n",
    "# Check if the date and time for the data matches the date and time for the alarm\n",
    "def timeMatches(dataLine, alarmLine):\n",
    "    fixedDataLine = getExactTime(dataLine)\n",
    "    if alarmLine in fixedDataLine:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "alarmLine = \"18/02/2017 07:12\"\n",
    "line = \"2017-02-17 07:12:00.608\"\n",
    "print(timeMatches(line,alarmLine))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep track of the line counts of each new file generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineCounts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Core split by alarm loop. The function is given a list of places it can read and write to, as well as the alarm on and off times it is searching for. It splits the data it can read from based on the alarm on/off times and puts the data in the write locations. There is one file generated for every alarm occurrence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMySplits(writePaths, ons, offs, dataLine, readFile):\n",
    "    for (writePath, on, off) in zip(writePaths, ons, offs):\n",
    "        writeFile = open(writePath, 'w')\n",
    "        writeFile.write(columns)\n",
    "        lineCount = 0\n",
    "        while timeMatches(dataLine, on):\n",
    "            writeFile.write(dataLine)\n",
    "            readFile,dataLine = iterateLine(readFile)\n",
    "            lineCount+=1\n",
    "        print(\"First round done\")\n",
    "        while timeMatches(dataLine, off):\n",
    "            readFile, dataLine = iterateLine(readFile)\n",
    "        print(\"Found All offlines\")\n",
    "        while not timeMatches(dataLine, off):\n",
    "            readFile,dataLine = iterateLine(readFile)\n",
    "        print(\"Resetting\")\n",
    "        writeFile.close()\n",
    "        lineCounts.append(lineCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the available writeto files based on how many alarm instances there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeDir = \"./processed/\"\n",
    "writePaths = []\n",
    "for i in range(len(ons)):\n",
    "    pathVal = writeDir + str(i) + \".csv\"\n",
    "    writePaths.append(pathVal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customise createMySplits search. This is done so that excess data is never searched- e.g. sometimes the alarm might not occur for months, causing the function to search through months of second-to-second data, and all those months of data will end up in one file as it is the data leading up to one alarm instance. The createMySplits function can still be run on the whole dataset at once instead of customising it, it just takes much longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "onGroups = [ons[0:5], ons[5:6], ons[6:]]\n",
    "offGroups = [offs[0:5], offs[5:6], offs[6:]]\n",
    "writePathGroups = [writePaths[0:5], writePaths[5:6], writePaths[6:]]\n",
    "readPathGroups = [names[1:3], names[10:12], names[16:18]]\n",
    "#print(readPathGroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for (onGroup, offGroup, writePathGroup, readPathGroup) in zip(onGroups, offGroups, writePathGroups, readPathGroups):\n",
    "#    print(onGroup)\n",
    "#    print(offGroup)\n",
    "#    print(writePathGroup)\n",
    "#    print(readPathGroup)\n",
    "#    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First round done\n",
      "Found All offlines\n",
      "Resetting\n",
      "First round done\n",
      "Found All offlines\n",
      "Resetting\n",
      "First round done\n",
      "Found All offlines\n",
      "Resetting\n",
      "First round done\n",
      "Found All offlines\n",
      "Resetting\n",
      "First round done\n",
      "Found All offlines\n",
      "Resetting\n",
      "First round done\n",
      "Found All offlines\n",
      "Resetting\n",
      "First round done\n",
      "Found All offlines\n",
      "Resetting\n",
      "First round done\n",
      "Found All offlines\n",
      "Resetting\n",
      "First round done\n",
      "Found All offlines\n",
      "Resetting\n",
      "First round done\n",
      "Found All offlines\n",
      "Resetting\n",
      "First round done\n",
      "Found All offlines\n",
      "Resetting\n",
      "First round done\n",
      "Found All offlines\n",
      "Resetting\n",
      "First round done\n",
      "Found All offlines\n",
      "Resetting\n",
      "First round done\n",
      "Found All offlines\n",
      "Resetting\n",
      "First round done\n",
      "Found All offlines\n",
      "Resetting\n",
      "First round done\n",
      "Found All offlines\n",
      "Resetting\n",
      "First round done\n",
      "Found All offlines\n",
      "Resetting\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for (onGroup, offGroup, writePathGroup, readPathGroup) in zip(onGroups, offGroups, writePathGroups, readPathGroups):\n",
    "    currentFile = 0\n",
    "    fileList = readPathGroup\n",
    "    openFile = open(fileList[0], 'r')\n",
    "    openFile.readline()\n",
    "    openFile.readline()\n",
    "    dataLine = openFile.readline()\n",
    "    createMySplits(writePathGroup, onGroup, offGroup, dataLine, openFile)\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
