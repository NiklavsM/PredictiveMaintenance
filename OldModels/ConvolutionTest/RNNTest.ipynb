{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#print(tf.keras.__version__)\n",
    "#print(tf.__version__)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math as mt\n",
    "import random as rng\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def getColumns(size):\n",
    "    columns = []\n",
    "    for i in range(size):\n",
    "        columns.append(i)\n",
    "    return columns\n",
    "\n",
    "directory = \"./CMAPSSData/train_FD001.txt\"\n",
    "turbo = pd.read_csv(directory, header=None, sep=' ')\n",
    "turbo = turbo.drop([26, 27], axis=1)\n",
    "\n",
    "#for i in turbo.columns:\n",
    "#    column = turbo[i]\n",
    "#    print(i)\n",
    "#    print(column.describe())\n",
    "    \n",
    "#print(turbo.values)\n",
    "\n",
    "# Drop the input parameters to get just the sensors\n",
    "turboSens = turbo.drop([0,1], axis=1)\n",
    "turboSens.columns = getColumns(turboSens.shape[1])\n",
    "\n",
    "# Get the cycles and useful sensors. \n",
    "turboUsefulSens = turboSens\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "norm_sens = min_max_scaler.fit_transform(turboUsefulSens)\n",
    "\n",
    "turboCycles = turbo[1]\n",
    "#print(turboCycles)\n",
    "\n",
    "deteriorate = []\n",
    "maxCycle = float(turboCycles.max())\n",
    "\n",
    "currentCount = maxCycle\n",
    "for i in range(turbo.shape[0] - 1, -1, -1):\n",
    "    currentRow = turboCycles.loc[i]\n",
    "    deteriorate.insert(0, currentCount)\n",
    "    if currentRow == 1:\n",
    "        currentCount = maxCycle\n",
    "    else:\n",
    "        currentCount -= 1\n",
    "\n",
    "        \n",
    "deteriorate = pd.DataFrame(deteriorate)\n",
    "\n",
    "deteriorateSwap = []\n",
    "for i in deteriorate[0]:\n",
    "    deteriorateSwap.append(maxCycle - i)\n",
    "deteriorate = pd.DataFrame(deteriorateSwap)\n",
    "\n",
    "\n",
    "norm_sens = pd.DataFrame(norm_sens)\n",
    "deteriorate = deteriorate.join(norm_sens, lsuffix='0', rsuffix='1')\n",
    "deteriorate.columns = getColumns(deteriorate.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = deteriorate.to_numpy()\n",
    "\n",
    "arrayCopy = array.tolist()\n",
    "\n",
    "simulations = []\n",
    "\n",
    "convCount = 10\n",
    "convDiv = int(convCount/2)\n",
    "\n",
    "count = len(array)\n",
    "\n",
    "while(count > 0):\n",
    "    cycles = []\n",
    "    element = [-1,-1]\n",
    "    while(element[0]!=0):\n",
    "        element = arrayCopy.pop(0)\n",
    "        cycles.append(element)\n",
    "        count-=1\n",
    "    simulations.append(cycles)\n",
    "    \n",
    "#for sim in simulations:\n",
    "#    lenth = len(sim)\n",
    "#    remainder = lenth%convCount\n",
    "#    for i in range(remainder):\n",
    "#        sim.pop(0)\n",
    "    \n",
    "#simsRecomb = []\n",
    "#for sim in simulations:\n",
    "#    for i in sim:\n",
    "#        simsRecomb.append(i)\n",
    "\n",
    "#print(len(simsRecomb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19631\n",
      "19631\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tens = []\n",
    "tensCount = []\n",
    "\n",
    "for sim in simulations:\n",
    "    for i in range(convDiv, len(sim) - convDiv):\n",
    "        ten = []\n",
    "        total = 0\n",
    "        for j in range(-convDiv,convDiv):\n",
    "            index = i + j\n",
    "            element = sim[index].copy()\n",
    "            total+= element.pop(0)\n",
    "            ten.append(element)\n",
    "        total/=convCount\n",
    "        tensCount.append(total)\n",
    "        tens.append(ten)\n",
    "\n",
    "    \n",
    "print(len(tens))\n",
    "print(len(tensCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "simsReorder = []\n",
    "simsCycleReorder = []\n",
    "\n",
    "length = len(tens)\n",
    "for i in range(length):\n",
    "    index = rng.randint(0, len(tens)-1)\n",
    "    simsReorder.append(tens.pop(index))\n",
    "    simsCycleReorder.append(tensCount.pop(index))\n",
    "    \n",
    "    \n",
    "    \n",
    "simsTrain = simsReorder[:15704]\n",
    "targetTrain = simsCycleReorder[:15704]\n",
    "\n",
    "simsTest = simsReorder[15704:]\n",
    "targetTest = simsCycleReorder[15704:]\n",
    "\n",
    "\n",
    "\n",
    "width = (turboUsefulSens.shape[1])\n",
    "print(len(simsTrain[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 8, 150)            10950     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 6, 300)            135300    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 300)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1, 300)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 400)               1121600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               40100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 2,029,251\n",
      "Trainable params: 2,029,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(150, 3, activation='relu', input_shape=(convCount, width)),\n",
    "    tf.keras.layers.Conv1D(300, 3, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.MaxPooling1D(6),\n",
    "    tf.keras.layers.LSTM(300, return_sequences=True, dropout=0.15, recurrent_dropout=0.15),\n",
    "    tf.keras.layers.LSTM(400, dropout=0.15, recurrent_dropout=0.15),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "              loss='mse', \n",
    "              metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15704 samples, validate on 3927 samples\n",
      "Epoch 1/500\n",
      "15704/15704 [==============================] - 22s 1ms/sample - loss: 127.8485 - mae: 7.6021 - mse: 127.8485 - val_loss: 186.1679 - val_mae: 8.6957 - val_mse: 186.1679\n",
      "Epoch 2/500\n",
      "15704/15704 [==============================] - 21s 1ms/sample - loss: 134.0935 - mae: 7.7305 - mse: 134.0936 - val_loss: 190.7431 - val_mae: 8.7175 - val_mse: 190.7430\n",
      "Epoch 3/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 133.8280 - mae: 7.6515 - mse: 133.8280 - val_loss: 199.5897 - val_mae: 8.9661 - val_mse: 199.5897\n",
      "Epoch 4/500\n",
      "15704/15704 [==============================] - 20s 1ms/sample - loss: 121.3706 - mae: 7.4765 - mse: 121.3707 - val_loss: 192.9741 - val_mae: 9.0907 - val_mse: 192.9741\n",
      "Epoch 5/500\n",
      "15704/15704 [==============================] - 21s 1ms/sample - loss: 123.4847 - mae: 7.5037 - mse: 123.4848 - val_loss: 211.1814 - val_mae: 9.1823 - val_mse: 211.1815\n",
      "Epoch 6/500\n",
      "15704/15704 [==============================] - 20s 1ms/sample - loss: 136.5614 - mae: 7.6929 - mse: 136.5614 - val_loss: 206.2906 - val_mae: 9.0798 - val_mse: 206.2906\n",
      "Epoch 7/500\n",
      "15704/15704 [==============================] - 21s 1ms/sample - loss: 125.5829 - mae: 7.4739 - mse: 125.5828 - val_loss: 187.2833 - val_mae: 8.8297 - val_mse: 187.2833\n",
      "Epoch 8/500\n",
      "15704/15704 [==============================] - 22s 1ms/sample - loss: 124.1279 - mae: 7.4942 - mse: 124.1279 - val_loss: 143.3615 - val_mae: 7.5901 - val_mse: 143.3615\n",
      "Epoch 9/500\n",
      "15704/15704 [==============================] - 20s 1ms/sample - loss: 119.1215 - mae: 7.3945 - mse: 119.1215 - val_loss: 151.7033 - val_mae: 7.6939 - val_mse: 151.7033\n",
      "Epoch 10/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 114.4760 - mae: 7.2856 - mse: 114.4761 - val_loss: 153.1698 - val_mae: 7.8151 - val_mse: 153.1698\n",
      "Epoch 11/500\n",
      "15704/15704 [==============================] - 20s 1ms/sample - loss: 124.8778 - mae: 7.5286 - mse: 124.8778 - val_loss: 158.8945 - val_mae: 8.2098 - val_mse: 158.8945\n",
      "Epoch 12/500\n",
      "15704/15704 [==============================] - 20s 1ms/sample - loss: 119.0059 - mae: 7.3877 - mse: 119.0059 - val_loss: 167.5472 - val_mae: 8.2351 - val_mse: 167.5472\n",
      "Epoch 13/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 139.1621 - mae: 7.6769 - mse: 139.1622 - val_loss: 151.8164 - val_mae: 7.9924 - val_mse: 151.8164\n",
      "Epoch 14/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 117.3225 - mae: 7.3243 - mse: 117.3225 - val_loss: 175.7627 - val_mae: 8.5702 - val_mse: 175.7627\n",
      "Epoch 15/500\n",
      "15704/15704 [==============================] - 20s 1ms/sample - loss: 128.9605 - mae: 7.4552 - mse: 128.9604 - val_loss: 172.3028 - val_mae: 8.1973 - val_mse: 172.3028\n",
      "Epoch 16/500\n",
      "15704/15704 [==============================] - 21s 1ms/sample - loss: 125.3046 - mae: 7.4547 - mse: 125.3045 - val_loss: 174.3688 - val_mae: 8.4441 - val_mse: 174.3688\n",
      "Epoch 17/500\n",
      "15704/15704 [==============================] - 20s 1ms/sample - loss: 119.5073 - mae: 7.3560 - mse: 119.5072 - val_loss: 181.2611 - val_mae: 8.7280 - val_mse: 181.2611\n",
      "Epoch 18/500\n",
      "15704/15704 [==============================] - 21s 1ms/sample - loss: 118.7028 - mae: 7.4158 - mse: 118.7028 - val_loss: 182.6711 - val_mae: 8.4995 - val_mse: 182.6712\n",
      "Epoch 19/500\n",
      "15704/15704 [==============================] - 20s 1ms/sample - loss: 129.5127 - mae: 7.5731 - mse: 129.5127 - val_loss: 171.0702 - val_mae: 8.3640 - val_mse: 171.0703\n",
      "Epoch 20/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 135.8483 - mae: 7.6586 - mse: 135.8484 - val_loss: 161.1037 - val_mae: 8.4448 - val_mse: 161.1037\n",
      "Epoch 21/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 124.4423 - mae: 7.5394 - mse: 124.4424 - val_loss: 141.4265 - val_mae: 7.8002 - val_mse: 141.4265\n",
      "Epoch 22/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 134.4918 - mae: 7.6616 - mse: 134.4917 - val_loss: 202.3190 - val_mae: 9.2577 - val_mse: 202.3190\n",
      "Epoch 23/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 134.5807 - mae: 7.6212 - mse: 134.5807 - val_loss: 193.0337 - val_mae: 8.6522 - val_mse: 193.0338\n",
      "Epoch 24/500\n",
      "15704/15704 [==============================] - 21s 1ms/sample - loss: 126.0208 - mae: 7.4920 - mse: 126.0208 - val_loss: 176.4799 - val_mae: 8.3884 - val_mse: 176.4799\n",
      "Epoch 25/500\n",
      "15704/15704 [==============================] - 20s 1ms/sample - loss: 119.6463 - mae: 7.3971 - mse: 119.6463 - val_loss: 193.4306 - val_mae: 8.7191 - val_mse: 193.4305\n",
      "Epoch 26/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 127.7119 - mae: 7.5583 - mse: 127.7118 - val_loss: 150.5446 - val_mae: 7.8842 - val_mse: 150.5446\n",
      "Epoch 27/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 128.3308 - mae: 7.5368 - mse: 128.3307 - val_loss: 175.4942 - val_mae: 9.0089 - val_mse: 175.4942\n",
      "Epoch 28/500\n",
      "15704/15704 [==============================] - 20s 1ms/sample - loss: 121.5526 - mae: 7.3764 - mse: 121.5526 - val_loss: 162.7849 - val_mae: 8.3156 - val_mse: 162.7849\n",
      "Epoch 29/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 132.6368 - mae: 7.5896 - mse: 132.6368 - val_loss: 164.0227 - val_mae: 8.1044 - val_mse: 164.0227\n",
      "Epoch 30/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 128.2317 - mae: 7.4932 - mse: 128.2316 - val_loss: 169.4253 - val_mae: 8.0098 - val_mse: 169.4253\n",
      "Epoch 31/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 125.0339 - mae: 7.5041 - mse: 125.0340 - val_loss: 151.3263 - val_mae: 8.1563 - val_mse: 151.3263\n",
      "Epoch 32/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 129.8111 - mae: 7.5308 - mse: 129.8112 - val_loss: 163.9734 - val_mae: 8.1742 - val_mse: 163.9734\n",
      "Epoch 33/500\n",
      "15704/15704 [==============================] - 21s 1ms/sample - loss: 122.4732 - mae: 7.3214 - mse: 122.4732 - val_loss: 204.6484 - val_mae: 9.0517 - val_mse: 204.6484\n",
      "Epoch 34/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 142.2045 - mae: 7.7091 - mse: 142.2046 - val_loss: 175.6415 - val_mae: 8.2751 - val_mse: 175.6415\n",
      "Epoch 35/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 126.0962 - mae: 7.4211 - mse: 126.0962 - val_loss: 179.9886 - val_mae: 8.6463 - val_mse: 179.9886\n",
      "Epoch 36/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 125.1509 - mae: 7.4691 - mse: 125.1509 - val_loss: 193.5637 - val_mae: 8.8419 - val_mse: 193.5637\n",
      "Epoch 37/500\n",
      "15704/15704 [==============================] - 20s 1ms/sample - loss: 137.7215 - mae: 7.7224 - mse: 137.7215 - val_loss: 154.3001 - val_mae: 8.2884 - val_mse: 154.3000\n",
      "Epoch 38/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 124.5637 - mae: 7.4604 - mse: 124.5637 - val_loss: 211.9996 - val_mae: 9.4997 - val_mse: 211.9996\n",
      "Epoch 39/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 126.3424 - mae: 7.4250 - mse: 126.3424 - val_loss: 177.7016 - val_mae: 8.5255 - val_mse: 177.7016\n",
      "Epoch 40/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 119.1392 - mae: 7.3876 - mse: 119.1392 - val_loss: 172.6006 - val_mae: 7.8724 - val_mse: 172.6006\n",
      "Epoch 41/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 124.3584 - mae: 7.4567 - mse: 124.3584 - val_loss: 159.8584 - val_mae: 7.9268 - val_mse: 159.8584\n",
      "Epoch 42/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 135.8063 - mae: 7.6731 - mse: 135.8063 - val_loss: 173.9745 - val_mae: 8.6251 - val_mse: 173.9745\n",
      "Epoch 43/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 120.4429 - mae: 7.4442 - mse: 120.4429 - val_loss: 181.5073 - val_mae: 8.6724 - val_mse: 181.5074\n",
      "Epoch 44/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 134.8299 - mae: 7.5907 - mse: 134.8299 - val_loss: 172.8944 - val_mae: 8.5368 - val_mse: 172.8944\n",
      "Epoch 45/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 129.4683 - mae: 7.5410 - mse: 129.4683 - val_loss: 142.0790 - val_mae: 7.8366 - val_mse: 142.0790\n",
      "Epoch 46/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 118.1257 - mae: 7.3356 - mse: 118.1257 - val_loss: 184.2539 - val_mae: 8.5585 - val_mse: 184.2538\n",
      "Epoch 47/500\n",
      "15704/15704 [==============================] - 20s 1ms/sample - loss: 120.0186 - mae: 7.4051 - mse: 120.0186 - val_loss: 164.9221 - val_mae: 8.1244 - val_mse: 164.9222\n",
      "Epoch 48/500\n",
      "15704/15704 [==============================] - 20s 1ms/sample - loss: 130.4006 - mae: 7.5665 - mse: 130.4006 - val_loss: 157.4338 - val_mae: 8.1370 - val_mse: 157.4338\n",
      "Epoch 49/500\n",
      "15704/15704 [==============================] - 20s 1ms/sample - loss: 123.9758 - mae: 7.4170 - mse: 123.9757 - val_loss: 207.9246 - val_mae: 9.1812 - val_mse: 207.9246\n",
      "Epoch 50/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 120.6930 - mae: 7.3575 - mse: 120.6930 - val_loss: 157.1387 - val_mae: 8.1714 - val_mse: 157.1387\n",
      "Epoch 51/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 121.1790 - mae: 7.4087 - mse: 121.1790 - val_loss: 179.7398 - val_mae: 8.5291 - val_mse: 179.7398\n",
      "Epoch 52/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 125.1713 - mae: 7.4419 - mse: 125.1713 - val_loss: 201.9013 - val_mae: 9.2411 - val_mse: 201.9014\n",
      "Epoch 53/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 129.0173 - mae: 7.5255 - mse: 129.0173 - val_loss: 183.9640 - val_mae: 8.7916 - val_mse: 183.9640\n",
      "Epoch 54/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 127.0304 - mae: 7.4555 - mse: 127.0304 - val_loss: 147.0820 - val_mae: 7.4625 - val_mse: 147.0820\n",
      "Epoch 55/500\n",
      "15704/15704 [==============================] - 20s 1ms/sample - loss: 124.5493 - mae: 7.3998 - mse: 124.5493 - val_loss: 185.0061 - val_mae: 8.3569 - val_mse: 185.0062\n",
      "Epoch 56/500\n",
      "15704/15704 [==============================] - 20s 1ms/sample - loss: 124.5628 - mae: 7.5107 - mse: 124.5628 - val_loss: 150.5487 - val_mae: 7.6582 - val_mse: 150.5487\n",
      "Epoch 57/500\n",
      "15704/15704 [==============================] - 20s 1ms/sample - loss: 134.9501 - mae: 7.6335 - mse: 134.9501 - val_loss: 166.6220 - val_mae: 8.1696 - val_mse: 166.6220\n",
      "Epoch 58/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 124.1092 - mae: 7.4425 - mse: 124.1093 - val_loss: 182.3690 - val_mae: 8.5570 - val_mse: 182.3690\n",
      "Epoch 59/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 130.0246 - mae: 7.5194 - mse: 130.0246 - val_loss: 194.2959 - val_mae: 9.0856 - val_mse: 194.2959\n",
      "Epoch 60/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 117.8181 - mae: 7.2800 - mse: 117.8181 - val_loss: 184.3911 - val_mae: 8.6650 - val_mse: 184.3911\n",
      "Epoch 61/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 121.3075 - mae: 7.3531 - mse: 121.3076 - val_loss: 193.5380 - val_mae: 9.1609 - val_mse: 193.5379\n",
      "Epoch 62/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 123.8763 - mae: 7.4233 - mse: 123.8763 - val_loss: 190.6686 - val_mae: 8.6273 - val_mse: 190.6686\n",
      "Epoch 63/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 130.0380 - mae: 7.5176 - mse: 130.0380 - val_loss: 163.4081 - val_mae: 7.9932 - val_mse: 163.4081\n",
      "Epoch 64/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 133.8095 - mae: 7.6055 - mse: 133.8095 - val_loss: 141.0011 - val_mae: 7.6064 - val_mse: 141.0011\n",
      "Epoch 65/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 133.6094 - mae: 7.5455 - mse: 133.6094 - val_loss: 186.0962 - val_mae: 8.3055 - val_mse: 186.0962\n",
      "Epoch 66/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 132.7143 - mae: 7.5359 - mse: 132.7144 - val_loss: 181.1825 - val_mae: 8.7140 - val_mse: 181.1825\n",
      "Epoch 67/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 128.5842 - mae: 7.4730 - mse: 128.5843 - val_loss: 160.2839 - val_mae: 8.2822 - val_mse: 160.2839\n",
      "Epoch 68/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 132.8987 - mae: 7.5575 - mse: 132.8987 - val_loss: 230.3683 - val_mae: 9.1553 - val_mse: 230.3683\n",
      "Epoch 69/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 141.1943 - mae: 7.6038 - mse: 141.1943 - val_loss: 133.3285 - val_mae: 7.7585 - val_mse: 133.3285\n",
      "Epoch 70/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 129.6040 - mae: 7.5379 - mse: 129.6040 - val_loss: 140.9673 - val_mae: 7.8898 - val_mse: 140.9673\n",
      "Epoch 71/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 136.0938 - mae: 7.5590 - mse: 136.0939 - val_loss: 180.3834 - val_mae: 8.4629 - val_mse: 180.3834\n",
      "Epoch 72/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 137.8920 - mae: 7.6000 - mse: 137.8919 - val_loss: 150.0527 - val_mae: 7.9967 - val_mse: 150.0528\n",
      "Epoch 73/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 138.8169 - mae: 7.6357 - mse: 138.8169 - val_loss: 170.3416 - val_mae: 8.4128 - val_mse: 170.3415\n",
      "Epoch 74/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 123.0106 - mae: 7.3398 - mse: 123.0107 - val_loss: 189.1129 - val_mae: 8.7871 - val_mse: 189.1129\n",
      "Epoch 75/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 133.1507 - mae: 7.5704 - mse: 133.1507 - val_loss: 159.4585 - val_mae: 7.9910 - val_mse: 159.4585\n",
      "Epoch 76/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 127.0397 - mae: 7.4482 - mse: 127.0396 - val_loss: 175.1837 - val_mae: 8.3989 - val_mse: 175.1837\n",
      "Epoch 77/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 119.8986 - mae: 7.3352 - mse: 119.8986 - val_loss: 173.4671 - val_mae: 8.7665 - val_mse: 173.4671\n",
      "Epoch 78/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 121.6170 - mae: 7.3673 - mse: 121.6170 - val_loss: 150.4470 - val_mae: 8.2226 - val_mse: 150.4469\n",
      "Epoch 79/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 138.4926 - mae: 7.7197 - mse: 138.4926 - val_loss: 159.7862 - val_mae: 8.1249 - val_mse: 159.7862\n",
      "Epoch 80/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 126.3202 - mae: 7.4721 - mse: 126.3202 - val_loss: 154.9060 - val_mae: 7.9548 - val_mse: 154.9060\n",
      "Epoch 81/500\n",
      "15704/15704 [==============================] - 20s 1ms/sample - loss: 125.7193 - mae: 7.4138 - mse: 125.7193 - val_loss: 175.0649 - val_mae: 8.4377 - val_mse: 175.0649\n",
      "Epoch 82/500\n",
      "15704/15704 [==============================] - 20s 1ms/sample - loss: 134.5210 - mae: 7.6322 - mse: 134.5210 - val_loss: 191.7208 - val_mae: 8.3777 - val_mse: 191.7208\n",
      "Epoch 83/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 120.9098 - mae: 7.2747 - mse: 120.9099 - val_loss: 171.1389 - val_mae: 8.4268 - val_mse: 171.1389\n",
      "Epoch 84/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 132.9985 - mae: 7.5087 - mse: 132.9985 - val_loss: 189.1127 - val_mae: 8.7649 - val_mse: 189.1127\n",
      "Epoch 85/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 125.7485 - mae: 7.3833 - mse: 125.7485 - val_loss: 177.6677 - val_mae: 8.7675 - val_mse: 177.6677\n",
      "Epoch 86/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 135.3068 - mae: 7.5486 - mse: 135.3069 - val_loss: 242.8139 - val_mae: 9.3666 - val_mse: 242.8139\n",
      "Epoch 87/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 129.2399 - mae: 7.5597 - mse: 129.2399 - val_loss: 158.3428 - val_mae: 7.9865 - val_mse: 158.3429\n",
      "Epoch 88/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 118.0879 - mae: 7.3855 - mse: 118.0879 - val_loss: 168.7357 - val_mae: 8.2689 - val_mse: 168.7357\n",
      "Epoch 89/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 136.0327 - mae: 7.5605 - mse: 136.0327 - val_loss: 161.4155 - val_mae: 7.9530 - val_mse: 161.4156\n",
      "Epoch 90/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 143.3731 - mae: 7.6773 - mse: 143.3731 - val_loss: 161.9685 - val_mae: 7.7573 - val_mse: 161.9685\n",
      "Epoch 91/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 126.3882 - mae: 7.4372 - mse: 126.3882 - val_loss: 165.9537 - val_mae: 8.2344 - val_mse: 165.9537\n",
      "Epoch 92/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 130.3301 - mae: 7.5224 - mse: 130.3301 - val_loss: 187.9544 - val_mae: 8.5629 - val_mse: 187.9544\n",
      "Epoch 93/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 130.1083 - mae: 7.4097 - mse: 130.1083 - val_loss: 201.9505 - val_mae: 8.3358 - val_mse: 201.9504\n",
      "Epoch 94/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 120.4159 - mae: 7.3217 - mse: 120.4158 - val_loss: 142.9668 - val_mae: 7.7830 - val_mse: 142.9668\n",
      "Epoch 95/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 125.8931 - mae: 7.3548 - mse: 125.8931 - val_loss: 214.9379 - val_mae: 9.0460 - val_mse: 214.9379\n",
      "Epoch 96/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 134.2079 - mae: 7.5273 - mse: 134.2079 - val_loss: 176.0031 - val_mae: 8.0265 - val_mse: 176.0032\n",
      "Epoch 97/500\n",
      "15704/15704 [==============================] - 18s 1ms/sample - loss: 116.5302 - mae: 7.2751 - mse: 116.5302 - val_loss: 177.3555 - val_mae: 8.2426 - val_mse: 177.3555\n",
      "Epoch 98/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 123.6359 - mae: 7.4603 - mse: 123.6359 - val_loss: 203.6183 - val_mae: 8.8885 - val_mse: 203.6183\n",
      "Epoch 99/500\n",
      "15704/15704 [==============================] - 19s 1ms/sample - loss: 120.8742 - mae: 7.2926 - mse: 120.8742 - val_loss: 150.6066 - val_mae: 7.8610 - val_mse: 150.6066\n",
      "Epoch 100/500\n",
      " 2528/15704 [===>..........................] - ETA: 15s - loss: 124.9640 - mae: 7.4296 - mse: 124.9640"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-db3372b28ee5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimsTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargetTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimsTest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargetTest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(simsTrain, targetTrain, epochs=500, verbose=1, validation_data=(simsTest,targetTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(simsTest,targetTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[309.90103]]]\n",
      "295.5\n",
      "[[[17.469666]]]\n",
      "16.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(model.predict([simsTest[0]]))\n",
    " \n",
    "print(targetTest[0])\n",
    "\n",
    "print(model.predict([simsTest[1]]))\n",
    "\n",
    "print(targetTest[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
