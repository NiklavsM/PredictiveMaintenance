{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "#print(tf.keras.__version__)\n",
    "#print(tf.__version__)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math as mt\n",
    "import random as rng\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def getColumns(size):\n",
    "    columns = []\n",
    "    for i in range(size):\n",
    "        columns.append(i)\n",
    "    return columns\n",
    "\n",
    "directory = \"./CMAPSSData/train_FD001.txt\"\n",
    "turbo = pd.read_csv(directory, header=None, sep=' ')\n",
    "turbo = turbo.drop([26, 27], axis=1)\n",
    "\n",
    "#for i in turbo.columns:\n",
    "#    column = turbo[i]\n",
    "#    print(i)\n",
    "#    print(column.describe())\n",
    "    \n",
    "#print(turbo.values)\n",
    "\n",
    "# Drop the input parameters to get just the sensors\n",
    "turboSens = turbo.drop([0,1], axis=1)\n",
    "turboSens.columns = getColumns(turboSens.shape[1])\n",
    "\n",
    "# Get the cycles and useful sensors. \n",
    "turboUsefulSens = turboSens\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "norm_sens = min_max_scaler.fit_transform(turboUsefulSens)\n",
    "\n",
    "turboCycles = turbo[1]\n",
    "#print(turboCycles)\n",
    "\n",
    "deteriorate = []\n",
    "maxCycle = float(turboCycles.max())\n",
    "\n",
    "currentCount = maxCycle\n",
    "for i in range(turbo.shape[0] - 1, -1, -1):\n",
    "    currentRow = turboCycles.loc[i]\n",
    "    deteriorate.insert(0, currentCount)\n",
    "    if currentRow == 1:\n",
    "        currentCount = maxCycle\n",
    "    else:\n",
    "        currentCount -= 1\n",
    "\n",
    "        \n",
    "deteriorate = pd.DataFrame(deteriorate)\n",
    "\n",
    "deteriorateSwap = []\n",
    "for i in deteriorate[0]:\n",
    "    deteriorateSwap.append(maxCycle - i)\n",
    "deteriorate = pd.DataFrame(deteriorateSwap)\n",
    "\n",
    "\n",
    "norm_sens = pd.DataFrame(norm_sens)\n",
    "deteriorate = deteriorate.join(norm_sens, lsuffix='0', rsuffix='1')\n",
    "deteriorate.columns = getColumns(deteriorate.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = deteriorate.to_numpy()\n",
    "\n",
    "arrayCopy = array.tolist()\n",
    "\n",
    "simulations = []\n",
    "\n",
    "convCount = 10\n",
    "convDiv = int(convCount/2)\n",
    "\n",
    "count = len(array)\n",
    "\n",
    "while(count > 0):\n",
    "    cycles = []\n",
    "    element = [-1,-1]\n",
    "    while(element[0]!=0):\n",
    "        element = arrayCopy.pop(0)\n",
    "        cycles.append(element)\n",
    "        count-=1\n",
    "    simulations.append(cycles)\n",
    "    \n",
    "#for sim in simulations:\n",
    "#    lenth = len(sim)\n",
    "#    remainder = lenth%convCount\n",
    "#    for i in range(remainder):\n",
    "#        sim.pop(0)\n",
    "    \n",
    "#simsRecomb = []\n",
    "#for sim in simulations:\n",
    "#    for i in sim:\n",
    "#        simsRecomb.append(i)\n",
    "\n",
    "#print(len(simsRecomb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19631\n",
      "19631\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tens = []\n",
    "tensCount = []\n",
    "\n",
    "for sim in simulations:\n",
    "    for i in range(convDiv, len(sim) - convDiv):\n",
    "        ten = []\n",
    "        total = 0\n",
    "        for j in range(-convDiv,convDiv):\n",
    "            index = i + j\n",
    "            element = sim[index].copy()\n",
    "            total+= element.pop(0)\n",
    "            ten.append(element)\n",
    "        total/=convCount\n",
    "        tensCount.append(total)\n",
    "        tens.append(ten)\n",
    "\n",
    "    \n",
    "print(len(tens))\n",
    "print(len(tensCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "simsReorder = []\n",
    "simsCycleReorder = []\n",
    "\n",
    "length = len(tens)\n",
    "for i in range(length):\n",
    "    index = rng.randint(0, len(tens)-1)\n",
    "    simsReorder.append(tens.pop(index))\n",
    "    simsCycleReorder.append(tensCount.pop(index))\n",
    "    \n",
    "    \n",
    "    \n",
    "simsTrain = np.array(simsReorder[:15704])\n",
    "targetTrain = np.array(simsCycleReorder[:15704])\n",
    "\n",
    "simsTest = np.array(simsReorder[15704:])\n",
    "targetTest = np.array(simsCycleReorder[15704:])\n",
    "\n",
    "\n",
    "\n",
    "width = (turboUsefulSens.shape[1])\n",
    "print(width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 10, 24)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 8, 150)       10950       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 6, 300)       135300      conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1, 300)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 10, 150)      105000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 300)          0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 300)          541200      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 600)          0           flatten_1[0][0]                  \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          60100       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            101         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 852,651\n",
      "Trainable params: 852,651\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "visible = layers.Input(shape=(convCount, width,))\n",
    "\n",
    "cnn1 = layers.Conv1D(150, 3, activation='relu')(visible)\n",
    "cnn2 = layers.Conv1D(300, 3, activation='relu')(cnn1)\n",
    "pool = layers.MaxPooling1D(6)(cnn2)\n",
    "drop = layers.Dropout(0.25)(pool)\n",
    "flat = layers.Flatten()(pool)\n",
    "\n",
    "lstm1 = layers.LSTM(150, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)(visible)\n",
    "lstm2 = layers.LSTM(300, dropout=0.1, recurrent_dropout=0.1)(lstm1)\n",
    "\n",
    "combo = layers.merge.concatenate([flat,lstm2])\n",
    "dense = layers.Dense(100, activation='relu')(combo)\n",
    "out = layers.Dense(1)(dense)\n",
    "\n",
    "model = Model(inputs=visible, outputs=out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "              loss='mse', \n",
    "              metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15704 samples, validate on 3927 samples\n",
      "Epoch 1/750\n",
      "15704/15704 [==============================] - 23s 1ms/step - loss: 2263.6504 - mae: 35.0192 - mse: 2263.6497 - val_loss: 1640.7981 - val_mae: 29.4764 - val_mse: 1640.7982\n",
      "Epoch 2/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 1736.7208 - mae: 30.0306 - mse: 1736.7201 - val_loss: 1599.3762 - val_mae: 28.5164 - val_mse: 1599.3760\n",
      "Epoch 3/750\n",
      "15704/15704 [==============================] - 24s 2ms/step - loss: 1680.6161 - mae: 29.2834 - mse: 1680.6166 - val_loss: 1551.8131 - val_mae: 28.3170 - val_mse: 1551.8131\n",
      "Epoch 4/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 1645.6455 - mae: 28.6733 - mse: 1645.6453 - val_loss: 1535.8922 - val_mae: 28.3367 - val_mse: 1535.8923\n",
      "Epoch 5/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 1610.8964 - mae: 28.3509 - mse: 1610.8970 - val_loss: 1493.7266 - val_mae: 27.3982 - val_mse: 1493.7268\n",
      "Epoch 6/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 1580.4822 - mae: 28.0718 - mse: 1580.4821 - val_loss: 1975.3642 - val_mae: 30.3589 - val_mse: 1975.3641\n",
      "Epoch 7/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 1572.5390 - mae: 27.9427 - mse: 1572.5403 - val_loss: 1664.4228 - val_mae: 29.9281 - val_mse: 1664.4230\n",
      "Epoch 8/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 1538.1551 - mae: 27.5085 - mse: 1538.1554 - val_loss: 1451.5347 - val_mae: 27.4194 - val_mse: 1451.5349\n",
      "Epoch 9/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 1520.1501 - mae: 27.4087 - mse: 1520.1500 - val_loss: 1442.7818 - val_mae: 27.2750 - val_mse: 1442.7822\n",
      "Epoch 10/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 1479.7222 - mae: 26.9963 - mse: 1479.7222 - val_loss: 1659.0470 - val_mae: 29.9359 - val_mse: 1659.0469\n",
      "Epoch 11/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 1460.2932 - mae: 26.8973 - mse: 1460.2928 - val_loss: 1380.6648 - val_mae: 26.3851 - val_mse: 1380.6649\n",
      "Epoch 12/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 1432.9794 - mae: 26.6078 - mse: 1432.9797 - val_loss: 1347.0688 - val_mae: 25.9769 - val_mse: 1347.0687\n",
      "Epoch 13/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 1395.6579 - mae: 26.3177 - mse: 1395.6576 - val_loss: 1367.0168 - val_mae: 26.6767 - val_mse: 1367.0168\n",
      "Epoch 14/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 1353.0676 - mae: 25.8890 - mse: 1353.0675 - val_loss: 1329.0849 - val_mae: 26.1853 - val_mse: 1329.0851\n",
      "Epoch 15/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 1307.9818 - mae: 25.5485 - mse: 1307.9816 - val_loss: 1271.8686 - val_mae: 25.0794 - val_mse: 1271.8687\n",
      "Epoch 16/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 1256.8105 - mae: 25.0895 - mse: 1256.8099 - val_loss: 1290.8735 - val_mae: 25.7022 - val_mse: 1290.8734\n",
      "Epoch 17/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 1195.0823 - mae: 24.5307 - mse: 1195.0835 - val_loss: 1344.9992 - val_mae: 25.8407 - val_mse: 1344.9994\n",
      "Epoch 18/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 1143.4077 - mae: 24.0946 - mse: 1143.4078 - val_loss: 1254.4334 - val_mae: 25.1650 - val_mse: 1254.4340\n",
      "Epoch 19/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 1098.5423 - mae: 23.5969 - mse: 1098.5425 - val_loss: 1115.6051 - val_mae: 23.8366 - val_mse: 1115.6049\n",
      "Epoch 20/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 1044.5298 - mae: 23.0161 - mse: 1044.5297 - val_loss: 1032.6479 - val_mae: 22.8252 - val_mse: 1032.6478\n",
      "Epoch 21/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 994.7437 - mae: 22.5531 - mse: 994.7438 - val_loss: 1002.6032 - val_mae: 22.6383 - val_mse: 1002.6033\n",
      "Epoch 22/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 923.3645 - mae: 21.7360 - mse: 923.3646 - val_loss: 950.5183 - val_mae: 21.8041 - val_mse: 950.5186\n",
      "Epoch 23/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 868.7978 - mae: 21.2277 - mse: 868.7982 - val_loss: 934.3134 - val_mae: 22.1792 - val_mse: 934.3132\n",
      "Epoch 24/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 803.2331 - mae: 20.4450 - mse: 803.2328 - val_loss: 918.5865 - val_mae: 21.5771 - val_mse: 918.5864\n",
      "Epoch 25/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 749.9694 - mae: 19.7553 - mse: 749.9694 - val_loss: 937.1290 - val_mae: 22.6945 - val_mse: 937.1287\n",
      "Epoch 26/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 701.8064 - mae: 19.1106 - mse: 701.8062 - val_loss: 864.5447 - val_mae: 20.8967 - val_mse: 864.5448\n",
      "Epoch 27/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 647.8029 - mae: 18.4433 - mse: 647.8027 - val_loss: 711.5693 - val_mae: 19.1426 - val_mse: 711.5694\n",
      "Epoch 28/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 604.1464 - mae: 17.9525 - mse: 604.1462 - val_loss: 740.0085 - val_mae: 19.3582 - val_mse: 740.0084\n",
      "Epoch 29/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 555.5177 - mae: 17.2368 - mse: 555.5175 - val_loss: 676.9608 - val_mae: 18.6899 - val_mse: 676.9607\n",
      "Epoch 30/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 517.3695 - mae: 16.6509 - mse: 517.3693 - val_loss: 666.0232 - val_mae: 19.4695 - val_mse: 666.0232\n",
      "Epoch 31/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 494.9148 - mae: 16.2276 - mse: 494.9149 - val_loss: 598.0646 - val_mae: 17.6005 - val_mse: 598.0647\n",
      "Epoch 32/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 455.7415 - mae: 15.7043 - mse: 455.7416 - val_loss: 551.0157 - val_mae: 17.0731 - val_mse: 551.0157\n",
      "Epoch 33/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 438.1810 - mae: 15.4525 - mse: 438.1806 - val_loss: 563.4082 - val_mae: 17.5625 - val_mse: 563.4081\n",
      "Epoch 34/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 407.9245 - mae: 14.9128 - mse: 407.9243 - val_loss: 492.3641 - val_mae: 16.0432 - val_mse: 492.3640\n",
      "Epoch 35/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 384.9888 - mae: 14.5887 - mse: 384.9889 - val_loss: 499.9939 - val_mae: 16.1404 - val_mse: 499.9940\n",
      "Epoch 36/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 365.7553 - mae: 14.2046 - mse: 365.7553 - val_loss: 449.5307 - val_mae: 15.2586 - val_mse: 449.5306\n",
      "Epoch 37/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 346.4418 - mae: 13.7293 - mse: 346.4419 - val_loss: 433.0287 - val_mae: 15.0631 - val_mse: 433.0287\n",
      "Epoch 38/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 332.7596 - mae: 13.5315 - mse: 332.7596 - val_loss: 418.6996 - val_mae: 14.6709 - val_mse: 418.6996\n",
      "Epoch 39/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 318.0821 - mae: 13.2773 - mse: 318.0822 - val_loss: 480.3865 - val_mae: 16.0655 - val_mse: 480.3864\n",
      "Epoch 40/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 302.7773 - mae: 13.0270 - mse: 302.7772 - val_loss: 401.3891 - val_mae: 14.6269 - val_mse: 401.3891\n",
      "Epoch 41/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 285.4213 - mae: 12.6974 - mse: 285.4213 - val_loss: 340.0082 - val_mae: 13.5333 - val_mse: 340.0082\n",
      "Epoch 42/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 280.0647 - mae: 12.5299 - mse: 280.0646 - val_loss: 589.0823 - val_mae: 17.8130 - val_mse: 589.0824\n",
      "Epoch 43/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 261.6934 - mae: 12.1783 - mse: 261.6934 - val_loss: 374.8126 - val_mae: 14.1907 - val_mse: 374.8127\n",
      "Epoch 44/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 254.4202 - mae: 11.8993 - mse: 254.4203 - val_loss: 382.2007 - val_mae: 14.8600 - val_mse: 382.2006\n",
      "Epoch 45/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 238.3215 - mae: 11.5900 - mse: 238.3214 - val_loss: 489.3703 - val_mae: 16.1603 - val_mse: 489.3703\n",
      "Epoch 46/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 230.0216 - mae: 11.3881 - mse: 230.0216 - val_loss: 873.9611 - val_mae: 22.4274 - val_mse: 873.9612\n",
      "Epoch 47/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 232.2553 - mae: 11.4070 - mse: 232.2553 - val_loss: 307.4971 - val_mae: 13.3292 - val_mse: 307.4972\n",
      "Epoch 48/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 217.8538 - mae: 11.0960 - mse: 217.8538 - val_loss: 292.8719 - val_mae: 12.8912 - val_mse: 292.8719\n",
      "Epoch 49/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 214.2788 - mae: 11.0118 - mse: 214.2788 - val_loss: 241.0793 - val_mae: 11.5700 - val_mse: 241.0793\n",
      "Epoch 50/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 209.4331 - mae: 10.8380 - mse: 209.4330 - val_loss: 267.9771 - val_mae: 12.0712 - val_mse: 267.9771\n",
      "Epoch 51/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 200.5066 - mae: 10.6555 - mse: 200.5065 - val_loss: 308.6479 - val_mae: 13.3699 - val_mse: 308.6479\n",
      "Epoch 52/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 199.0742 - mae: 10.5844 - mse: 199.0741 - val_loss: 450.2486 - val_mae: 15.8531 - val_mse: 450.2485\n",
      "Epoch 53/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 187.1543 - mae: 10.3522 - mse: 187.1543 - val_loss: 242.1163 - val_mae: 11.5343 - val_mse: 242.1164\n",
      "Epoch 54/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 181.4088 - mae: 10.1782 - mse: 181.4088 - val_loss: 482.9321 - val_mae: 16.8959 - val_mse: 482.9320\n",
      "Epoch 55/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 177.4928 - mae: 10.0574 - mse: 177.4927 - val_loss: 251.9600 - val_mae: 11.8141 - val_mse: 251.9600\n",
      "Epoch 56/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 169.1601 - mae: 9.8075 - mse: 169.1602 - val_loss: 666.8823 - val_mae: 20.5492 - val_mse: 666.8823\n",
      "Epoch 57/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 167.8358 - mae: 9.7172 - mse: 167.8358 - val_loss: 245.5780 - val_mae: 11.4695 - val_mse: 245.5779\n",
      "Epoch 58/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 163.1739 - mae: 9.6401 - mse: 163.1738 - val_loss: 223.5466 - val_mae: 11.1218 - val_mse: 223.5466\n",
      "Epoch 59/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 159.6686 - mae: 9.5526 - mse: 159.6686 - val_loss: 256.0208 - val_mae: 11.9687 - val_mse: 256.0208\n",
      "Epoch 60/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 151.9139 - mae: 9.2278 - mse: 151.9140 - val_loss: 264.5802 - val_mae: 12.2306 - val_mse: 264.5802\n",
      "Epoch 61/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 151.1454 - mae: 9.2054 - mse: 151.1454 - val_loss: 228.4589 - val_mae: 10.8814 - val_mse: 228.4589\n",
      "Epoch 62/750\n",
      "15704/15704 [==============================] - 23s 1ms/step - loss: 144.8252 - mae: 9.1057 - mse: 144.8252 - val_loss: 341.9226 - val_mae: 14.4372 - val_mse: 341.9225\n",
      "Epoch 63/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 146.7299 - mae: 9.1011 - mse: 146.7299 - val_loss: 239.2633 - val_mae: 11.7651 - val_mse: 239.2633\n",
      "Epoch 64/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 139.4035 - mae: 8.9391 - mse: 139.4035 - val_loss: 313.3769 - val_mae: 12.8800 - val_mse: 313.3769\n",
      "Epoch 65/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 138.9579 - mae: 8.8686 - mse: 138.9579 - val_loss: 272.9945 - val_mae: 12.0644 - val_mse: 272.9944\n",
      "Epoch 66/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 131.7136 - mae: 8.5804 - mse: 131.7136 - val_loss: 186.9995 - val_mae: 10.1785 - val_mse: 186.9996\n",
      "Epoch 67/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 128.4208 - mae: 8.5787 - mse: 128.4209 - val_loss: 177.8046 - val_mae: 9.8774 - val_mse: 177.8047\n",
      "Epoch 68/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 125.8973 - mae: 8.4599 - mse: 125.8974 - val_loss: 279.4266 - val_mae: 11.9287 - val_mse: 279.4266\n",
      "Epoch 69/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 123.8929 - mae: 8.4196 - mse: 123.8929 - val_loss: 255.3006 - val_mae: 12.0929 - val_mse: 255.3006\n",
      "Epoch 70/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 120.8876 - mae: 8.2454 - mse: 120.8876 - val_loss: 197.3420 - val_mae: 10.5863 - val_mse: 197.3421\n",
      "Epoch 71/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 118.9666 - mae: 8.2332 - mse: 118.9667 - val_loss: 215.1601 - val_mae: 10.5697 - val_mse: 215.1600\n",
      "Epoch 72/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 115.4772 - mae: 8.0751 - mse: 115.4772 - val_loss: 156.8083 - val_mae: 9.5709 - val_mse: 156.8084\n",
      "Epoch 73/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 113.7807 - mae: 8.0274 - mse: 113.7807 - val_loss: 173.2889 - val_mae: 9.5931 - val_mse: 173.2890\n",
      "Epoch 74/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 109.0383 - mae: 7.8738 - mse: 109.0383 - val_loss: 152.4798 - val_mae: 8.9760 - val_mse: 152.4799\n",
      "Epoch 75/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 109.1802 - mae: 7.8596 - mse: 109.1802 - val_loss: 190.6767 - val_mae: 10.0295 - val_mse: 190.6767\n",
      "Epoch 76/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 107.9503 - mae: 7.8098 - mse: 107.9503 - val_loss: 288.2039 - val_mae: 12.3936 - val_mse: 288.2039\n",
      "Epoch 77/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 106.5282 - mae: 7.7463 - mse: 106.5283 - val_loss: 197.0202 - val_mae: 10.1988 - val_mse: 197.0202\n",
      "Epoch 78/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 102.1817 - mae: 7.6235 - mse: 102.1817 - val_loss: 148.4621 - val_mae: 9.0860 - val_mse: 148.4622\n",
      "Epoch 79/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 100.8453 - mae: 7.6300 - mse: 100.8453 - val_loss: 150.0428 - val_mae: 8.8734 - val_mse: 150.0428\n",
      "Epoch 80/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 100.9981 - mae: 7.5987 - mse: 100.9981 - val_loss: 184.2331 - val_mae: 10.2065 - val_mse: 184.2331\n",
      "Epoch 81/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 98.5661 - mae: 7.5018 - mse: 98.5661 - val_loss: 160.9219 - val_mae: 9.3430 - val_mse: 160.9220\n",
      "Epoch 82/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 96.6806 - mae: 7.4351 - mse: 96.6806 - val_loss: 174.1461 - val_mae: 10.1628 - val_mse: 174.1461\n",
      "Epoch 83/750\n",
      "15704/15704 [==============================] - 23s 1ms/step - loss: 93.7825 - mae: 7.3064 - mse: 93.7825 - val_loss: 147.9623 - val_mae: 9.0728 - val_mse: 147.9624\n",
      "Epoch 84/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 93.8203 - mae: 7.3326 - mse: 93.8203 - val_loss: 212.5469 - val_mae: 10.9460 - val_mse: 212.5469\n",
      "Epoch 85/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 91.4838 - mae: 7.1740 - mse: 91.4838 - val_loss: 120.2654 - val_mae: 7.9638 - val_mse: 120.2654\n",
      "Epoch 86/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 90.5376 - mae: 7.2110 - mse: 90.5375 - val_loss: 169.5614 - val_mae: 9.3724 - val_mse: 169.5614\n",
      "Epoch 87/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 86.8908 - mae: 7.0071 - mse: 86.8907 - val_loss: 145.8296 - val_mae: 8.9799 - val_mse: 145.8295\n",
      "Epoch 88/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 87.2911 - mae: 7.0310 - mse: 87.2911 - val_loss: 131.1794 - val_mae: 8.3425 - val_mse: 131.1794\n",
      "Epoch 89/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 85.4371 - mae: 6.9068 - mse: 85.4371 - val_loss: 128.0896 - val_mae: 8.2107 - val_mse: 128.0896\n",
      "Epoch 90/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 83.6300 - mae: 6.9185 - mse: 83.6301 - val_loss: 187.5238 - val_mae: 10.5567 - val_mse: 187.5238\n",
      "Epoch 91/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 83.8878 - mae: 6.8933 - mse: 83.8878 - val_loss: 173.8607 - val_mae: 9.8342 - val_mse: 173.8607\n",
      "Epoch 92/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 81.9758 - mae: 6.8473 - mse: 81.9757 - val_loss: 187.5333 - val_mae: 10.0980 - val_mse: 187.5332\n",
      "Epoch 93/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 80.7544 - mae: 6.7815 - mse: 80.7544 - val_loss: 129.9733 - val_mae: 8.4111 - val_mse: 129.9733\n",
      "Epoch 94/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 79.2334 - mae: 6.7014 - mse: 79.2334 - val_loss: 132.0662 - val_mae: 8.3871 - val_mse: 132.0662\n",
      "Epoch 95/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 78.2384 - mae: 6.6598 - mse: 78.2384 - val_loss: 208.3958 - val_mae: 11.3373 - val_mse: 208.3958\n",
      "Epoch 96/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 78.2682 - mae: 6.6440 - mse: 78.2682 - val_loss: 219.8782 - val_mae: 11.2185 - val_mse: 219.8782\n",
      "Epoch 97/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 74.0148 - mae: 6.5016 - mse: 74.0148 - val_loss: 296.7127 - val_mae: 12.9510 - val_mse: 296.7127\n",
      "Epoch 98/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 73.8832 - mae: 6.5050 - mse: 73.8832 - val_loss: 168.8259 - val_mae: 9.4198 - val_mse: 168.8260\n",
      "Epoch 99/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 73.2162 - mae: 6.4030 - mse: 73.2162 - val_loss: 194.5698 - val_mae: 10.3853 - val_mse: 194.5698\n",
      "Epoch 100/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 71.4861 - mae: 6.3752 - mse: 71.4861 - val_loss: 148.2778 - val_mae: 9.2694 - val_mse: 148.2778\n",
      "Epoch 101/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 71.6793 - mae: 6.3679 - mse: 71.6793 - val_loss: 100.9739 - val_mae: 7.1900 - val_mse: 100.9739\n",
      "Epoch 102/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 70.7978 - mae: 6.3356 - mse: 70.7978 - val_loss: 131.2127 - val_mae: 8.7215 - val_mse: 131.2127\n",
      "Epoch 103/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 69.0440 - mae: 6.2691 - mse: 69.0440 - val_loss: 125.2111 - val_mae: 8.5089 - val_mse: 125.2111\n",
      "Epoch 104/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 69.8912 - mae: 6.3056 - mse: 69.8912 - val_loss: 123.5515 - val_mae: 8.3893 - val_mse: 123.5515\n",
      "Epoch 105/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 68.3606 - mae: 6.2654 - mse: 68.3606 - val_loss: 102.8399 - val_mae: 7.4664 - val_mse: 102.8399\n",
      "Epoch 106/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 65.7812 - mae: 6.1236 - mse: 65.7812 - val_loss: 139.8226 - val_mae: 8.4903 - val_mse: 139.8226\n",
      "Epoch 107/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 66.1038 - mae: 6.1129 - mse: 66.1037 - val_loss: 142.8973 - val_mae: 8.9747 - val_mse: 142.8973\n",
      "Epoch 108/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 64.5495 - mae: 6.0738 - mse: 64.5495 - val_loss: 141.9258 - val_mae: 8.9080 - val_mse: 141.9258\n",
      "Epoch 109/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 62.9471 - mae: 5.9894 - mse: 62.9471 - val_loss: 103.0340 - val_mae: 7.5794 - val_mse: 103.0340\n",
      "Epoch 110/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 64.5765 - mae: 6.0640 - mse: 64.5765 - val_loss: 107.9459 - val_mae: 7.6323 - val_mse: 107.9459\n",
      "Epoch 111/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 61.1702 - mae: 5.9362 - mse: 61.1702 - val_loss: 188.4415 - val_mae: 10.8222 - val_mse: 188.4416\n",
      "Epoch 112/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 62.2049 - mae: 5.9072 - mse: 62.2049 - val_loss: 92.7562 - val_mae: 7.0267 - val_mse: 92.7563\n",
      "Epoch 113/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 60.5219 - mae: 5.8165 - mse: 60.5219 - val_loss: 102.8512 - val_mae: 7.8483 - val_mse: 102.8511\n",
      "Epoch 114/750\n",
      "15704/15704 [==============================] - 23s 1ms/step - loss: 60.3524 - mae: 5.8493 - mse: 60.3524 - val_loss: 105.2119 - val_mae: 7.6174 - val_mse: 105.2119\n",
      "Epoch 115/750\n",
      "15704/15704 [==============================] - 25s 2ms/step - loss: 60.2782 - mae: 5.8420 - mse: 60.2782 - val_loss: 109.0950 - val_mae: 7.5320 - val_mse: 109.0950\n",
      "Epoch 116/750\n",
      "15704/15704 [==============================] - 23s 1ms/step - loss: 57.3728 - mae: 5.7423 - mse: 57.3728 - val_loss: 142.0895 - val_mae: 8.5524 - val_mse: 142.0896\n",
      "Epoch 117/750\n",
      "15704/15704 [==============================] - 25s 2ms/step - loss: 58.8617 - mae: 5.7820 - mse: 58.8617 - val_loss: 101.5378 - val_mae: 7.3679 - val_mse: 101.5378\n",
      "Epoch 118/750\n",
      "15704/15704 [==============================] - 26s 2ms/step - loss: 56.7492 - mae: 5.7216 - mse: 56.7492 - val_loss: 102.9276 - val_mae: 7.6799 - val_mse: 102.9276\n",
      "Epoch 119/750\n",
      "15704/15704 [==============================] - 25s 2ms/step - loss: 56.2931 - mae: 5.6489 - mse: 56.2931 - val_loss: 117.1254 - val_mae: 8.1051 - val_mse: 117.1253\n",
      "Epoch 120/750\n",
      "15704/15704 [==============================] - 26s 2ms/step - loss: 54.7122 - mae: 5.5875 - mse: 54.7122 - val_loss: 87.8798 - val_mae: 6.7821 - val_mse: 87.8798\n",
      "Epoch 121/750\n",
      "15704/15704 [==============================] - 24s 2ms/step - loss: 56.0330 - mae: 5.6378 - mse: 56.0330 - val_loss: 118.4172 - val_mae: 8.1001 - val_mse: 118.4173\n",
      "Epoch 122/750\n",
      "15704/15704 [==============================] - 23s 1ms/step - loss: 53.6210 - mae: 5.4695 - mse: 53.6210 - val_loss: 86.0086 - val_mae: 6.7491 - val_mse: 86.0086\n",
      "Epoch 123/750\n",
      "15704/15704 [==============================] - 24s 2ms/step - loss: 53.7476 - mae: 5.5448 - mse: 53.7475 - val_loss: 77.1694 - val_mae: 6.3293 - val_mse: 77.1694\n",
      "Epoch 124/750\n",
      "15704/15704 [==============================] - 23s 1ms/step - loss: 52.8403 - mae: 5.4407 - mse: 52.8403 - val_loss: 99.8770 - val_mae: 7.2259 - val_mse: 99.8769\n",
      "Epoch 125/750\n",
      "15704/15704 [==============================] - 23s 1ms/step - loss: 51.8499 - mae: 5.4344 - mse: 51.8499 - val_loss: 109.4609 - val_mae: 7.4595 - val_mse: 109.4609\n",
      "Epoch 126/750\n",
      "15704/15704 [==============================] - 24s 2ms/step - loss: 51.8069 - mae: 5.4064 - mse: 51.8069 - val_loss: 117.0362 - val_mae: 8.2696 - val_mse: 117.0362\n",
      "Epoch 127/750\n",
      "15704/15704 [==============================] - 23s 1ms/step - loss: 51.7084 - mae: 5.4049 - mse: 51.7084 - val_loss: 80.2463 - val_mae: 6.5465 - val_mse: 80.2462\n",
      "Epoch 128/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 50.5037 - mae: 5.3471 - mse: 50.5037 - val_loss: 110.8976 - val_mae: 7.5301 - val_mse: 110.8976\n",
      "Epoch 129/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 49.7477 - mae: 5.2948 - mse: 49.7476 - val_loss: 93.0683 - val_mae: 7.0932 - val_mse: 93.0683\n",
      "Epoch 130/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 49.5805 - mae: 5.3295 - mse: 49.5805 - val_loss: 145.3132 - val_mae: 8.5992 - val_mse: 145.3132\n",
      "Epoch 131/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 49.3944 - mae: 5.2706 - mse: 49.3944 - val_loss: 90.3222 - val_mae: 7.0345 - val_mse: 90.3222\n",
      "Epoch 132/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 46.9467 - mae: 5.1644 - mse: 46.9467 - val_loss: 121.0311 - val_mae: 8.0520 - val_mse: 121.0311\n",
      "Epoch 133/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 48.7685 - mae: 5.2441 - mse: 48.7685 - val_loss: 83.4295 - val_mae: 6.6178 - val_mse: 83.4295\n",
      "Epoch 134/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 48.1070 - mae: 5.2231 - mse: 48.1070 - val_loss: 95.4583 - val_mae: 7.0001 - val_mse: 95.4583\n",
      "Epoch 135/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 47.3629 - mae: 5.1694 - mse: 47.3629 - val_loss: 103.6613 - val_mae: 7.4013 - val_mse: 103.6613\n",
      "Epoch 136/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 47.0572 - mae: 5.1792 - mse: 47.0572 - val_loss: 77.7559 - val_mae: 6.4826 - val_mse: 77.7559\n",
      "Epoch 137/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 46.3284 - mae: 5.1387 - mse: 46.3284 - val_loss: 84.7461 - val_mae: 6.5233 - val_mse: 84.7461\n",
      "Epoch 138/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 45.6269 - mae: 5.0827 - mse: 45.6269 - val_loss: 101.5711 - val_mae: 7.1802 - val_mse: 101.5710\n",
      "Epoch 139/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 45.5805 - mae: 5.0791 - mse: 45.5804 - val_loss: 92.3378 - val_mae: 6.8448 - val_mse: 92.3378\n",
      "Epoch 140/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 44.4462 - mae: 5.0594 - mse: 44.4462 - val_loss: 87.5166 - val_mae: 6.9927 - val_mse: 87.5166\n",
      "Epoch 141/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 43.8429 - mae: 4.9755 - mse: 43.8429 - val_loss: 75.1447 - val_mae: 6.2590 - val_mse: 75.1447\n",
      "Epoch 142/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 43.5602 - mae: 4.9623 - mse: 43.5602 - val_loss: 83.5547 - val_mae: 6.5913 - val_mse: 83.5547\n",
      "Epoch 143/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 43.7703 - mae: 4.9722 - mse: 43.7703 - val_loss: 97.6479 - val_mae: 7.2792 - val_mse: 97.6478\n",
      "Epoch 144/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 42.9865 - mae: 4.9140 - mse: 42.9866 - val_loss: 86.8437 - val_mae: 6.7205 - val_mse: 86.8437\n",
      "Epoch 145/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 41.6110 - mae: 4.8502 - mse: 41.6110 - val_loss: 107.9183 - val_mae: 7.7280 - val_mse: 107.9183\n",
      "Epoch 146/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 42.0245 - mae: 4.9132 - mse: 42.0244 - val_loss: 90.2419 - val_mae: 7.0379 - val_mse: 90.2419\n",
      "Epoch 147/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 41.7912 - mae: 4.8814 - mse: 41.7912 - val_loss: 93.9674 - val_mae: 6.9350 - val_mse: 93.9674\n",
      "Epoch 148/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 41.0938 - mae: 4.8634 - mse: 41.0938 - val_loss: 78.5299 - val_mae: 6.3452 - val_mse: 78.5299\n",
      "Epoch 149/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 40.8801 - mae: 4.8142 - mse: 40.8801 - val_loss: 95.1534 - val_mae: 6.9405 - val_mse: 95.1534\n",
      "Epoch 150/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 40.1333 - mae: 4.7482 - mse: 40.1333 - val_loss: 114.3312 - val_mae: 7.9948 - val_mse: 114.3312\n",
      "Epoch 151/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 39.3296 - mae: 4.7412 - mse: 39.3296 - val_loss: 75.6875 - val_mae: 6.1423 - val_mse: 75.6875\n",
      "Epoch 152/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 39.8777 - mae: 4.7874 - mse: 39.8777 - val_loss: 105.5685 - val_mae: 7.2245 - val_mse: 105.5685\n",
      "Epoch 153/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 38.9108 - mae: 4.7176 - mse: 38.9108 - val_loss: 70.6615 - val_mae: 6.0264 - val_mse: 70.6615\n",
      "Epoch 154/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 38.0724 - mae: 4.6451 - mse: 38.0725 - val_loss: 71.5366 - val_mae: 6.0402 - val_mse: 71.5366\n",
      "Epoch 155/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 38.2363 - mae: 4.6686 - mse: 38.2363 - val_loss: 74.4329 - val_mae: 6.2409 - val_mse: 74.4329\n",
      "Epoch 156/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 37.8208 - mae: 4.6459 - mse: 37.8208 - val_loss: 74.5110 - val_mae: 6.2882 - val_mse: 74.5110\n",
      "Epoch 157/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 37.1799 - mae: 4.5843 - mse: 37.1799 - val_loss: 84.0701 - val_mae: 6.4067 - val_mse: 84.0701\n",
      "Epoch 158/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 37.8427 - mae: 4.6262 - mse: 37.8427 - val_loss: 80.5388 - val_mae: 6.3085 - val_mse: 80.5388\n",
      "Epoch 159/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 36.7631 - mae: 4.5482 - mse: 36.7631 - val_loss: 66.7473 - val_mae: 5.8823 - val_mse: 66.7473\n",
      "Epoch 160/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 37.4477 - mae: 4.5834 - mse: 37.4477 - val_loss: 69.7575 - val_mae: 5.9301 - val_mse: 69.7575\n",
      "Epoch 161/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 36.4771 - mae: 4.5156 - mse: 36.4771 - val_loss: 75.0552 - val_mae: 6.3186 - val_mse: 75.0551\n",
      "Epoch 162/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 36.5713 - mae: 4.5696 - mse: 36.5713 - val_loss: 124.6166 - val_mae: 8.1854 - val_mse: 124.6165\n",
      "Epoch 163/750\n",
      "15704/15704 [==============================] - 23s 1ms/step - loss: 34.9937 - mae: 4.4508 - mse: 34.9937 - val_loss: 116.7864 - val_mae: 7.7530 - val_mse: 116.7864\n",
      "Epoch 164/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 35.8518 - mae: 4.4997 - mse: 35.8518 - val_loss: 65.9597 - val_mae: 5.7487 - val_mse: 65.9598\n",
      "Epoch 165/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 34.7767 - mae: 4.4695 - mse: 34.7767 - val_loss: 78.0483 - val_mae: 6.3089 - val_mse: 78.0483\n",
      "Epoch 166/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 34.9694 - mae: 4.4693 - mse: 34.9694 - val_loss: 102.8617 - val_mae: 7.1576 - val_mse: 102.8617\n",
      "Epoch 167/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 34.4955 - mae: 4.4169 - mse: 34.4955 - val_loss: 65.2883 - val_mae: 5.9268 - val_mse: 65.2883\n",
      "Epoch 168/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 33.7619 - mae: 4.3899 - mse: 33.7619 - val_loss: 74.0885 - val_mae: 6.2539 - val_mse: 74.0885\n",
      "Epoch 169/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 34.6313 - mae: 4.4503 - mse: 34.6313 - val_loss: 80.3166 - val_mae: 6.5578 - val_mse: 80.3166\n",
      "Epoch 170/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 33.4887 - mae: 4.3810 - mse: 33.4887 - val_loss: 88.9560 - val_mae: 6.9285 - val_mse: 88.9560\n",
      "Epoch 171/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 32.8534 - mae: 4.3343 - mse: 32.8534 - val_loss: 79.1093 - val_mae: 6.3294 - val_mse: 79.1093\n",
      "Epoch 172/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 33.1528 - mae: 4.3533 - mse: 33.1528 - val_loss: 61.1180 - val_mae: 5.5631 - val_mse: 61.1180\n",
      "Epoch 173/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 32.0657 - mae: 4.2681 - mse: 32.0657 - val_loss: 129.0033 - val_mae: 8.7192 - val_mse: 129.0034\n",
      "Epoch 174/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 32.4567 - mae: 4.2952 - mse: 32.4567 - val_loss: 63.9807 - val_mae: 5.7846 - val_mse: 63.9807\n",
      "Epoch 175/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 31.5808 - mae: 4.2243 - mse: 31.5808 - val_loss: 77.8474 - val_mae: 6.4489 - val_mse: 77.8474\n",
      "Epoch 176/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 32.3568 - mae: 4.2705 - mse: 32.3568 - val_loss: 79.5296 - val_mae: 6.2376 - val_mse: 79.5296\n",
      "Epoch 177/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 31.6368 - mae: 4.2525 - mse: 31.6369 - val_loss: 93.6421 - val_mae: 7.0215 - val_mse: 93.6421\n",
      "Epoch 178/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 31.7786 - mae: 4.2469 - mse: 31.7786 - val_loss: 102.3830 - val_mae: 7.1508 - val_mse: 102.3830\n",
      "Epoch 179/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 31.1094 - mae: 4.2269 - mse: 31.1094 - val_loss: 58.1532 - val_mae: 5.4767 - val_mse: 58.1532\n",
      "Epoch 180/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 30.4182 - mae: 4.1531 - mse: 30.4181 - val_loss: 77.0995 - val_mae: 6.2523 - val_mse: 77.0995\n",
      "Epoch 181/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 30.9996 - mae: 4.2065 - mse: 30.9996 - val_loss: 88.2848 - val_mae: 6.7959 - val_mse: 88.2848\n",
      "Epoch 182/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 30.9928 - mae: 4.2003 - mse: 30.9928 - val_loss: 67.0152 - val_mae: 5.8864 - val_mse: 67.0152\n",
      "Epoch 183/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 30.4750 - mae: 4.1683 - mse: 30.4750 - val_loss: 96.8474 - val_mae: 6.9841 - val_mse: 96.8474\n",
      "Epoch 184/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 30.1100 - mae: 4.1492 - mse: 30.1100 - val_loss: 69.7322 - val_mae: 5.9097 - val_mse: 69.7322\n",
      "Epoch 185/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 29.4891 - mae: 4.1041 - mse: 29.4891 - val_loss: 66.0974 - val_mae: 5.7382 - val_mse: 66.0974\n",
      "Epoch 186/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 29.4395 - mae: 4.0550 - mse: 29.4395 - val_loss: 80.1265 - val_mae: 6.5887 - val_mse: 80.1265\n",
      "Epoch 187/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 29.4349 - mae: 4.0909 - mse: 29.4348 - val_loss: 72.2243 - val_mae: 6.1200 - val_mse: 72.2243\n",
      "Epoch 188/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 29.2156 - mae: 4.0918 - mse: 29.2156 - val_loss: 168.2058 - val_mae: 9.4652 - val_mse: 168.2058\n",
      "Epoch 189/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 29.6096 - mae: 4.1056 - mse: 29.6096 - val_loss: 66.5433 - val_mae: 5.9399 - val_mse: 66.5433\n",
      "Epoch 190/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 28.3550 - mae: 4.0171 - mse: 28.3550 - val_loss: 69.4650 - val_mae: 5.9971 - val_mse: 69.4650\n",
      "Epoch 191/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 28.8740 - mae: 4.0797 - mse: 28.8740 - val_loss: 63.7842 - val_mae: 5.6009 - val_mse: 63.7842\n",
      "Epoch 192/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 28.2274 - mae: 4.0275 - mse: 28.2274 - val_loss: 60.7383 - val_mae: 5.5561 - val_mse: 60.7383\n",
      "Epoch 193/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 28.5283 - mae: 4.0298 - mse: 28.5282 - val_loss: 78.3265 - val_mae: 6.5153 - val_mse: 78.3265\n",
      "Epoch 194/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 27.8056 - mae: 3.9927 - mse: 27.8057 - val_loss: 63.0496 - val_mae: 5.5188 - val_mse: 63.0496\n",
      "Epoch 195/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 27.3411 - mae: 3.9416 - mse: 27.3411 - val_loss: 74.5151 - val_mae: 6.3440 - val_mse: 74.5151\n",
      "Epoch 196/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 27.5637 - mae: 3.9507 - mse: 27.5637 - val_loss: 77.9324 - val_mae: 6.2133 - val_mse: 77.9324\n",
      "Epoch 197/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 26.8853 - mae: 3.9071 - mse: 26.8853 - val_loss: 73.6368 - val_mae: 6.1595 - val_mse: 73.6368\n",
      "Epoch 198/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 27.5925 - mae: 3.9713 - mse: 27.5925 - val_loss: 65.8501 - val_mae: 5.7259 - val_mse: 65.8501\n",
      "Epoch 199/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 27.0087 - mae: 3.9500 - mse: 27.0087 - val_loss: 59.7573 - val_mae: 5.5123 - val_mse: 59.7573\n",
      "Epoch 200/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 26.1098 - mae: 3.8566 - mse: 26.1098 - val_loss: 80.7983 - val_mae: 6.5825 - val_mse: 80.7984\n",
      "Epoch 201/750\n",
      "15704/15704 [==============================] - 23s 1ms/step - loss: 26.5199 - mae: 3.8777 - mse: 26.5199 - val_loss: 79.6253 - val_mae: 6.4880 - val_mse: 79.6253\n",
      "Epoch 202/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 25.9159 - mae: 3.8604 - mse: 25.9160 - val_loss: 60.6971 - val_mae: 5.7032 - val_mse: 60.6971\n",
      "Epoch 203/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 26.5030 - mae: 3.9006 - mse: 26.5031 - val_loss: 96.4841 - val_mae: 7.4020 - val_mse: 96.4841\n",
      "Epoch 204/750\n",
      "15704/15704 [==============================] - 23s 1ms/step - loss: 26.7267 - mae: 3.9226 - mse: 26.7267 - val_loss: 117.9526 - val_mae: 8.0599 - val_mse: 117.9526s: 26.7238 - mae: 3.9241 - m\n",
      "Epoch 205/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 25.6361 - mae: 3.8120 - mse: 25.6361 - val_loss: 54.9123 - val_mae: 5.2671 - val_mse: 54.9123\n",
      "Epoch 206/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 25.9839 - mae: 3.8235 - mse: 25.9839 - val_loss: 61.6350 - val_mae: 5.6009 - val_mse: 61.6350\n",
      "Epoch 207/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 25.6918 - mae: 3.8296 - mse: 25.6918 - val_loss: 51.7197 - val_mae: 5.0713 - val_mse: 51.7197\n",
      "Epoch 208/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 25.0550 - mae: 3.7625 - mse: 25.0550 - val_loss: 64.3767 - val_mae: 5.6831 - val_mse: 64.3768\n",
      "Epoch 209/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 24.8212 - mae: 3.7401 - mse: 24.8212 - val_loss: 69.5270 - val_mae: 6.1595 - val_mse: 69.5270\n",
      "Epoch 210/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 25.2691 - mae: 3.7612 - mse: 25.2691 - val_loss: 78.6234 - val_mae: 6.6589 - val_mse: 78.6234\n",
      "Epoch 211/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 25.2382 - mae: 3.8038 - mse: 25.2382 - val_loss: 105.1527 - val_mae: 7.2193 - val_mse: 105.1527\n",
      "Epoch 212/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 24.6015 - mae: 3.6933 - mse: 24.6015 - val_loss: 68.4889 - val_mae: 6.1249 - val_mse: 68.4889\n",
      "Epoch 213/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 24.5892 - mae: 3.7415 - mse: 24.5892 - val_loss: 71.5517 - val_mae: 5.9444 - val_mse: 71.5517\n",
      "Epoch 214/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 24.6004 - mae: 3.7208 - mse: 24.6005 - val_loss: 63.4365 - val_mae: 5.6338 - val_mse: 63.4366\n",
      "Epoch 215/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 24.8263 - mae: 3.7530 - mse: 24.8263 - val_loss: 64.3692 - val_mae: 5.9266 - val_mse: 64.3692\n",
      "Epoch 216/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 23.8154 - mae: 3.6617 - mse: 23.8153 - val_loss: 62.7349 - val_mae: 5.5420 - val_mse: 62.7349\n",
      "Epoch 217/750\n",
      "15704/15704 [==============================] - 23s 1ms/step - loss: 23.6077 - mae: 3.6755 - mse: 23.6077 - val_loss: 82.6952 - val_mae: 6.7817 - val_mse: 82.6952\n",
      "Epoch 218/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 23.5813 - mae: 3.6758 - mse: 23.5813 - val_loss: 57.5827 - val_mae: 5.3424 - val_mse: 57.5827\n",
      "Epoch 219/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 24.0543 - mae: 3.6829 - mse: 24.0543 - val_loss: 59.0694 - val_mae: 5.4263 - val_mse: 59.0694\n",
      "Epoch 220/750\n",
      "15704/15704 [==============================] - 23s 1ms/step - loss: 23.5271 - mae: 3.6471 - mse: 23.5271 - val_loss: 79.1772 - val_mae: 6.6680 - val_mse: 79.1772\n",
      "Epoch 221/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 23.6912 - mae: 3.6631 - mse: 23.6912 - val_loss: 68.8058 - val_mae: 5.8312 - val_mse: 68.8058\n",
      "Epoch 222/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 23.6218 - mae: 3.6772 - mse: 23.6218 - val_loss: 53.5512 - val_mae: 5.1973 - val_mse: 53.5512\n",
      "Epoch 223/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 22.7819 - mae: 3.6055 - mse: 22.7819 - val_loss: 69.7932 - val_mae: 6.1274 - val_mse: 69.7932\n",
      "Epoch 224/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 22.9440 - mae: 3.6148 - mse: 22.9440 - val_loss: 72.6220 - val_mae: 6.2501 - val_mse: 72.6220\n",
      "Epoch 225/750\n",
      "15704/15704 [==============================] - 23s 1ms/step - loss: 22.7584 - mae: 3.5866 - mse: 22.7584 - val_loss: 59.7271 - val_mae: 5.4994 - val_mse: 59.7271\n",
      "Epoch 226/750\n",
      "15704/15704 [==============================] - 23s 1ms/step - loss: 22.6460 - mae: 3.6040 - mse: 22.6460 - val_loss: 103.6095 - val_mae: 7.9926 - val_mse: 103.6095\n",
      "Epoch 227/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 22.5266 - mae: 3.5689 - mse: 22.5266 - val_loss: 85.0617 - val_mae: 6.6989 - val_mse: 85.0617\n",
      "Epoch 228/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 22.3561 - mae: 3.5964 - mse: 22.3561 - val_loss: 47.2393 - val_mae: 4.8331 - val_mse: 47.2393\n",
      "Epoch 229/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 22.5612 - mae: 3.5781 - mse: 22.5612 - val_loss: 70.4879 - val_mae: 6.2445 - val_mse: 70.4879\n",
      "Epoch 230/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 21.6427 - mae: 3.5214 - mse: 21.6427 - val_loss: 54.2928 - val_mae: 5.1926 - val_mse: 54.2928\n",
      "Epoch 231/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 21.8104 - mae: 3.5273 - mse: 21.8104 - val_loss: 62.0735 - val_mae: 5.7062 - val_mse: 62.0736\n",
      "Epoch 232/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 21.7539 - mae: 3.5151 - mse: 21.7539 - val_loss: 55.7682 - val_mae: 5.2472 - val_mse: 55.7682\n",
      "Epoch 233/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 21.0591 - mae: 3.4811 - mse: 21.0591 - val_loss: 52.1798 - val_mae: 5.0298 - val_mse: 52.1798\n",
      "Epoch 234/750\n",
      "15704/15704 [==============================] - 23s 1ms/step - loss: 21.4997 - mae: 3.4924 - mse: 21.4997 - val_loss: 73.5026 - val_mae: 6.2612 - val_mse: 73.5026\n",
      "Epoch 235/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 21.2092 - mae: 3.4776 - mse: 21.2092 - val_loss: 71.8933 - val_mae: 6.2333 - val_mse: 71.8933\n",
      "Epoch 236/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 21.5162 - mae: 3.4927 - mse: 21.5162 - val_loss: 56.8755 - val_mae: 5.3046 - val_mse: 56.8755\n",
      "Epoch 237/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 21.2376 - mae: 3.4604 - mse: 21.2376 - val_loss: 54.2565 - val_mae: 5.0964 - val_mse: 54.2565\n",
      "Epoch 238/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 20.8935 - mae: 3.4502 - mse: 20.8935 - val_loss: 59.1667 - val_mae: 5.4181 - val_mse: 59.1667\n",
      "Epoch 239/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 20.8600 - mae: 3.4446 - mse: 20.8600 - val_loss: 63.7552 - val_mae: 5.5878 - val_mse: 63.7552\n",
      "Epoch 240/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 20.3577 - mae: 3.3877 - mse: 20.3577 - val_loss: 94.2887 - val_mae: 7.1986 - val_mse: 94.2887\n",
      "Epoch 241/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 21.1885 - mae: 3.4531 - mse: 21.1885 - val_loss: 60.3542 - val_mae: 5.4388 - val_mse: 60.3542\n",
      "Epoch 242/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 20.9195 - mae: 3.4754 - mse: 20.9195 - val_loss: 64.2920 - val_mae: 5.6501 - val_mse: 64.2920\n",
      "Epoch 243/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 20.3498 - mae: 3.3988 - mse: 20.3498 - val_loss: 64.5786 - val_mae: 5.7006 - val_mse: 64.5785\n",
      "Epoch 244/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 20.6186 - mae: 3.4306 - mse: 20.6185 - val_loss: 56.9606 - val_mae: 5.4496 - val_mse: 56.9606\n",
      "Epoch 245/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 20.4016 - mae: 3.4267 - mse: 20.4016 - val_loss: 59.1335 - val_mae: 5.3660 - val_mse: 59.1336\n",
      "Epoch 246/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 20.1622 - mae: 3.3901 - mse: 20.1622 - val_loss: 58.8724 - val_mae: 5.4895 - val_mse: 58.8724\n",
      "Epoch 247/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 20.0118 - mae: 3.3808 - mse: 20.0118 - val_loss: 50.5473 - val_mae: 4.9443 - val_mse: 50.5473\n",
      "Epoch 248/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 19.7718 - mae: 3.3630 - mse: 19.7718 - val_loss: 57.6198 - val_mae: 5.2925 - val_mse: 57.6198\n",
      "Epoch 249/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 19.9898 - mae: 3.3617 - mse: 19.9898 - val_loss: 51.7748 - val_mae: 4.9335 - val_mse: 51.7748\n",
      "Epoch 250/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 19.5840 - mae: 3.3418 - mse: 19.5840 - val_loss: 68.1849 - val_mae: 6.0870 - val_mse: 68.1849\n",
      "Epoch 251/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 19.1721 - mae: 3.3102 - mse: 19.1721 - val_loss: 47.2815 - val_mae: 4.9149 - val_mse: 47.2815\n",
      "Epoch 252/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 19.2207 - mae: 3.3159 - mse: 19.2207 - val_loss: 46.5091 - val_mae: 4.7621 - val_mse: 46.5091\n",
      "Epoch 253/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 19.1546 - mae: 3.2925 - mse: 19.1546 - val_loss: 68.3131 - val_mae: 5.7947 - val_mse: 68.3131\n",
      "Epoch 254/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 19.1796 - mae: 3.3006 - mse: 19.1795 - val_loss: 62.2679 - val_mae: 5.4847 - val_mse: 62.2679\n",
      "Epoch 255/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 18.9069 - mae: 3.2874 - mse: 18.9069 - val_loss: 61.8539 - val_mae: 5.4449 - val_mse: 61.8538\n",
      "Epoch 256/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 18.9425 - mae: 3.2864 - mse: 18.9425 - val_loss: 61.3295 - val_mae: 5.7071 - val_mse: 61.3295\n",
      "Epoch 257/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 19.0674 - mae: 3.2843 - mse: 19.0674 - val_loss: 67.5811 - val_mae: 5.8932 - val_mse: 67.5811\n",
      "Epoch 258/750\n",
      "15704/15704 [==============================] - 23s 1ms/step - loss: 19.1365 - mae: 3.2971 - mse: 19.1365 - val_loss: 68.0894 - val_mae: 6.0485 - val_mse: 68.0894\n",
      "Epoch 259/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 18.5402 - mae: 3.2434 - mse: 18.5401 - val_loss: 65.0672 - val_mae: 5.5630 - val_mse: 65.0672\n",
      "Epoch 260/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 18.4479 - mae: 3.2478 - mse: 18.4479 - val_loss: 49.1371 - val_mae: 4.9690 - val_mse: 49.1371\n",
      "Epoch 261/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 18.2492 - mae: 3.1997 - mse: 18.2492 - val_loss: 52.5146 - val_mae: 5.0281 - val_mse: 52.5146\n",
      "Epoch 262/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 18.3817 - mae: 3.2225 - mse: 18.3817 - val_loss: 80.5791 - val_mae: 6.1617 - val_mse: 80.5791\n",
      "Epoch 263/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 18.3235 - mae: 3.2372 - mse: 18.3235 - val_loss: 58.6879 - val_mae: 5.2457 - val_mse: 58.6879\n",
      "Epoch 264/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 18.2767 - mae: 3.2250 - mse: 18.2767 - val_loss: 51.7267 - val_mae: 5.0816 - val_mse: 51.7267\n",
      "Epoch 265/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 18.2492 - mae: 3.2162 - mse: 18.2492 - val_loss: 94.9340 - val_mae: 6.9655 - val_mse: 94.9340\n",
      "Epoch 266/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 18.5178 - mae: 3.2314 - mse: 18.5178 - val_loss: 46.8557 - val_mae: 4.7562 - val_mse: 46.8557\n",
      "Epoch 267/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 18.0083 - mae: 3.1933 - mse: 18.0083 - val_loss: 60.5876 - val_mae: 5.7130 - val_mse: 60.5876\n",
      "Epoch 268/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 17.8179 - mae: 3.2023 - mse: 17.8179 - val_loss: 52.4509 - val_mae: 5.1414 - val_mse: 52.4509\n",
      "Epoch 269/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 17.8644 - mae: 3.1887 - mse: 17.8644 - val_loss: 54.0457 - val_mae: 5.2156 - val_mse: 54.0457\n",
      "Epoch 270/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 17.3007 - mae: 3.1569 - mse: 17.3007 - val_loss: 61.7693 - val_mae: 5.4904 - val_mse: 61.7693\n",
      "Epoch 271/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 17.8338 - mae: 3.1757 - mse: 17.8338 - val_loss: 69.3770 - val_mae: 6.1480 - val_mse: 69.3770\n",
      "Epoch 272/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 17.4578 - mae: 3.1770 - mse: 17.4578 - val_loss: 52.2769 - val_mae: 5.1425 - val_mse: 52.2769\n",
      "Epoch 273/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 17.1685 - mae: 3.1199 - mse: 17.1685 - val_loss: 54.7690 - val_mae: 5.2325 - val_mse: 54.7690\n",
      "Epoch 274/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 17.0142 - mae: 3.1076 - mse: 17.0142 - val_loss: 67.4114 - val_mae: 6.0186 - val_mse: 67.4114\n",
      "Epoch 275/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 17.2024 - mae: 3.1348 - mse: 17.2024 - val_loss: 65.1350 - val_mae: 5.6378 - val_mse: 65.1350\n",
      "Epoch 276/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 17.1428 - mae: 3.1096 - mse: 17.1428 - val_loss: 47.8389 - val_mae: 4.8058 - val_mse: 47.8389\n",
      "Epoch 277/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 16.7961 - mae: 3.0821 - mse: 16.7961 - val_loss: 50.3109 - val_mae: 4.8398 - val_mse: 50.3109\n",
      "Epoch 278/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 16.8750 - mae: 3.0820 - mse: 16.8750 - val_loss: 49.0146 - val_mae: 4.8632 - val_mse: 49.0146\n",
      "Epoch 279/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 16.6853 - mae: 3.0997 - mse: 16.6853 - val_loss: 52.1821 - val_mae: 5.0336 - val_mse: 52.1821\n",
      "Epoch 280/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 17.1136 - mae: 3.0901 - mse: 17.1136 - val_loss: 49.3717 - val_mae: 4.8889 - val_mse: 49.3717\n",
      "Epoch 281/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 17.0340 - mae: 3.1235 - mse: 17.0340 - val_loss: 59.3500 - val_mae: 5.4108 - val_mse: 59.3500\n",
      "Epoch 282/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 16.8159 - mae: 3.0704 - mse: 16.8159 - val_loss: 55.3171 - val_mae: 5.1647 - val_mse: 55.3171\n",
      "Epoch 283/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 16.6588 - mae: 3.0732 - mse: 16.6588 - val_loss: 59.1314 - val_mae: 5.4119 - val_mse: 59.1314\n",
      "Epoch 284/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 15.9723 - mae: 3.0190 - mse: 15.9723 - val_loss: 51.4975 - val_mae: 4.9460 - val_mse: 51.4975\n",
      "Epoch 285/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 16.2324 - mae: 3.0670 - mse: 16.2324 - val_loss: 63.5884 - val_mae: 5.5958 - val_mse: 63.5884\n",
      "Epoch 286/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 16.4516 - mae: 3.0741 - mse: 16.4516 - val_loss: 47.9451 - val_mae: 4.7468 - val_mse: 47.9451\n",
      "Epoch 287/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 16.2350 - mae: 3.0470 - mse: 16.2350 - val_loss: 71.0291 - val_mae: 6.2704 - val_mse: 71.0292\n",
      "Epoch 288/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 16.1030 - mae: 3.0267 - mse: 16.1030 - val_loss: 51.5460 - val_mae: 4.9706 - val_mse: 51.5460\n",
      "Epoch 289/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 16.1546 - mae: 3.0282 - mse: 16.1546 - val_loss: 55.9448 - val_mae: 5.1294 - val_mse: 55.9448\n",
      "Epoch 290/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 16.0750 - mae: 3.0462 - mse: 16.0750 - val_loss: 78.9912 - val_mae: 6.6745 - val_mse: 78.9912\n",
      "Epoch 291/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 16.0261 - mae: 3.0311 - mse: 16.0261 - val_loss: 95.9892 - val_mae: 7.0917 - val_mse: 95.9892\n",
      "Epoch 292/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 15.7622 - mae: 2.9892 - mse: 15.7622 - val_loss: 48.8076 - val_mae: 4.9825 - val_mse: 48.8076\n",
      "Epoch 293/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 15.7242 - mae: 2.9885 - mse: 15.7242 - val_loss: 55.6323 - val_mae: 5.3167 - val_mse: 55.6324\n",
      "Epoch 294/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 15.4949 - mae: 2.9724 - mse: 15.4949 - val_loss: 48.4370 - val_mae: 4.8361 - val_mse: 48.4370\n",
      "Epoch 295/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 15.7352 - mae: 3.0043 - mse: 15.7352 - val_loss: 63.5222 - val_mae: 5.8458 - val_mse: 63.5222\n",
      "Epoch 296/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 15.4895 - mae: 2.9803 - mse: 15.4895 - val_loss: 58.3032 - val_mae: 5.2680 - val_mse: 58.3032\n",
      "Epoch 297/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 15.6132 - mae: 2.9754 - mse: 15.6132 - val_loss: 51.4119 - val_mae: 4.9512 - val_mse: 51.4119\n",
      "Epoch 298/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 15.1918 - mae: 2.9408 - mse: 15.1918 - val_loss: 82.3261 - val_mae: 6.8915 - val_mse: 82.3261\n",
      "Epoch 299/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 15.0423 - mae: 2.9194 - mse: 15.0423 - val_loss: 62.8661 - val_mae: 5.7968 - val_mse: 62.8661\n",
      "Epoch 300/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 15.5836 - mae: 2.9700 - mse: 15.5836 - val_loss: 50.2131 - val_mae: 4.8857 - val_mse: 50.2131\n",
      "Epoch 301/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 15.0304 - mae: 2.9337 - mse: 15.0304 - val_loss: 51.3944 - val_mae: 4.9368 - val_mse: 51.3944\n",
      "Epoch 302/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 15.3059 - mae: 2.9444 - mse: 15.3059 - val_loss: 52.7227 - val_mae: 4.9842 - val_mse: 52.7227\n",
      "Epoch 303/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 14.9514 - mae: 2.9117 - mse: 14.9514 - val_loss: 46.3411 - val_mae: 4.7915 - val_mse: 46.3411\n",
      "Epoch 304/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 14.5634 - mae: 2.8946 - mse: 14.5634 - val_loss: 51.1260 - val_mae: 5.1586 - val_mse: 51.1260\n",
      "Epoch 305/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 14.9076 - mae: 2.9342 - mse: 14.9076 - val_loss: 67.7725 - val_mae: 6.0750 - val_mse: 67.7725\n",
      "Epoch 306/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 15.1692 - mae: 2.9335 - mse: 15.1692 - val_loss: 49.9198 - val_mae: 5.0169 - val_mse: 49.9198\n",
      "Epoch 307/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 14.6294 - mae: 2.8939 - mse: 14.6294 - val_loss: 49.9440 - val_mae: 4.8859 - val_mse: 49.9441\n",
      "Epoch 308/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 14.7066 - mae: 2.8632 - mse: 14.7066 - val_loss: 64.2099 - val_mae: 5.7280 - val_mse: 64.2099\n",
      "Epoch 309/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 14.3816 - mae: 2.8575 - mse: 14.3816 - val_loss: 45.5510 - val_mae: 4.6443 - val_mse: 45.5510\n",
      "Epoch 310/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 14.5696 - mae: 2.8680 - mse: 14.5696 - val_loss: 49.4560 - val_mae: 4.8460 - val_mse: 49.4560\n",
      "Epoch 311/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 14.3173 - mae: 2.8639 - mse: 14.3173 - val_loss: 69.7048 - val_mae: 6.1433 - val_mse: 69.7048\n",
      "Epoch 312/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 14.4413 - mae: 2.8749 - mse: 14.4413 - val_loss: 54.9565 - val_mae: 5.2853 - val_mse: 54.9565\n",
      "Epoch 313/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 14.4860 - mae: 2.8617 - mse: 14.4860 - val_loss: 56.8182 - val_mae: 5.4667 - val_mse: 56.8182\n",
      "Epoch 314/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 14.2254 - mae: 2.8441 - mse: 14.2254 - val_loss: 68.6701 - val_mae: 6.0444 - val_mse: 68.6701\n",
      "Epoch 315/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 14.3373 - mae: 2.8566 - mse: 14.3373 - val_loss: 53.8146 - val_mae: 5.0800 - val_mse: 53.8146\n",
      "Epoch 316/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 13.9870 - mae: 2.8215 - mse: 13.9870 - val_loss: 51.5328 - val_mae: 4.9236 - val_mse: 51.5328\n",
      "Epoch 317/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 14.3556 - mae: 2.8643 - mse: 14.3556 - val_loss: 62.4603 - val_mae: 5.5701 - val_mse: 62.4602\n",
      "Epoch 318/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 14.3757 - mae: 2.8387 - mse: 14.3757 - val_loss: 70.3042 - val_mae: 5.8056 - val_mse: 70.3042\n",
      "Epoch 319/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 14.2716 - mae: 2.8528 - mse: 14.2716 - val_loss: 55.6489 - val_mae: 5.2669 - val_mse: 55.6489\n",
      "Epoch 320/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 13.8315 - mae: 2.7974 - mse: 13.8316 - val_loss: 49.4645 - val_mae: 4.8766 - val_mse: 49.4645\n",
      "Epoch 321/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 14.1102 - mae: 2.8250 - mse: 14.1102 - val_loss: 44.7547 - val_mae: 4.6589 - val_mse: 44.7547\n",
      "Epoch 322/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 13.6207 - mae: 2.8036 - mse: 13.6207 - val_loss: 54.6301 - val_mae: 5.2555 - val_mse: 54.6302\n",
      "Epoch 323/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 13.7760 - mae: 2.8286 - mse: 13.7760 - val_loss: 49.3273 - val_mae: 4.9614 - val_mse: 49.3273\n",
      "Epoch 324/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 13.6763 - mae: 2.7867 - mse: 13.6763 - val_loss: 57.8468 - val_mae: 5.3231 - val_mse: 57.8468\n",
      "Epoch 325/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 13.7339 - mae: 2.7861 - mse: 13.7339 - val_loss: 55.3508 - val_mae: 5.2632 - val_mse: 55.3508\n",
      "Epoch 326/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 13.8656 - mae: 2.8236 - mse: 13.8656 - val_loss: 79.5359 - val_mae: 6.2387 - val_mse: 79.5359\n",
      "Epoch 327/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 13.6553 - mae: 2.7950 - mse: 13.6553 - val_loss: 48.0997 - val_mae: 4.7216 - val_mse: 48.0997\n",
      "Epoch 328/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 13.9150 - mae: 2.7880 - mse: 13.9150 - val_loss: 44.9947 - val_mae: 4.6820 - val_mse: 44.9947\n",
      "Epoch 329/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 13.2927 - mae: 2.7403 - mse: 13.2927 - val_loss: 75.3665 - val_mae: 6.1094 - val_mse: 75.3665\n",
      "Epoch 330/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 13.2352 - mae: 2.7549 - mse: 13.2352 - val_loss: 50.3494 - val_mae: 4.9174 - val_mse: 50.3494\n",
      "Epoch 331/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 13.0749 - mae: 2.7554 - mse: 13.0748 - val_loss: 46.2418 - val_mae: 4.8032 - val_mse: 46.2418\n",
      "Epoch 332/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 13.1356 - mae: 2.7355 - mse: 13.1356 - val_loss: 90.1159 - val_mae: 7.3879 - val_mse: 90.1159\n",
      "Epoch 333/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 13.2134 - mae: 2.7445 - mse: 13.2134 - val_loss: 68.6138 - val_mae: 5.9312 - val_mse: 68.6138\n",
      "Epoch 334/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 13.2989 - mae: 2.7589 - mse: 13.2989 - val_loss: 46.9593 - val_mae: 4.7760 - val_mse: 46.9593\n",
      "Epoch 335/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 12.9057 - mae: 2.7069 - mse: 12.9057 - val_loss: 51.1808 - val_mae: 5.0741 - val_mse: 51.1808\n",
      "Epoch 336/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 13.1136 - mae: 2.7388 - mse: 13.1136 - val_loss: 41.1394 - val_mae: 4.4530 - val_mse: 41.1394\n",
      "Epoch 337/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 13.0709 - mae: 2.7322 - mse: 13.0709 - val_loss: 44.3987 - val_mae: 4.6396 - val_mse: 44.3987\n",
      "Epoch 338/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 12.9000 - mae: 2.7221 - mse: 12.9000 - val_loss: 56.9865 - val_mae: 5.3998 - val_mse: 56.9866\n",
      "Epoch 339/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 13.0059 - mae: 2.7254 - mse: 13.0059 - val_loss: 53.7259 - val_mae: 5.0160 - val_mse: 53.7260\n",
      "Epoch 340/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 12.7754 - mae: 2.7103 - mse: 12.7754 - val_loss: 40.6326 - val_mae: 4.3556 - val_mse: 40.6326\n",
      "Epoch 341/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 12.5817 - mae: 2.6700 - mse: 12.5817 - val_loss: 42.5032 - val_mae: 4.4388 - val_mse: 42.5032\n",
      "Epoch 342/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 12.9652 - mae: 2.7132 - mse: 12.9652 - val_loss: 46.7792 - val_mae: 4.8275 - val_mse: 46.7792\n",
      "Epoch 343/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 12.8716 - mae: 2.7332 - mse: 12.8717 - val_loss: 56.0381 - val_mae: 5.3776 - val_mse: 56.0381\n",
      "Epoch 344/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 12.2892 - mae: 2.6542 - mse: 12.2892 - val_loss: 44.7347 - val_mae: 4.6440 - val_mse: 44.7347\n",
      "Epoch 345/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 12.6795 - mae: 2.6791 - mse: 12.6795 - val_loss: 51.5168 - val_mae: 4.9128 - val_mse: 51.5168\n",
      "Epoch 346/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 12.2387 - mae: 2.6454 - mse: 12.2387 - val_loss: 44.4837 - val_mae: 4.6558 - val_mse: 44.4837\n",
      "Epoch 347/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 12.5701 - mae: 2.6680 - mse: 12.5701 - val_loss: 41.6271 - val_mae: 4.4545 - val_mse: 41.6270\n",
      "Epoch 348/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 12.4257 - mae: 2.6595 - mse: 12.4257 - val_loss: 54.8198 - val_mae: 5.1685 - val_mse: 54.8198\n",
      "Epoch 349/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 12.4274 - mae: 2.6521 - mse: 12.4274 - val_loss: 50.8003 - val_mae: 4.8109 - val_mse: 50.8003\n",
      "Epoch 350/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 12.2328 - mae: 2.6335 - mse: 12.2328 - val_loss: 54.4083 - val_mae: 5.1736 - val_mse: 54.4083\n",
      "Epoch 351/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 12.1248 - mae: 2.6235 - mse: 12.1248 - val_loss: 43.6528 - val_mae: 4.5408 - val_mse: 43.6528\n",
      "Epoch 352/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 12.1552 - mae: 2.6296 - mse: 12.1552 - val_loss: 62.0094 - val_mae: 5.6834 - val_mse: 62.0094\n",
      "Epoch 353/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 12.0786 - mae: 2.6074 - mse: 12.0786 - val_loss: 77.8101 - val_mae: 6.2505 - val_mse: 77.8101\n",
      "Epoch 354/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 12.2121 - mae: 2.6319 - mse: 12.2121 - val_loss: 42.9008 - val_mae: 4.5534 - val_mse: 42.9009\n",
      "Epoch 355/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 12.0898 - mae: 2.6244 - mse: 12.0898 - val_loss: 42.4119 - val_mae: 4.4558 - val_mse: 42.4118\n",
      "Epoch 356/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.9412 - mae: 2.6031 - mse: 11.9412 - val_loss: 49.1739 - val_mae: 5.1260 - val_mse: 49.1739\n",
      "Epoch 357/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.8809 - mae: 2.6000 - mse: 11.8809 - val_loss: 47.2809 - val_mae: 4.7068 - val_mse: 47.2809\n",
      "Epoch 358/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 12.0048 - mae: 2.6112 - mse: 12.0048 - val_loss: 43.5685 - val_mae: 4.5935 - val_mse: 43.5685\n",
      "Epoch 359/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.8318 - mae: 2.6013 - mse: 11.8318 - val_loss: 66.1103 - val_mae: 5.5401 - val_mse: 66.1103\n",
      "Epoch 360/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.9223 - mae: 2.6009 - mse: 11.9223 - val_loss: 44.6491 - val_mae: 4.6723 - val_mse: 44.6492\n",
      "Epoch 361/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.7520 - mae: 2.5911 - mse: 11.7520 - val_loss: 42.7368 - val_mae: 4.5227 - val_mse: 42.7368\n",
      "Epoch 362/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.6863 - mae: 2.5824 - mse: 11.6863 - val_loss: 42.9162 - val_mae: 4.5302 - val_mse: 42.9162\n",
      "Epoch 363/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.8492 - mae: 2.6112 - mse: 11.8492 - val_loss: 57.6831 - val_mae: 5.3096 - val_mse: 57.6831\n",
      "Epoch 364/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.8808 - mae: 2.6058 - mse: 11.8808 - val_loss: 51.8998 - val_mae: 5.0740 - val_mse: 51.8998\n",
      "Epoch 365/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.7441 - mae: 2.5818 - mse: 11.7441 - val_loss: 42.9795 - val_mae: 4.4927 - val_mse: 42.9795\n",
      "Epoch 366/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.5585 - mae: 2.5500 - mse: 11.5585 - val_loss: 41.8696 - val_mae: 4.4375 - val_mse: 41.8696\n",
      "Epoch 367/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.4621 - mae: 2.5612 - mse: 11.4621 - val_loss: 71.9288 - val_mae: 6.0429 - val_mse: 71.9288\n",
      "Epoch 368/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.5179 - mae: 2.5584 - mse: 11.5179 - val_loss: 44.6359 - val_mae: 4.5981 - val_mse: 44.6359\n",
      "Epoch 369/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.5871 - mae: 2.5691 - mse: 11.5871 - val_loss: 44.7675 - val_mae: 4.5863 - val_mse: 44.7675\n",
      "Epoch 370/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.4446 - mae: 2.5457 - mse: 11.4446 - val_loss: 38.0718 - val_mae: 4.2838 - val_mse: 38.0718\n",
      "Epoch 371/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.6178 - mae: 2.5747 - mse: 11.6178 - val_loss: 51.5493 - val_mae: 4.9447 - val_mse: 51.5493\n",
      "Epoch 372/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.4690 - mae: 2.5619 - mse: 11.4690 - val_loss: 45.8182 - val_mae: 4.7291 - val_mse: 45.8182\n",
      "Epoch 373/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.4970 - mae: 2.5609 - mse: 11.4970 - val_loss: 47.7670 - val_mae: 4.9657 - val_mse: 47.7670\n",
      "Epoch 374/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.2381 - mae: 2.5395 - mse: 11.2381 - val_loss: 45.8433 - val_mae: 4.7652 - val_mse: 45.8433\n",
      "Epoch 375/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.2117 - mae: 2.5272 - mse: 11.2117 - val_loss: 41.3848 - val_mae: 4.4230 - val_mse: 41.3848\n",
      "Epoch 376/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.0464 - mae: 2.5187 - mse: 11.0464 - val_loss: 47.4065 - val_mae: 4.8848 - val_mse: 47.4065\n",
      "Epoch 377/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.2967 - mae: 2.5408 - mse: 11.2967 - val_loss: 46.0866 - val_mae: 4.8009 - val_mse: 46.0866\n",
      "Epoch 378/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.0893 - mae: 2.5225 - mse: 11.0893 - val_loss: 41.1465 - val_mae: 4.5489 - val_mse: 41.1465\n",
      "Epoch 379/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.1287 - mae: 2.5192 - mse: 11.1287 - val_loss: 46.4628 - val_mae: 4.8041 - val_mse: 46.4628\n",
      "Epoch 380/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.8647 - mae: 2.4932 - mse: 10.8647 - val_loss: 43.5209 - val_mae: 4.6055 - val_mse: 43.5209\n",
      "Epoch 381/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.1047 - mae: 2.5119 - mse: 11.1047 - val_loss: 43.2458 - val_mae: 4.5209 - val_mse: 43.2458\n",
      "Epoch 382/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 11.1026 - mae: 2.5037 - mse: 11.1026 - val_loss: 41.9743 - val_mae: 4.5213 - val_mse: 41.9743197 - mae: 2.5068 - m\n",
      "Epoch 383/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.8728 - mae: 2.4925 - mse: 10.8728 - val_loss: 58.5061 - val_mae: 5.3201 - val_mse: 58.5061\n",
      "Epoch 384/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.8088 - mae: 2.4840 - mse: 10.8088 - val_loss: 48.0603 - val_mae: 4.9694 - val_mse: 48.0603\n",
      "Epoch 385/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.8267 - mae: 2.4873 - mse: 10.8267 - val_loss: 41.3285 - val_mae: 4.4359 - val_mse: 41.3285\n",
      "Epoch 386/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.8780 - mae: 2.4814 - mse: 10.8780 - val_loss: 40.7831 - val_mae: 4.5064 - val_mse: 40.7831\n",
      "Epoch 387/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.8615 - mae: 2.4736 - mse: 10.8615 - val_loss: 50.7811 - val_mae: 4.8873 - val_mse: 50.7811\n",
      "Epoch 388/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.7569 - mae: 2.4780 - mse: 10.7569 - val_loss: 52.7451 - val_mae: 5.3273 - val_mse: 52.7451\n",
      "Epoch 389/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.7670 - mae: 2.4706 - mse: 10.7670 - val_loss: 43.2783 - val_mae: 4.6012 - val_mse: 43.2783\n",
      "Epoch 390/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.6396 - mae: 2.4677 - mse: 10.6396 - val_loss: 50.0511 - val_mae: 5.1351 - val_mse: 50.0511\n",
      "Epoch 391/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.7425 - mae: 2.4682 - mse: 10.7425 - val_loss: 43.8626 - val_mae: 4.6236 - val_mse: 43.8626\n",
      "Epoch 392/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.7347 - mae: 2.4659 - mse: 10.7347 - val_loss: 46.8255 - val_mae: 4.7341 - val_mse: 46.8255\n",
      "Epoch 393/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.6538 - mae: 2.4596 - mse: 10.6538 - val_loss: 45.3588 - val_mae: 4.7661 - val_mse: 45.3588\n",
      "Epoch 394/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.6278 - mae: 2.4588 - mse: 10.6278 - val_loss: 50.8948 - val_mae: 5.1211 - val_mse: 50.8948\n",
      "Epoch 395/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.5455 - mae: 2.4321 - mse: 10.5455 - val_loss: 47.1147 - val_mae: 4.6223 - val_mse: 47.1147\n",
      "Epoch 396/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.5289 - mae: 2.4496 - mse: 10.5289 - val_loss: 50.0428 - val_mae: 5.0724 - val_mse: 50.0428\n",
      "Epoch 397/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.3583 - mae: 2.4325 - mse: 10.3583 - val_loss: 51.6277 - val_mae: 4.9605 - val_mse: 51.6277\n",
      "Epoch 398/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.4940 - mae: 2.4532 - mse: 10.4940 - val_loss: 53.8736 - val_mae: 5.2902 - val_mse: 53.8736\n",
      "Epoch 399/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.3736 - mae: 2.4207 - mse: 10.3736 - val_loss: 63.4713 - val_mae: 5.9884 - val_mse: 63.4713\n",
      "Epoch 400/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.4391 - mae: 2.4403 - mse: 10.4391 - val_loss: 45.7330 - val_mae: 4.6967 - val_mse: 45.7330\n",
      "Epoch 401/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.5412 - mae: 2.4526 - mse: 10.5412 - val_loss: 78.0576 - val_mae: 5.9804 - val_mse: 78.0576\n",
      "Epoch 402/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.0878 - mae: 2.3933 - mse: 10.0878 - val_loss: 67.6497 - val_mae: 5.9069 - val_mse: 67.6497\n",
      "Epoch 403/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.2853 - mae: 2.4347 - mse: 10.2853 - val_loss: 57.5413 - val_mae: 5.1611 - val_mse: 57.5413\n",
      "Epoch 404/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.3340 - mae: 2.4290 - mse: 10.3340 - val_loss: 41.0900 - val_mae: 4.4832 - val_mse: 41.0900\n",
      "Epoch 405/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.2944 - mae: 2.4275 - mse: 10.2944 - val_loss: 40.8805 - val_mae: 4.3624 - val_mse: 40.8805\n",
      "Epoch 406/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.3083 - mae: 2.4205 - mse: 10.3083 - val_loss: 45.7980 - val_mae: 4.7578 - val_mse: 45.7980\n",
      "Epoch 407/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.9975 - mae: 2.3913 - mse: 9.9975 - val_loss: 45.1947 - val_mae: 4.7309 - val_mse: 45.1947\n",
      "Epoch 408/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.2563 - mae: 2.4206 - mse: 10.2563 - val_loss: 74.0081 - val_mae: 6.3251 - val_mse: 74.0081\n",
      "Epoch 409/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.0873 - mae: 2.4085 - mse: 10.0873 - val_loss: 42.3772 - val_mae: 4.5145 - val_mse: 42.3772\n",
      "Epoch 410/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.3126 - mae: 2.4105 - mse: 10.3126 - val_loss: 41.9835 - val_mae: 4.3817 - val_mse: 41.9835\n",
      "Epoch 411/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.0722 - mae: 2.3792 - mse: 10.0722 - val_loss: 43.9617 - val_mae: 4.5713 - val_mse: 43.9617\n",
      "Epoch 412/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.9504 - mae: 2.3721 - mse: 9.9504 - val_loss: 42.1455 - val_mae: 4.3784 - val_mse: 42.1455\n",
      "Epoch 413/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.7437 - mae: 2.3550 - mse: 9.7437 - val_loss: 54.2792 - val_mae: 5.0464 - val_mse: 54.2792\n",
      "Epoch 414/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.8576 - mae: 2.3678 - mse: 9.8576 - val_loss: 39.6350 - val_mae: 4.3147 - val_mse: 39.6350\n",
      "Epoch 415/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.9858 - mae: 2.3925 - mse: 9.9858 - val_loss: 42.8461 - val_mae: 4.5884 - val_mse: 42.8461\n",
      "Epoch 416/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.8956 - mae: 2.3708 - mse: 9.8956 - val_loss: 41.4435 - val_mae: 4.3853 - val_mse: 41.4436\n",
      "Epoch 417/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 10.0955 - mae: 2.3940 - mse: 10.0955 - val_loss: 47.0125 - val_mae: 4.6273 - val_mse: 47.0125\n",
      "Epoch 418/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.7004 - mae: 2.3575 - mse: 9.7004 - val_loss: 50.4915 - val_mae: 4.8348 - val_mse: 50.4915\n",
      "Epoch 419/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.9166 - mae: 2.3843 - mse: 9.9166 - val_loss: 52.2982 - val_mae: 4.9720 - val_mse: 52.2982\n",
      "Epoch 420/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.6194 - mae: 2.3434 - mse: 9.6194 - val_loss: 42.0291 - val_mae: 4.5706 - val_mse: 42.0291\n",
      "Epoch 421/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.9041 - mae: 2.3575 - mse: 9.9041 - val_loss: 39.0097 - val_mae: 4.2812 - val_mse: 39.0097\n",
      "Epoch 422/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.8613 - mae: 2.3631 - mse: 9.8613 - val_loss: 63.8006 - val_mae: 5.5182 - val_mse: 63.8006\n",
      "Epoch 423/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.6674 - mae: 2.3250 - mse: 9.6674 - val_loss: 45.2336 - val_mae: 4.6178 - val_mse: 45.2336\n",
      "Epoch 424/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.4028 - mae: 2.2976 - mse: 9.4028 - val_loss: 45.1391 - val_mae: 4.7825 - val_mse: 45.1391\n",
      "Epoch 425/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.6168 - mae: 2.3423 - mse: 9.6168 - val_loss: 56.4613 - val_mae: 5.0507 - val_mse: 56.4614\n",
      "Epoch 426/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.7237 - mae: 2.3515 - mse: 9.7237 - val_loss: 59.3570 - val_mae: 5.6894 - val_mse: 59.3570\n",
      "Epoch 427/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.5953 - mae: 2.3316 - mse: 9.5953 - val_loss: 40.8253 - val_mae: 4.3347 - val_mse: 40.8253\n",
      "Epoch 428/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.4533 - mae: 2.3283 - mse: 9.4533 - val_loss: 39.3943 - val_mae: 4.2801 - val_mse: 39.3943\n",
      "Epoch 429/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.5785 - mae: 2.3388 - mse: 9.5785 - val_loss: 38.8798 - val_mae: 4.3048 - val_mse: 38.8798\n",
      "Epoch 430/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.4709 - mae: 2.3127 - mse: 9.4709 - val_loss: 42.5047 - val_mae: 4.4401 - val_mse: 42.5047\n",
      "Epoch 431/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.4139 - mae: 2.3079 - mse: 9.4139 - val_loss: 42.7400 - val_mae: 4.5025 - val_mse: 42.7400\n",
      "Epoch 432/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.3333 - mae: 2.2956 - mse: 9.3333 - val_loss: 44.6828 - val_mae: 4.6424 - val_mse: 44.6828\n",
      "Epoch 433/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.4854 - mae: 2.3293 - mse: 9.4854 - val_loss: 39.5917 - val_mae: 4.2471 - val_mse: 39.5917\n",
      "Epoch 434/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.2234 - mae: 2.3034 - mse: 9.2234 - val_loss: 45.4910 - val_mae: 4.6074 - val_mse: 45.4910\n",
      "Epoch 435/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.3092 - mae: 2.2989 - mse: 9.3092 - val_loss: 65.2224 - val_mae: 5.4265 - val_mse: 65.2224\n",
      "Epoch 436/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.4684 - mae: 2.3094 - mse: 9.4684 - val_loss: 42.7341 - val_mae: 4.5239 - val_mse: 42.7341\n",
      "Epoch 437/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.5654 - mae: 2.3285 - mse: 9.5654 - val_loss: 42.7385 - val_mae: 4.5025 - val_mse: 42.7384\n",
      "Epoch 438/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.4173 - mae: 2.3034 - mse: 9.4173 - val_loss: 61.8642 - val_mae: 5.6825 - val_mse: 61.8642\n",
      "Epoch 439/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.0657 - mae: 2.2791 - mse: 9.0657 - val_loss: 46.0726 - val_mae: 4.8343 - val_mse: 46.0726\n",
      "Epoch 440/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.2635 - mae: 2.3048 - mse: 9.2635 - val_loss: 47.6400 - val_mae: 4.9909 - val_mse: 47.6400\n",
      "Epoch 441/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.0633 - mae: 2.2775 - mse: 9.0633 - val_loss: 52.1751 - val_mae: 4.9441 - val_mse: 52.1751\n",
      "Epoch 442/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.1752 - mae: 2.2676 - mse: 9.1752 - val_loss: 41.6580 - val_mae: 4.3041 - val_mse: 41.6580\n",
      "Epoch 443/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.1553 - mae: 2.2845 - mse: 9.1553 - val_loss: 38.1776 - val_mae: 4.2184 - val_mse: 38.1776\n",
      "Epoch 444/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.0186 - mae: 2.2698 - mse: 9.0186 - val_loss: 44.2372 - val_mae: 4.6040 - val_mse: 44.2372\n",
      "Epoch 445/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.1574 - mae: 2.2939 - mse: 9.1574 - val_loss: 42.6803 - val_mae: 4.5233 - val_mse: 42.6803\n",
      "Epoch 446/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.2010 - mae: 2.2803 - mse: 9.2010 - val_loss: 41.9864 - val_mae: 4.5586 - val_mse: 41.9864\n",
      "Epoch 447/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.1350 - mae: 2.2850 - mse: 9.1350 - val_loss: 40.1721 - val_mae: 4.2600 - val_mse: 40.1721\n",
      "Epoch 448/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.0256 - mae: 2.2683 - mse: 9.0256 - val_loss: 49.4539 - val_mae: 4.9182 - val_mse: 49.4539\n",
      "Epoch 449/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.8361 - mae: 2.2514 - mse: 8.8361 - val_loss: 47.2718 - val_mae: 4.7952 - val_mse: 47.2718\n",
      "Epoch 450/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.9600 - mae: 2.2720 - mse: 8.9600 - val_loss: 38.2107 - val_mae: 4.2150 - val_mse: 38.2107\n",
      "Epoch 451/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.1602 - mae: 2.3016 - mse: 9.1602 - val_loss: 36.6241 - val_mae: 4.0556 - val_mse: 36.6241\n",
      "Epoch 452/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.0746 - mae: 2.2764 - mse: 9.0746 - val_loss: 40.8498 - val_mae: 4.2679 - val_mse: 40.8498\n",
      "Epoch 453/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.8029 - mae: 2.2450 - mse: 8.8029 - val_loss: 45.2164 - val_mae: 4.6726 - val_mse: 45.216448 - mae: 2.\n",
      "Epoch 454/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.8592 - mae: 2.2525 - mse: 8.8592 - val_loss: 40.9874 - val_mae: 4.2802 - val_mse: 40.9874\n",
      "Epoch 455/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.7880 - mae: 2.2501 - mse: 8.7880 - val_loss: 43.8551 - val_mae: 4.4946 - val_mse: 43.8551\n",
      "Epoch 456/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.7608 - mae: 2.2464 - mse: 8.7608 - val_loss: 49.9893 - val_mae: 4.9628 - val_mse: 49.9893\n",
      "Epoch 457/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.7518 - mae: 2.2297 - mse: 8.7518 - val_loss: 38.1011 - val_mae: 4.1585 - val_mse: 38.1011\n",
      "Epoch 458/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.9296 - mae: 2.2662 - mse: 8.9296 - val_loss: 49.5413 - val_mae: 4.8507 - val_mse: 49.5413\n",
      "Epoch 459/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 9.0145 - mae: 2.2553 - mse: 9.0145 - val_loss: 37.6979 - val_mae: 4.3062 - val_mse: 37.6979\n",
      "Epoch 460/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.8436 - mae: 2.2496 - mse: 8.8436 - val_loss: 46.0345 - val_mae: 4.6304 - val_mse: 46.0345\n",
      "Epoch 461/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.7613 - mae: 2.2464 - mse: 8.7613 - val_loss: 41.6746 - val_mae: 4.5896 - val_mse: 41.6746\n",
      "Epoch 462/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.6250 - mae: 2.2124 - mse: 8.6250 - val_loss: 47.9895 - val_mae: 4.9192 - val_mse: 47.9895\n",
      "Epoch 463/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.8253 - mae: 2.2238 - mse: 8.8253 - val_loss: 40.3455 - val_mae: 4.2578 - val_mse: 40.3455\n",
      "Epoch 464/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.6651 - mae: 2.2054 - mse: 8.6651 - val_loss: 38.0337 - val_mae: 4.2814 - val_mse: 38.0337\n",
      "Epoch 465/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.7060 - mae: 2.2304 - mse: 8.7060 - val_loss: 43.9716 - val_mae: 4.6551 - val_mse: 43.9716\n",
      "Epoch 466/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.7367 - mae: 2.2305 - mse: 8.7367 - val_loss: 40.7495 - val_mae: 4.4934 - val_mse: 40.7495\n",
      "Epoch 467/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.4900 - mae: 2.2145 - mse: 8.4900 - val_loss: 51.6584 - val_mae: 5.0177 - val_mse: 51.6584\n",
      "Epoch 468/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.7907 - mae: 2.2291 - mse: 8.7907 - val_loss: 39.3936 - val_mae: 4.3480 - val_mse: 39.3936\n",
      "Epoch 469/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.6020 - mae: 2.2090 - mse: 8.6020 - val_loss: 36.3580 - val_mae: 4.1015 - val_mse: 36.3580\n",
      "Epoch 470/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.4755 - mae: 2.1938 - mse: 8.4755 - val_loss: 37.6752 - val_mae: 4.1520 - val_mse: 37.6752\n",
      "Epoch 471/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.4734 - mae: 2.1894 - mse: 8.4734 - val_loss: 45.2874 - val_mae: 4.6913 - val_mse: 45.2874\n",
      "Epoch 472/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.4093 - mae: 2.1811 - mse: 8.4093 - val_loss: 35.6495 - val_mae: 4.0268 - val_mse: 35.6495\n",
      "Epoch 473/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.6602 - mae: 2.2272 - mse: 8.6602 - val_loss: 45.2019 - val_mae: 4.5932 - val_mse: 45.2019\n",
      "Epoch 474/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.3809 - mae: 2.1846 - mse: 8.3809 - val_loss: 47.4157 - val_mae: 4.7659 - val_mse: 47.4156\n",
      "Epoch 475/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.6627 - mae: 2.2209 - mse: 8.6627 - val_loss: 46.2291 - val_mae: 4.7973 - val_mse: 46.2290\n",
      "Epoch 476/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.4699 - mae: 2.1989 - mse: 8.4699 - val_loss: 48.2357 - val_mae: 4.9861 - val_mse: 48.2357\n",
      "Epoch 477/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.4771 - mae: 2.2001 - mse: 8.4771 - val_loss: 37.4269 - val_mae: 4.1618 - val_mse: 37.4268\n",
      "Epoch 478/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.3558 - mae: 2.1684 - mse: 8.3558 - val_loss: 41.3897 - val_mae: 4.5292 - val_mse: 41.3897\n",
      "Epoch 479/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.4484 - mae: 2.1827 - mse: 8.4484 - val_loss: 48.2415 - val_mae: 4.6925 - val_mse: 48.2415\n",
      "Epoch 480/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.4273 - mae: 2.1797 - mse: 8.4273 - val_loss: 47.3539 - val_mae: 4.6506 - val_mse: 47.3539\n",
      "Epoch 481/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.4897 - mae: 2.2074 - mse: 8.4897 - val_loss: 43.9638 - val_mae: 4.4807 - val_mse: 43.9638\n",
      "Epoch 482/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.3154 - mae: 2.1761 - mse: 8.3154 - val_loss: 51.0310 - val_mae: 4.9201 - val_mse: 51.0310\n",
      "Epoch 483/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.0625 - mae: 2.1358 - mse: 8.0625 - val_loss: 41.7984 - val_mae: 4.5125 - val_mse: 41.7984\n",
      "Epoch 484/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.2896 - mae: 2.1758 - mse: 8.2896 - val_loss: 40.0052 - val_mae: 4.3770 - val_mse: 40.0052\n",
      "Epoch 485/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.2573 - mae: 2.1678 - mse: 8.2573 - val_loss: 40.2350 - val_mae: 4.3264 - val_mse: 40.2350\n",
      "Epoch 486/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.0795 - mae: 2.1523 - mse: 8.0795 - val_loss: 48.2485 - val_mae: 4.7804 - val_mse: 48.2485\n",
      "Epoch 487/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.0952 - mae: 2.1574 - mse: 8.0952 - val_loss: 39.3026 - val_mae: 4.2495 - val_mse: 39.3026\n",
      "Epoch 488/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.1919 - mae: 2.1581 - mse: 8.1919 - val_loss: 36.2721 - val_mae: 4.0936 - val_mse: 36.2721\n",
      "Epoch 489/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.2446 - mae: 2.1575 - mse: 8.2446 - val_loss: 39.9245 - val_mae: 4.4079 - val_mse: 39.9245\n",
      "Epoch 490/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.0419 - mae: 2.1371 - mse: 8.0419 - val_loss: 41.0051 - val_mae: 4.5011 - val_mse: 41.0051\n",
      "Epoch 491/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.2036 - mae: 2.1522 - mse: 8.2036 - val_loss: 41.8344 - val_mae: 4.4066 - val_mse: 41.8344\n",
      "Epoch 492/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.0632 - mae: 2.1294 - mse: 8.0632 - val_loss: 39.3942 - val_mae: 4.1755 - val_mse: 39.3942\n",
      "Epoch 493/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.1060 - mae: 2.1508 - mse: 8.1060 - val_loss: 41.9972 - val_mae: 4.4849 - val_mse: 41.9972\n",
      "Epoch 494/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.1846 - mae: 2.1645 - mse: 8.1846 - val_loss: 39.6688 - val_mae: 4.2196 - val_mse: 39.6688\n",
      "Epoch 495/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.9194 - mae: 2.1426 - mse: 7.9194 - val_loss: 48.8764 - val_mae: 5.0119 - val_mse: 48.8764\n",
      "Epoch 496/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.1096 - mae: 2.1459 - mse: 8.1096 - val_loss: 39.3382 - val_mae: 4.2201 - val_mse: 39.3382\n",
      "Epoch 497/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.0978 - mae: 2.1401 - mse: 8.0978 - val_loss: 35.6352 - val_mae: 4.0672 - val_mse: 35.6352\n",
      "Epoch 498/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.9919 - mae: 2.1403 - mse: 7.9919 - val_loss: 47.0578 - val_mae: 4.7950 - val_mse: 47.0578\n",
      "Epoch 499/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.0420 - mae: 2.1393 - mse: 8.0420 - val_loss: 41.8623 - val_mae: 4.5322 - val_mse: 41.8623\n",
      "Epoch 500/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.9555 - mae: 2.1303 - mse: 7.9555 - val_loss: 39.5730 - val_mae: 4.2261 - val_mse: 39.5730\n",
      "Epoch 501/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.0903 - mae: 2.1509 - mse: 8.0903 - val_loss: 61.1686 - val_mae: 5.2502 - val_mse: 61.1686\n",
      "Epoch 502/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.8201 - mae: 2.1123 - mse: 7.8201 - val_loss: 44.6769 - val_mae: 4.5335 - val_mse: 44.6769\n",
      "Epoch 503/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.9606 - mae: 2.1297 - mse: 7.9606 - val_loss: 51.9936 - val_mae: 4.9273 - val_mse: 51.9936\n",
      "Epoch 504/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 8.0384 - mae: 2.1290 - mse: 8.0384 - val_loss: 40.6970 - val_mae: 4.3204 - val_mse: 40.6970\n",
      "Epoch 505/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.9263 - mae: 2.1194 - mse: 7.9263 - val_loss: 36.3510 - val_mae: 4.1843 - val_mse: 36.3510\n",
      "Epoch 506/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.9604 - mae: 2.1276 - mse: 7.9604 - val_loss: 43.2863 - val_mae: 4.4599 - val_mse: 43.2863\n",
      "Epoch 507/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.9877 - mae: 2.1289 - mse: 7.9877 - val_loss: 51.1687 - val_mae: 5.2008 - val_mse: 51.1687\n",
      "Epoch 508/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 7.8627 - mae: 2.1276 - mse: 7.8627 - val_loss: 43.6739 - val_mae: 4.4998 - val_mse: 43.6739\n",
      "Epoch 509/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.7936 - mae: 2.1034 - mse: 7.7936 - val_loss: 43.1843 - val_mae: 4.4532 - val_mse: 43.1843\n",
      "Epoch 510/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.8124 - mae: 2.1077 - mse: 7.8124 - val_loss: 43.5113 - val_mae: 4.6658 - val_mse: 43.5112\n",
      "Epoch 511/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 7.7210 - mae: 2.0825 - mse: 7.7210 - val_loss: 40.7950 - val_mae: 4.4275 - val_mse: 40.7950\n",
      "Epoch 512/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.9122 - mae: 2.1140 - mse: 7.9122 - val_loss: 65.5151 - val_mae: 6.0461 - val_mse: 65.5151\n",
      "Epoch 513/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.8487 - mae: 2.1003 - mse: 7.8487 - val_loss: 37.8032 - val_mae: 4.1269 - val_mse: 37.8032\n",
      "Epoch 514/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.6659 - mae: 2.0857 - mse: 7.6659 - val_loss: 50.9767 - val_mae: 5.1226 - val_mse: 50.9767\n",
      "Epoch 515/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.7222 - mae: 2.0777 - mse: 7.7222 - val_loss: 40.8099 - val_mae: 4.3894 - val_mse: 40.8099\n",
      "Epoch 516/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.7147 - mae: 2.0994 - mse: 7.7147 - val_loss: 38.6609 - val_mae: 4.2038 - val_mse: 38.6609\n",
      "Epoch 517/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.6245 - mae: 2.0869 - mse: 7.6245 - val_loss: 68.4053 - val_mae: 5.6370 - val_mse: 68.4053\n",
      "Epoch 518/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.8209 - mae: 2.0936 - mse: 7.8209 - val_loss: 37.4821 - val_mae: 4.1271 - val_mse: 37.4821\n",
      "Epoch 519/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.5988 - mae: 2.0875 - mse: 7.5988 - val_loss: 50.4378 - val_mae: 4.8570 - val_mse: 50.4378\n",
      "Epoch 520/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.5862 - mae: 2.0797 - mse: 7.5862 - val_loss: 36.2867 - val_mae: 4.1496 - val_mse: 36.2867\n",
      "Epoch 521/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.4457 - mae: 2.0543 - mse: 7.4457 - val_loss: 38.7917 - val_mae: 4.3158 - val_mse: 38.7918\n",
      "Epoch 522/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.5893 - mae: 2.0889 - mse: 7.5894 - val_loss: 45.0660 - val_mae: 4.5640 - val_mse: 45.0660\n",
      "Epoch 523/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.6760 - mae: 2.0998 - mse: 7.6760 - val_loss: 40.9316 - val_mae: 4.4679 - val_mse: 40.9316\n",
      "Epoch 524/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.5176 - mae: 2.0672 - mse: 7.5176 - val_loss: 47.3240 - val_mae: 4.6578 - val_mse: 47.3240\n",
      "Epoch 525/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.5948 - mae: 2.0779 - mse: 7.5948 - val_loss: 47.3770 - val_mae: 4.8083 - val_mse: 47.3770\n",
      "Epoch 526/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.4219 - mae: 2.0511 - mse: 7.4219 - val_loss: 42.9229 - val_mae: 4.6674 - val_mse: 42.9229\n",
      "Epoch 527/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.4382 - mae: 2.0479 - mse: 7.4382 - val_loss: 47.5012 - val_mae: 4.9403 - val_mse: 47.5012\n",
      "Epoch 528/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 7.4850 - mae: 2.0624 - mse: 7.4850 - val_loss: 44.4908 - val_mae: 4.5052 - val_mse: 44.4908\n",
      "Epoch 529/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.5314 - mae: 2.0831 - mse: 7.5314 - val_loss: 42.5493 - val_mae: 4.3912 - val_mse: 42.5493\n",
      "Epoch 530/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.5354 - mae: 2.0731 - mse: 7.5354 - val_loss: 60.1226 - val_mae: 5.2053 - val_mse: 60.1226\n",
      "Epoch 531/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.4797 - mae: 2.0792 - mse: 7.4797 - val_loss: 45.2107 - val_mae: 4.7349 - val_mse: 45.2107\n",
      "Epoch 532/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.1866 - mae: 2.0222 - mse: 7.1866 - val_loss: 41.2929 - val_mae: 4.2974 - val_mse: 41.2929\n",
      "Epoch 533/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.3411 - mae: 2.0402 - mse: 7.3411 - val_loss: 37.1640 - val_mae: 4.1908 - val_mse: 37.1640\n",
      "Epoch 534/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.4569 - mae: 2.0637 - mse: 7.4569 - val_loss: 43.7860 - val_mae: 4.4621 - val_mse: 43.7860\n",
      "Epoch 535/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 7.6024 - mae: 2.0842 - mse: 7.6024 - val_loss: 36.2556 - val_mae: 4.0772 - val_mse: 36.2556\n",
      "Epoch 536/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.5071 - mae: 2.0708 - mse: 7.5071 - val_loss: 45.3899 - val_mae: 4.7962 - val_mse: 45.3899\n",
      "Epoch 537/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.1822 - mae: 2.0366 - mse: 7.1822 - val_loss: 47.7289 - val_mae: 4.7409 - val_mse: 47.7290\n",
      "Epoch 538/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.3954 - mae: 2.0542 - mse: 7.3954 - val_loss: 39.0259 - val_mae: 4.2424 - val_mse: 39.0258\n",
      "Epoch 539/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.4966 - mae: 2.0689 - mse: 7.4966 - val_loss: 41.3121 - val_mae: 4.5497 - val_mse: 41.3121\n",
      "Epoch 540/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.5780 - mae: 2.0703 - mse: 7.5780 - val_loss: 36.1232 - val_mae: 4.0627 - val_mse: 36.1232\n",
      "Epoch 541/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 7.2712 - mae: 2.0215 - mse: 7.2712 - val_loss: 40.7132 - val_mae: 4.3487 - val_mse: 40.7132\n",
      "Epoch 542/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 7.2939 - mae: 2.0312 - mse: 7.2939 - val_loss: 44.1534 - val_mae: 4.5200 - val_mse: 44.1534\n",
      "Epoch 543/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.3447 - mae: 2.0463 - mse: 7.3447 - val_loss: 42.0909 - val_mae: 4.3515 - val_mse: 42.0909\n",
      "Epoch 544/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.1277 - mae: 2.0196 - mse: 7.1277 - val_loss: 40.8659 - val_mae: 4.2880 - val_mse: 40.8659\n",
      "Epoch 545/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 7.1184 - mae: 2.0125 - mse: 7.1184 - val_loss: 38.3227 - val_mae: 4.2169 - val_mse: 38.3227\n",
      "Epoch 546/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.3059 - mae: 2.0353 - mse: 7.3059 - val_loss: 44.3295 - val_mae: 4.4307 - val_mse: 44.3295\n",
      "Epoch 547/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.3916 - mae: 2.0395 - mse: 7.3916 - val_loss: 55.4707 - val_mae: 4.8760 - val_mse: 55.4707\n",
      "Epoch 548/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.3925 - mae: 2.0493 - mse: 7.3925 - val_loss: 34.7635 - val_mae: 3.9811 - val_mse: 34.7635\n",
      "Epoch 549/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.3648 - mae: 2.0330 - mse: 7.3648 - val_loss: 34.7620 - val_mae: 3.9791 - val_mse: 34.7620\n",
      "Epoch 550/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.1858 - mae: 2.0219 - mse: 7.1858 - val_loss: 39.8934 - val_mae: 4.2788 - val_mse: 39.8933\n",
      "Epoch 551/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.1520 - mae: 2.0071 - mse: 7.1520 - val_loss: 53.4183 - val_mae: 5.0926 - val_mse: 53.4183\n",
      "Epoch 552/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 7.1270 - mae: 2.0103 - mse: 7.1270 - val_loss: 44.4214 - val_mae: 4.4085 - val_mse: 44.4214\n",
      "Epoch 553/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.3148 - mae: 2.0422 - mse: 7.3148 - val_loss: 38.7932 - val_mae: 4.2204 - val_mse: 38.7932\n",
      "Epoch 554/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.2541 - mae: 2.0222 - mse: 7.2541 - val_loss: 37.0390 - val_mae: 4.0610 - val_mse: 37.0390\n",
      "Epoch 555/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.0313 - mae: 2.0009 - mse: 7.0313 - val_loss: 45.0293 - val_mae: 4.5817 - val_mse: 45.0293\n",
      "Epoch 556/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 7.1242 - mae: 2.0196 - mse: 7.1242 - val_loss: 40.1811 - val_mae: 4.2822 - val_mse: 40.1811\n",
      "Epoch 557/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.0747 - mae: 2.0065 - mse: 7.0747 - val_loss: 44.4561 - val_mae: 4.6679 - val_mse: 44.4561\n",
      "Epoch 558/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.1532 - mae: 2.0030 - mse: 7.1532 - val_loss: 50.3647 - val_mae: 5.1424 - val_mse: 50.3647\n",
      "Epoch 559/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.0592 - mae: 2.0054 - mse: 7.0592 - val_loss: 43.8586 - val_mae: 4.5133 - val_mse: 43.8586\n",
      "Epoch 560/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.9997 - mae: 2.0005 - mse: 6.9997 - val_loss: 39.4576 - val_mae: 4.3615 - val_mse: 39.4575\n",
      "Epoch 561/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 7.2016 - mae: 2.0215 - mse: 7.2016 - val_loss: 33.5411 - val_mae: 3.9212 - val_mse: 33.5411\n",
      "Epoch 562/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.0320 - mae: 1.9884 - mse: 7.0320 - val_loss: 37.2654 - val_mae: 4.1784 - val_mse: 37.2654\n",
      "Epoch 563/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.8712 - mae: 1.9782 - mse: 6.8712 - val_loss: 46.3697 - val_mae: 4.6131 - val_mse: 46.3697\n",
      "Epoch 564/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 7.1122 - mae: 2.0082 - mse: 7.1122 - val_loss: 43.1000 - val_mae: 4.5316 - val_mse: 43.1000\n",
      "Epoch 565/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.0273 - mae: 1.9963 - mse: 7.0273 - val_loss: 47.3504 - val_mae: 4.6236 - val_mse: 47.3504\n",
      "Epoch 566/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.8221 - mae: 1.9750 - mse: 6.8221 - val_loss: 39.1954 - val_mae: 4.2719 - val_mse: 39.1954\n",
      "Epoch 567/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.0387 - mae: 2.0023 - mse: 7.0387 - val_loss: 39.1078 - val_mae: 4.2981 - val_mse: 39.1078\n",
      "Epoch 568/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.0324 - mae: 1.9920 - mse: 7.0324 - val_loss: 37.5585 - val_mae: 4.1559 - val_mse: 37.5585\n",
      "Epoch 569/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.8882 - mae: 1.9841 - mse: 6.8882 - val_loss: 37.4106 - val_mae: 4.1684 - val_mse: 37.4106\n",
      "Epoch 570/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 6.9027 - mae: 1.9814 - mse: 6.9027 - val_loss: 42.5252 - val_mae: 4.4461 - val_mse: 42.5252\n",
      "Epoch 571/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 7.0273 - mae: 2.0118 - mse: 7.0273 - val_loss: 36.1782 - val_mae: 4.0445 - val_mse: 36.1782\n",
      "Epoch 572/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.9203 - mae: 1.9778 - mse: 6.9203 - val_loss: 41.3560 - val_mae: 4.5251 - val_mse: 41.3560\n",
      "Epoch 573/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 6.6937 - mae: 1.9456 - mse: 6.6937 - val_loss: 40.6062 - val_mae: 4.3249 - val_mse: 40.6062\n",
      "Epoch 574/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.8968 - mae: 1.9789 - mse: 6.8968 - val_loss: 41.7962 - val_mae: 4.3381 - val_mse: 41.7962\n",
      "Epoch 575/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.9045 - mae: 1.9855 - mse: 6.9045 - val_loss: 52.0909 - val_mae: 4.9327 - val_mse: 52.0909\n",
      "Epoch 576/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 6.8439 - mae: 1.9740 - mse: 6.8439 - val_loss: 35.9944 - val_mae: 3.9955 - val_mse: 35.9944\n",
      "Epoch 577/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.9395 - mae: 1.9989 - mse: 6.9395 - val_loss: 36.3539 - val_mae: 4.0283 - val_mse: 36.3539\n",
      "Epoch 578/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.8084 - mae: 1.9632 - mse: 6.8084 - val_loss: 45.9519 - val_mae: 4.6397 - val_mse: 45.9519\n",
      "Epoch 579/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.7361 - mae: 1.9586 - mse: 6.7361 - val_loss: 43.1279 - val_mae: 4.3278 - val_mse: 43.1279\n",
      "Epoch 580/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.8748 - mae: 1.9877 - mse: 6.8748 - val_loss: 41.5619 - val_mae: 4.3289 - val_mse: 41.5619\n",
      "Epoch 581/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 6.8189 - mae: 1.9755 - mse: 6.8189 - val_loss: 45.4425 - val_mae: 4.9090 - val_mse: 45.4425\n",
      "Epoch 582/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 6.7138 - mae: 1.9591 - mse: 6.7138 - val_loss: 41.5941 - val_mae: 4.5027 - val_mse: 41.5941\n",
      "Epoch 583/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.7449 - mae: 1.9517 - mse: 6.7450 - val_loss: 38.5567 - val_mae: 4.3201 - val_mse: 38.5567\n",
      "Epoch 584/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 6.9013 - mae: 1.9831 - mse: 6.9013 - val_loss: 34.9469 - val_mae: 3.9657 - val_mse: 34.9469\n",
      "Epoch 585/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 6.6131 - mae: 1.9483 - mse: 6.6131 - val_loss: 37.7676 - val_mae: 4.1458 - val_mse: 37.7676\n",
      "Epoch 586/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.7986 - mae: 1.9760 - mse: 6.7986 - val_loss: 37.9510 - val_mae: 4.1156 - val_mse: 37.9510\n",
      "Epoch 587/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 6.7441 - mae: 1.9684 - mse: 6.7441 - val_loss: 37.0233 - val_mae: 4.1767 - val_mse: 37.0232\n",
      "Epoch 588/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.7029 - mae: 1.9546 - mse: 6.7029 - val_loss: 43.8162 - val_mae: 4.4760 - val_mse: 43.8162\n",
      "Epoch 589/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.7685 - mae: 1.9658 - mse: 6.7685 - val_loss: 38.4889 - val_mae: 4.2306 - val_mse: 38.4889\n",
      "Epoch 590/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 6.7346 - mae: 1.9534 - mse: 6.7346 - val_loss: 37.0300 - val_mae: 4.0453 - val_mse: 37.0300\n",
      "Epoch 591/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.6285 - mae: 1.9470 - mse: 6.6285 - val_loss: 50.2413 - val_mae: 5.1825 - val_mse: 50.2413\n",
      "Epoch 592/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.7431 - mae: 1.9433 - mse: 6.7431 - val_loss: 40.9816 - val_mae: 4.3152 - val_mse: 40.9816\n",
      "Epoch 593/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.6209 - mae: 1.9432 - mse: 6.6209 - val_loss: 38.0814 - val_mae: 4.1553 - val_mse: 38.0814\n",
      "Epoch 594/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.6000 - mae: 1.9436 - mse: 6.6000 - val_loss: 38.6481 - val_mae: 4.2585 - val_mse: 38.6481\n",
      "Epoch 595/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.5800 - mae: 1.9300 - mse: 6.5800 - val_loss: 33.9588 - val_mae: 3.8898 - val_mse: 33.9588\n",
      "Epoch 596/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.5195 - mae: 1.9325 - mse: 6.5195 - val_loss: 46.7039 - val_mae: 4.9736 - val_mse: 46.7039\n",
      "Epoch 597/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.6167 - mae: 1.9344 - mse: 6.6167 - val_loss: 41.9707 - val_mae: 4.3599 - val_mse: 41.9707\n",
      "Epoch 598/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.4919 - mae: 1.9262 - mse: 6.4919 - val_loss: 38.7631 - val_mae: 4.3793 - val_mse: 38.7631\n",
      "Epoch 599/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 6.5374 - mae: 1.9376 - mse: 6.5374 - val_loss: 41.9466 - val_mae: 4.3664 - val_mse: 41.9466\n",
      "Epoch 600/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.6161 - mae: 1.9456 - mse: 6.6161 - val_loss: 37.9521 - val_mae: 4.2281 - val_mse: 37.9521\n",
      "Epoch 601/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.7856 - mae: 1.9397 - mse: 6.7856 - val_loss: 46.1349 - val_mae: 4.8015 - val_mse: 46.1350\n",
      "Epoch 602/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.5302 - mae: 1.9182 - mse: 6.5302 - val_loss: 40.8315 - val_mae: 4.2897 - val_mse: 40.8315\n",
      "Epoch 603/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.5338 - mae: 1.9222 - mse: 6.5338 - val_loss: 36.5338 - val_mae: 4.0849 - val_mse: 36.5338\n",
      "Epoch 604/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 6.6636 - mae: 1.9526 - mse: 6.6636 - val_loss: 46.4655 - val_mae: 4.6872 - val_mse: 46.4654\n",
      "Epoch 605/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.3861 - mae: 1.9107 - mse: 6.3861 - val_loss: 38.2003 - val_mae: 4.2003 - val_mse: 38.2003\n",
      "Epoch 606/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.4749 - mae: 1.9088 - mse: 6.4749 - val_loss: 36.2372 - val_mae: 4.0001 - val_mse: 36.2372\n",
      "Epoch 607/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 6.5848 - mae: 1.9350 - mse: 6.5848 - val_loss: 35.6221 - val_mae: 4.0829 - val_mse: 35.6221\n",
      "Epoch 608/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.5404 - mae: 1.9238 - mse: 6.5404 - val_loss: 37.4383 - val_mae: 4.1643 - val_mse: 37.4383\n",
      "Epoch 609/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.5227 - mae: 1.9188 - mse: 6.5227 - val_loss: 37.1117 - val_mae: 4.1586 - val_mse: 37.1117\n",
      "Epoch 610/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.5746 - mae: 1.9326 - mse: 6.5746 - val_loss: 37.3648 - val_mae: 4.1931 - val_mse: 37.3648\n",
      "Epoch 611/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.4073 - mae: 1.9144 - mse: 6.4073 - val_loss: 33.6961 - val_mae: 3.9095 - val_mse: 33.6961\n",
      "Epoch 612/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.4058 - mae: 1.9160 - mse: 6.4058 - val_loss: 45.6238 - val_mae: 4.8033 - val_mse: 45.6238\n",
      "Epoch 613/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.4507 - mae: 1.9016 - mse: 6.4507 - val_loss: 39.2689 - val_mae: 4.2831 - val_mse: 39.2689\n",
      "Epoch 614/750\n",
      "15704/15704 [==============================] - 23s 1ms/step - loss: 6.5008 - mae: 1.9300 - mse: 6.5008 - val_loss: 42.8350 - val_mae: 4.3245 - val_mse: 42.8350\n",
      "Epoch 615/750\n",
      "15704/15704 [==============================] - 23s 1ms/step - loss: 6.2219 - mae: 1.8889 - mse: 6.2219 - val_loss: 39.4985 - val_mae: 4.2873 - val_mse: 39.4985\n",
      "Epoch 616/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.4321 - mae: 1.9261 - mse: 6.4321 - val_loss: 36.1299 - val_mae: 4.0542 - val_mse: 36.1299\n",
      "Epoch 617/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.2593 - mae: 1.8868 - mse: 6.2593 - val_loss: 37.3636 - val_mae: 4.0678 - val_mse: 37.3636\n",
      "Epoch 618/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 6.3425 - mae: 1.9083 - mse: 6.3425 - val_loss: 36.5572 - val_mae: 4.0822 - val_mse: 36.5572\n",
      "Epoch 619/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.4486 - mae: 1.9099 - mse: 6.4486 - val_loss: 49.7559 - val_mae: 5.0312 - val_mse: 49.7559\n",
      "Epoch 620/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.2353 - mae: 1.8791 - mse: 6.2353 - val_loss: 39.8224 - val_mae: 4.3359 - val_mse: 39.8224\n",
      "Epoch 621/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.2690 - mae: 1.8907 - mse: 6.2690 - val_loss: 37.4559 - val_mae: 4.1462 - val_mse: 37.4559\n",
      "Epoch 622/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.2704 - mae: 1.8881 - mse: 6.2704 - val_loss: 37.5579 - val_mae: 4.1098 - val_mse: 37.5579\n",
      "Epoch 623/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.3351 - mae: 1.8847 - mse: 6.3351 - val_loss: 50.3704 - val_mae: 5.1768 - val_mse: 50.3704\n",
      "Epoch 624/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 6.3428 - mae: 1.8967 - mse: 6.3428 - val_loss: 40.3307 - val_mae: 4.3546 - val_mse: 40.3307\n",
      "Epoch 625/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.2203 - mae: 1.8616 - mse: 6.2203 - val_loss: 37.2841 - val_mae: 4.0665 - val_mse: 37.2841\n",
      "Epoch 626/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.1936 - mae: 1.8788 - mse: 6.1936 - val_loss: 39.2533 - val_mae: 4.3470 - val_mse: 39.2533\n",
      "Epoch 627/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.2197 - mae: 1.8717 - mse: 6.2197 - val_loss: 45.5478 - val_mae: 4.6542 - val_mse: 45.5479\n",
      "Epoch 628/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 6.3500 - mae: 1.9069 - mse: 6.3500 - val_loss: 41.9888 - val_mae: 4.4059 - val_mse: 41.9888\n",
      "Epoch 629/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.2090 - mae: 1.8765 - mse: 6.2090 - val_loss: 35.0002 - val_mae: 4.0351 - val_mse: 35.0002\n",
      "Epoch 630/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 6.3325 - mae: 1.8876 - mse: 6.3325 - val_loss: 32.3720 - val_mae: 3.7948 - val_mse: 32.3720\n",
      "Epoch 631/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.3440 - mae: 1.9117 - mse: 6.3440 - val_loss: 44.0067 - val_mae: 4.4503 - val_mse: 44.0066\n",
      "Epoch 632/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 6.2639 - mae: 1.8889 - mse: 6.2639 - val_loss: 36.3710 - val_mae: 4.1306 - val_mse: 36.3710\n",
      "Epoch 633/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 6.2139 - mae: 1.8801 - mse: 6.2139 - val_loss: 37.0282 - val_mae: 4.0458 - val_mse: 37.0282\n",
      "Epoch 634/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.1818 - mae: 1.8796 - mse: 6.1818 - val_loss: 34.9070 - val_mae: 3.9555 - val_mse: 34.9070\n",
      "Epoch 635/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 6.1637 - mae: 1.8664 - mse: 6.1637 - val_loss: 35.7455 - val_mae: 4.0305 - val_mse: 35.7455\n",
      "Epoch 636/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.1921 - mae: 1.8652 - mse: 6.1921 - val_loss: 36.0076 - val_mae: 4.0027 - val_mse: 36.0077\n",
      "Epoch 637/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.2231 - mae: 1.8917 - mse: 6.2231 - val_loss: 36.3400 - val_mae: 4.0458 - val_mse: 36.3400\n",
      "Epoch 638/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.2812 - mae: 1.8834 - mse: 6.2812 - val_loss: 38.2991 - val_mae: 4.1602 - val_mse: 38.2991\n",
      "Epoch 639/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.9873 - mae: 1.8560 - mse: 5.9873 - val_loss: 44.5082 - val_mae: 4.5369 - val_mse: 44.5082\n",
      "Epoch 640/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.0739 - mae: 1.8570 - mse: 6.0739 - val_loss: 35.6495 - val_mae: 4.0428 - val_mse: 35.6495\n",
      "Epoch 641/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.0410 - mae: 1.8688 - mse: 6.0410 - val_loss: 34.8617 - val_mae: 3.9632 - val_mse: 34.8617\n",
      "Epoch 642/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.1122 - mae: 1.8595 - mse: 6.1122 - val_loss: 52.9422 - val_mae: 4.9434 - val_mse: 52.9422\n",
      "Epoch 643/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.2372 - mae: 1.8690 - mse: 6.2372 - val_loss: 54.4376 - val_mae: 5.3154 - val_mse: 54.4376\n",
      "Epoch 644/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.0475 - mae: 1.8439 - mse: 6.0475 - val_loss: 36.8460 - val_mae: 4.2565 - val_mse: 36.8460\n",
      "Epoch 645/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.1516 - mae: 1.8679 - mse: 6.1516 - val_loss: 49.5020 - val_mae: 4.8199 - val_mse: 49.5020\n",
      "Epoch 646/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 6.1210 - mae: 1.8587 - mse: 6.1210 - val_loss: 40.2355 - val_mae: 4.2470 - val_mse: 40.2355\n",
      "Epoch 647/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.0174 - mae: 1.8381 - mse: 6.0174 - val_loss: 36.7828 - val_mae: 4.1206 - val_mse: 36.7828\n",
      "Epoch 648/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.0977 - mae: 1.8674 - mse: 6.0977 - val_loss: 40.7317 - val_mae: 4.5166 - val_mse: 40.7317\n",
      "Epoch 649/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.0021 - mae: 1.8591 - mse: 6.0021 - val_loss: 42.7639 - val_mae: 4.5718 - val_mse: 42.7639\n",
      "Epoch 650/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.9697 - mae: 1.8357 - mse: 5.9697 - val_loss: 34.3189 - val_mae: 3.9657 - val_mse: 34.3189\n",
      "Epoch 651/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.0710 - mae: 1.8577 - mse: 6.0710 - val_loss: 41.6908 - val_mae: 4.2697 - val_mse: 41.6908\n",
      "Epoch 652/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.9952 - mae: 1.8404 - mse: 5.9952 - val_loss: 38.7370 - val_mae: 4.1575 - val_mse: 38.7370\n",
      "Epoch 653/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.9451 - mae: 1.8402 - mse: 5.9451 - val_loss: 36.2717 - val_mae: 4.1554 - val_mse: 36.2717\n",
      "Epoch 654/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.1234 - mae: 1.8709 - mse: 6.1234 - val_loss: 33.5415 - val_mae: 3.9116 - val_mse: 33.5415\n",
      "Epoch 655/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 6.0306 - mae: 1.8471 - mse: 6.0306 - val_loss: 41.4951 - val_mae: 4.3880 - val_mse: 41.4951\n",
      "Epoch 656/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.8916 - mae: 1.8324 - mse: 5.8916 - val_loss: 40.4386 - val_mae: 4.2290 - val_mse: 40.4386\n",
      "Epoch 657/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.8881 - mae: 1.8361 - mse: 5.8881 - val_loss: 38.5521 - val_mae: 4.1678 - val_mse: 38.5521\n",
      "Epoch 658/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.8190 - mae: 1.8225 - mse: 5.8190 - val_loss: 37.4188 - val_mae: 4.1014 - val_mse: 37.4188\n",
      "Epoch 659/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.7038 - mae: 1.8148 - mse: 5.7038 - val_loss: 38.1244 - val_mae: 4.0875 - val_mse: 38.1244\n",
      "Epoch 660/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.9101 - mae: 1.8369 - mse: 5.9101 - val_loss: 36.9279 - val_mae: 4.0405 - val_mse: 36.9279\n",
      "Epoch 661/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.8196 - mae: 1.8242 - mse: 5.8196 - val_loss: 44.6668 - val_mae: 4.6088 - val_mse: 44.6668\n",
      "Epoch 662/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.8433 - mae: 1.8362 - mse: 5.8433 - val_loss: 39.1638 - val_mae: 4.1804 - val_mse: 39.1638\n",
      "Epoch 663/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.9118 - mae: 1.8412 - mse: 5.9118 - val_loss: 37.0529 - val_mae: 4.2000 - val_mse: 37.0529\n",
      "Epoch 664/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.8100 - mae: 1.8127 - mse: 5.8100 - val_loss: 46.3857 - val_mae: 4.5071 - val_mse: 46.3857\n",
      "Epoch 665/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.7105 - mae: 1.8101 - mse: 5.7105 - val_loss: 38.6358 - val_mae: 4.1602 - val_mse: 38.6358\n",
      "Epoch 666/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.8623 - mae: 1.8178 - mse: 5.8623 - val_loss: 42.5279 - val_mae: 4.3414 - val_mse: 42.5279\n",
      "Epoch 667/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.7690 - mae: 1.8042 - mse: 5.7690 - val_loss: 35.5904 - val_mae: 4.0808 - val_mse: 35.5904\n",
      "Epoch 668/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.8825 - mae: 1.8322 - mse: 5.8825 - val_loss: 40.8065 - val_mae: 4.4100 - val_mse: 40.8065\n",
      "Epoch 669/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.7044 - mae: 1.8060 - mse: 5.7044 - val_loss: 43.1944 - val_mae: 4.7232 - val_mse: 43.1944\n",
      "Epoch 670/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.8302 - mae: 1.8125 - mse: 5.8302 - val_loss: 49.5561 - val_mae: 4.8891 - val_mse: 49.5561\n",
      "Epoch 671/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.8101 - mae: 1.8151 - mse: 5.8101 - val_loss: 35.2685 - val_mae: 3.9991 - val_mse: 35.2685\n",
      "Epoch 672/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.6147 - mae: 1.7928 - mse: 5.6147 - val_loss: 34.4345 - val_mae: 3.9386 - val_mse: 34.4345\n",
      "Epoch 673/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.6302 - mae: 1.7822 - mse: 5.6302 - val_loss: 37.3085 - val_mae: 4.0240 - val_mse: 37.3085\n",
      "Epoch 674/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.6717 - mae: 1.7834 - mse: 5.6717 - val_loss: 34.4810 - val_mae: 3.9345 - val_mse: 34.4810\n",
      "Epoch 675/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.6516 - mae: 1.8077 - mse: 5.6516 - val_loss: 37.9862 - val_mae: 4.0719 - val_mse: 37.9862\n",
      "Epoch 676/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.7469 - mae: 1.8058 - mse: 5.7468 - val_loss: 41.5737 - val_mae: 4.3192 - val_mse: 41.5737\n",
      "Epoch 677/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.8192 - mae: 1.8199 - mse: 5.8192 - val_loss: 41.1899 - val_mae: 4.5023 - val_mse: 41.1899\n",
      "Epoch 678/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.6572 - mae: 1.7973 - mse: 5.6572 - val_loss: 40.3754 - val_mae: 4.2878 - val_mse: 40.3754\n",
      "Epoch 679/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.6371 - mae: 1.7883 - mse: 5.6371 - val_loss: 33.1114 - val_mae: 3.8613 - val_mse: 33.1114\n",
      "Epoch 680/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.7327 - mae: 1.8027 - mse: 5.7327 - val_loss: 34.9950 - val_mae: 4.0233 - val_mse: 34.9950\n",
      "Epoch 681/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.5931 - mae: 1.7799 - mse: 5.5931 - val_loss: 38.8718 - val_mae: 4.1189 - val_mse: 38.8718\n",
      "Epoch 682/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.6336 - mae: 1.7977 - mse: 5.6336 - val_loss: 35.1828 - val_mae: 4.0336 - val_mse: 35.1828\n",
      "Epoch 683/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.5185 - mae: 1.7763 - mse: 5.5185 - val_loss: 34.9876 - val_mae: 3.9877 - val_mse: 34.9876\n",
      "Epoch 684/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.6318 - mae: 1.8006 - mse: 5.6318 - val_loss: 36.2450 - val_mae: 4.0284 - val_mse: 36.2450\n",
      "Epoch 685/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.7784 - mae: 1.8086 - mse: 5.7784 - val_loss: 38.9397 - val_mae: 4.1658 - val_mse: 38.9398\n",
      "Epoch 686/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.7526 - mae: 1.8136 - mse: 5.7526 - val_loss: 38.0072 - val_mae: 4.1606 - val_mse: 38.0072\n",
      "Epoch 687/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.5510 - mae: 1.7779 - mse: 5.5510 - val_loss: 50.2642 - val_mae: 4.7884 - val_mse: 50.2642\n",
      "Epoch 688/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.6896 - mae: 1.7906 - mse: 5.6896 - val_loss: 41.8340 - val_mae: 4.3418 - val_mse: 41.8340\n",
      "Epoch 689/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.5614 - mae: 1.7889 - mse: 5.5614 - val_loss: 41.2221 - val_mae: 4.3390 - val_mse: 41.2221\n",
      "Epoch 690/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.6688 - mae: 1.7904 - mse: 5.6688 - val_loss: 36.0624 - val_mae: 3.9942 - val_mse: 36.0624\n",
      "Epoch 691/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.6640 - mae: 1.7897 - mse: 5.6640 - val_loss: 38.9895 - val_mae: 4.2484 - val_mse: 38.9895\n",
      "Epoch 692/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.5759 - mae: 1.7735 - mse: 5.5759 - val_loss: 40.0863 - val_mae: 4.2020 - val_mse: 40.0863\n",
      "Epoch 693/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.4998 - mae: 1.7693 - mse: 5.4998 - val_loss: 37.8972 - val_mae: 4.1796 - val_mse: 37.8972\n",
      "Epoch 694/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.6316 - mae: 1.7964 - mse: 5.6316 - val_loss: 34.5288 - val_mae: 3.9164 - val_mse: 34.5288\n",
      "Epoch 695/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.6393 - mae: 1.7830 - mse: 5.6393 - val_loss: 32.6529 - val_mae: 3.8218 - val_mse: 32.6529\n",
      "Epoch 696/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.6448 - mae: 1.7850 - mse: 5.6448 - val_loss: 39.4651 - val_mae: 4.1606 - val_mse: 39.4651\n",
      "Epoch 697/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.6087 - mae: 1.7886 - mse: 5.6087 - val_loss: 47.7681 - val_mae: 4.8392 - val_mse: 47.7681\n",
      "Epoch 698/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.4616 - mae: 1.7675 - mse: 5.4616 - val_loss: 36.3534 - val_mae: 4.0340 - val_mse: 36.3534\n",
      "Epoch 699/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.5205 - mae: 1.7726 - mse: 5.5205 - val_loss: 34.6283 - val_mae: 3.9147 - val_mse: 34.6283\n",
      "Epoch 700/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.5329 - mae: 1.7788 - mse: 5.5329 - val_loss: 36.4122 - val_mae: 4.0856 - val_mse: 36.4122\n",
      "Epoch 701/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.5954 - mae: 1.7719 - mse: 5.5954 - val_loss: 36.7186 - val_mae: 4.1808 - val_mse: 36.7186\n",
      "Epoch 702/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.5625 - mae: 1.7829 - mse: 5.5625 - val_loss: 35.6479 - val_mae: 4.0092 - val_mse: 35.6479\n",
      "Epoch 703/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.4097 - mae: 1.7609 - mse: 5.4097 - val_loss: 42.5027 - val_mae: 4.6189 - val_mse: 42.5026\n",
      "Epoch 704/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.5867 - mae: 1.7758 - mse: 5.5867 - val_loss: 38.0492 - val_mae: 4.1297 - val_mse: 38.0492\n",
      "Epoch 705/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.4357 - mae: 1.7608 - mse: 5.4357 - val_loss: 40.3484 - val_mae: 4.5760 - val_mse: 40.3484\n",
      "Epoch 706/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.5078 - mae: 1.7626 - mse: 5.5078 - val_loss: 36.8074 - val_mae: 4.0127 - val_mse: 36.8074\n",
      "Epoch 707/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.5194 - mae: 1.7683 - mse: 5.5194 - val_loss: 34.5111 - val_mae: 3.9335 - val_mse: 34.5111\n",
      "Epoch 708/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.3755 - mae: 1.7403 - mse: 5.3755 - val_loss: 37.5319 - val_mae: 4.1656 - val_mse: 37.5319\n",
      "Epoch 709/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.4361 - mae: 1.7588 - mse: 5.4361 - val_loss: 54.0136 - val_mae: 5.0110 - val_mse: 54.0137\n",
      "Epoch 710/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.4429 - mae: 1.7514 - mse: 5.4429 - val_loss: 40.9925 - val_mae: 4.4941 - val_mse: 40.9924\n",
      "Epoch 711/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.5019 - mae: 1.7660 - mse: 5.5019 - val_loss: 40.4822 - val_mae: 4.3958 - val_mse: 40.4822\n",
      "Epoch 712/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.4873 - mae: 1.7675 - mse: 5.4873 - val_loss: 34.2983 - val_mae: 3.9001 - val_mse: 34.2983\n",
      "Epoch 713/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.4533 - mae: 1.7610 - mse: 5.4533 - val_loss: 37.8666 - val_mae: 4.2471 - val_mse: 37.8667\n",
      "Epoch 714/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.4954 - mae: 1.7642 - mse: 5.4954 - val_loss: 40.0248 - val_mae: 4.4384 - val_mse: 40.0248\n",
      "Epoch 715/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.3711 - mae: 1.7593 - mse: 5.3711 - val_loss: 42.0740 - val_mae: 4.4212 - val_mse: 42.0740\n",
      "Epoch 716/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.4751 - mae: 1.7615 - mse: 5.4751 - val_loss: 40.4485 - val_mae: 4.1462 - val_mse: 40.4485\n",
      "Epoch 717/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.4153 - mae: 1.7523 - mse: 5.4153 - val_loss: 37.3091 - val_mae: 4.2296 - val_mse: 37.3091\n",
      "Epoch 718/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.3018 - mae: 1.7405 - mse: 5.3018 - val_loss: 38.5841 - val_mae: 4.1762 - val_mse: 38.5841\n",
      "Epoch 719/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.4538 - mae: 1.7590 - mse: 5.4538 - val_loss: 33.1316 - val_mae: 3.8478 - val_mse: 33.1316\n",
      "Epoch 720/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.3673 - mae: 1.7337 - mse: 5.3673 - val_loss: 40.3285 - val_mae: 4.2258 - val_mse: 40.3285\n",
      "Epoch 721/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.4094 - mae: 1.7443 - mse: 5.4094 - val_loss: 32.7578 - val_mae: 3.8411 - val_mse: 32.7578\n",
      "Epoch 722/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.3563 - mae: 1.7522 - mse: 5.3563 - val_loss: 38.1749 - val_mae: 4.3697 - val_mse: 38.1749\n",
      "Epoch 723/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.4069 - mae: 1.7501 - mse: 5.4069 - val_loss: 37.3076 - val_mae: 4.1537 - val_mse: 37.3076\n",
      "Epoch 724/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.4309 - mae: 1.7529 - mse: 5.4309 - val_loss: 33.8957 - val_mae: 3.8799 - val_mse: 33.8957\n",
      "Epoch 725/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.4840 - mae: 1.7582 - mse: 5.4840 - val_loss: 38.6842 - val_mae: 4.3486 - val_mse: 38.6842\n",
      "Epoch 726/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.3712 - mae: 1.7366 - mse: 5.3712 - val_loss: 41.5108 - val_mae: 4.4963 - val_mse: 41.5108\n",
      "Epoch 727/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.3176 - mae: 1.7410 - mse: 5.3176 - val_loss: 37.5126 - val_mae: 4.0986 - val_mse: 37.5126\n",
      "Epoch 728/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.2200 - mae: 1.7280 - mse: 5.2200 - val_loss: 35.9908 - val_mae: 3.9648 - val_mse: 35.9908\n",
      "Epoch 729/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.4531 - mae: 1.7539 - mse: 5.4531 - val_loss: 33.1235 - val_mae: 3.9078 - val_mse: 33.1235\n",
      "Epoch 730/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.2744 - mae: 1.7337 - mse: 5.2744 - val_loss: 39.3815 - val_mae: 4.3438 - val_mse: 39.3815\n",
      "Epoch 731/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.4297 - mae: 1.7469 - mse: 5.4297 - val_loss: 40.0144 - val_mae: 4.3217 - val_mse: 40.0144\n",
      "Epoch 732/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.3582 - mae: 1.7500 - mse: 5.3582 - val_loss: 37.2227 - val_mae: 4.1513 - val_mse: 37.2227\n",
      "Epoch 733/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.2643 - mae: 1.7327 - mse: 5.2643 - val_loss: 42.8058 - val_mae: 4.3937 - val_mse: 42.8058\n",
      "Epoch 734/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.2479 - mae: 1.7312 - mse: 5.2479 - val_loss: 40.6004 - val_mae: 4.3770 - val_mse: 40.6004\n",
      "Epoch 735/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.1751 - mae: 1.7168 - mse: 5.1751 - val_loss: 33.7438 - val_mae: 3.8795 - val_mse: 33.7438\n",
      "Epoch 736/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.3009 - mae: 1.7333 - mse: 5.3009 - val_loss: 38.9885 - val_mae: 4.1121 - val_mse: 38.9885\n",
      "Epoch 737/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.2357 - mae: 1.7262 - mse: 5.2357 - val_loss: 37.4214 - val_mae: 4.1574 - val_mse: 37.4214\n",
      "Epoch 738/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.2259 - mae: 1.7098 - mse: 5.2259 - val_loss: 36.9781 - val_mae: 4.0507 - val_mse: 36.9781\n",
      "Epoch 739/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.2348 - mae: 1.7321 - mse: 5.2348 - val_loss: 37.2283 - val_mae: 4.1090 - val_mse: 37.2283\n",
      "Epoch 740/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.3224 - mae: 1.7368 - mse: 5.3224 - val_loss: 38.8545 - val_mae: 4.2490 - val_mse: 38.8545\n",
      "Epoch 741/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.1455 - mae: 1.7014 - mse: 5.1455 - val_loss: 33.9116 - val_mae: 3.8315 - val_mse: 33.9116\n",
      "Epoch 742/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.3022 - mae: 1.7379 - mse: 5.3022 - val_loss: 41.9092 - val_mae: 4.4533 - val_mse: 41.9092\n",
      "Epoch 743/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.2098 - mae: 1.7097 - mse: 5.2098 - val_loss: 34.1246 - val_mae: 3.9507 - val_mse: 34.1246\n",
      "Epoch 744/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.2252 - mae: 1.7205 - mse: 5.2252 - val_loss: 36.0589 - val_mae: 3.9904 - val_mse: 36.0589\n",
      "Epoch 745/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.2637 - mae: 1.7179 - mse: 5.2637 - val_loss: 32.6492 - val_mae: 3.8214 - val_mse: 32.6492\n",
      "Epoch 746/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.1584 - mae: 1.7200 - mse: 5.1584 - val_loss: 41.1365 - val_mae: 4.3786 - val_mse: 41.1365\n",
      "Epoch 747/750\n",
      "15704/15704 [==============================] - 21s 1ms/step - loss: 5.1745 - mae: 1.7062 - mse: 5.1745 - val_loss: 36.4053 - val_mae: 4.0719 - val_mse: 36.4053\n",
      "Epoch 748/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.2438 - mae: 1.7260 - mse: 5.2438 - val_loss: 34.8817 - val_mae: 4.0291 - val_mse: 34.8817\n",
      "Epoch 749/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.2513 - mae: 1.7344 - mse: 5.2513 - val_loss: 34.9025 - val_mae: 3.9991 - val_mse: 34.9025\n",
      "Epoch 750/750\n",
      "15704/15704 [==============================] - 22s 1ms/step - loss: 5.1002 - mae: 1.7062 - mse: 5.1002 - val_loss: 35.8286 - val_mae: 4.0982 - val_mse: 35.8286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x210bbbd7108>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(simsTrain, targetTrain, epochs=750, verbose=1, validation_data=(simsTest,targetTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3927/3927 [==============================] - 2s 401us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[35.82863289240756, 4.098214626312256, 35.82863998413086]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(simsTest,targetTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 129ms/step\n",
      "[[53.631084]]\n",
      "62.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[103.068344]]\n",
      "99.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[147.82161]]\n",
      "156.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[97.04354]]\n",
      "81.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[132.71924]]\n",
      "135.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[275.43393]]\n",
      "268.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[101.08215]]\n",
      "99.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[59.951275]]\n",
      "61.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[116.662544]]\n",
      "126.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[151.58888]]\n",
      "149.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[97.1438]]\n",
      "93.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[106.10655]]\n",
      "108.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[126.30682]]\n",
      "127.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[168.36891]]\n",
      "174.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[19.651096]]\n",
      "26.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[142.53249]]\n",
      "149.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[208.72757]]\n",
      "205.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[264.66522]]\n",
      "261.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[27.73299]]\n",
      "29.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[22.365948]]\n",
      "23.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[49.780025]]\n",
      "47.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[52.56359]]\n",
      "52.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[119.81587]]\n",
      "124.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[21.338974]]\n",
      "23.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[25.48476]]\n",
      "28.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[119.14045]]\n",
      "124.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[134.38475]]\n",
      "134.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[9.92382]]\n",
      "10.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[54.61064]]\n",
      "53.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[99.718094]]\n",
      "109.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[157.88991]]\n",
      "161.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[157.10443]]\n",
      "149.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[87.12022]]\n",
      "93.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[160.9043]]\n",
      "160.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[172.98587]]\n",
      "184.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[76.02493]]\n",
      "85.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[51.75322]]\n",
      "46.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[117.75005]]\n",
      "111.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[140.9416]]\n",
      "140.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[91.70203]]\n",
      "89.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[65.08163]]\n",
      "66.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[71.03731]]\n",
      "62.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[67.69692]]\n",
      "78.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[113.56173]]\n",
      "110.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[50.280434]]\n",
      "50.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[43.18919]]\n",
      "48.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[114.1323]]\n",
      "104.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[141.34914]]\n",
      "143.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[41.06296]]\n",
      "43.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[212.30376]]\n",
      "212.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[132.3926]]\n",
      "142.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[93.40167]]\n",
      "97.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[160.15047]]\n",
      "164.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[182.71255]]\n",
      "184.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[226.51256]]\n",
      "240.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[100.185036]]\n",
      "97.5\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "[[71.98175]]\n",
      "74.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[263.39014]]\n",
      "258.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[34.979237]]\n",
      "35.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[18.887613]]\n",
      "21.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[209.8116]]\n",
      "209.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[42.96514]]\n",
      "41.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[122.61709]]\n",
      "124.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[179.76007]]\n",
      "180.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[19.781149]]\n",
      "26.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[40.12128]]\n",
      "52.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[179.23282]]\n",
      "183.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[70.60402]]\n",
      "70.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[195.28728]]\n",
      "193.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[51.4694]]\n",
      "59.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[4.5515976]]\n",
      "6.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[17.957817]]\n",
      "22.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[133.62498]]\n",
      "138.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[274.78903]]\n",
      "271.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[36.417854]]\n",
      "37.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[71.29631]]\n",
      "67.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[95.87546]]\n",
      "95.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[16.087164]]\n",
      "19.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[81.85265]]\n",
      "80.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[32.9107]]\n",
      "34.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[104.4231]]\n",
      "104.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[152.27338]]\n",
      "149.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[93.93402]]\n",
      "97.5\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "[[139.87367]]\n",
      "143.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[156.35182]]\n",
      "158.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[95.14294]]\n",
      "95.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[112.20948]]\n",
      "111.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[5.4866943]]\n",
      "7.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[102.539406]]\n",
      "96.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[48.06275]]\n",
      "49.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[147.22357]]\n",
      "146.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[178.41322]]\n",
      "181.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[100.65214]]\n",
      "96.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[144.77145]]\n",
      "144.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[115.35187]]\n",
      "111.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[125.217285]]\n",
      "126.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[183.76544]]\n",
      "185.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[96.5572]]\n",
      "100.5\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[78.807655]]\n",
      "78.5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[115.53697]]\n",
      "117.5\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    test = np.array([simsTest[i]])\n",
    "    print(model.predict(test, verbose=1))\n",
    "    print(targetTest[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"./model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./valData.npy\", simsTest)\n",
    "np.save(\"./valTarget.npy\", targetTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
